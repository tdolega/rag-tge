{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tdolega/miniconda/envs/p311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from common.consts import RESULTS_DIR, EVAL_SIZE\n",
    "from common.utils import filename_to_obj, remove_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:14<00:00,  1.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_idx</th>\n",
       "      <th>question_id</th>\n",
       "      <th>llm</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>ellm</th>\n",
       "      <th>sim</th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>citations/supported</th>\n",
       "      <th>citations/citations</th>\n",
       "      <th>citations/correct_citations</th>\n",
       "      <th>citations/out_of_range</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "      <th>quality/new_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[[], [3]]</td>\n",
       "      <td>[[], [True]]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.730736</td>\n",
       "      <td>What is the relationship between Jordan Subban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[[], [3]]</td>\n",
       "      <td>[[], [True]]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.822013</td>\n",
       "      <td>What professional hockey player was drafted fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[[], [3]]</td>\n",
       "      <td>[[], [True]]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.730736</td>\n",
       "      <td>What is the relationship between Jordan Subban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5a761900554299109176e648</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[[1]]</td>\n",
       "      <td>[[True]]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965509</td>\n",
       "      <td>What is the name of the lobbying group that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5a761900554299109176e648</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[[1]]</td>\n",
       "      <td>[[True]]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974511</td>\n",
       "      <td>What is the name of the lobbying group that wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_idx               question_id                 llm prompt_id  \\\n",
       "0             0  5abab42e55429955dce3eed2  gpt-3.5-turbo-0125         1   \n",
       "1             0  5abab42e55429955dce3eed2  gpt-3.5-turbo-0125         1   \n",
       "2             0  5abab42e55429955dce3eed2  gpt-3.5-turbo-0125         1   \n",
       "3             1  5a761900554299109176e648  gpt-3.5-turbo-0125         1   \n",
       "4             1  5a761900554299109176e648  gpt-3.5-turbo-0125         1   \n",
       "\n",
       "  temperature                      nli                      ellm  \\\n",
       "0         0.1  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "1         0.1  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "2         0.1  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "3         0.1  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "4         0.1  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "\n",
       "                sim  citations/ais_recall  citations/ais_precision  ...  \\\n",
       "0  all-MiniLM-L6-v2                   0.0                      1.0  ...   \n",
       "1  all-MiniLM-L6-v2                   0.0                      1.0  ...   \n",
       "2  all-MiniLM-L6-v2                   0.0                      1.0  ...   \n",
       "3  all-MiniLM-L6-v2                   1.0                      1.0  ...   \n",
       "4  all-MiniLM-L6-v2                   1.0                      1.0  ...   \n",
       "\n",
       "   citations/supported  citations/citations  citations/correct_citations  \\\n",
       "0               [0, 0]            [[], [3]]                 [[], [True]]   \n",
       "1               [0, 0]            [[], [3]]                 [[], [True]]   \n",
       "2               [0, 0]            [[], [3]]                 [[], [True]]   \n",
       "3                  [1]                [[1]]                     [[True]]   \n",
       "4                  [1]                [[1]]                     [[True]]   \n",
       "\n",
       "   citations/out_of_range  correctness/answer_overlap  \\\n",
       "0                  [0, 0]                         0.5   \n",
       "1                  [0, 0]                         0.5   \n",
       "2                  [0, 0]                         0.5   \n",
       "3                     [0]                         1.0   \n",
       "4                     [0]                         1.0   \n",
       "\n",
       "  correctness/answer_entail correctness/citations_recall  \\\n",
       "0                       0.0                          0.5   \n",
       "1                       0.0                          0.5   \n",
       "2                       0.0                          0.5   \n",
       "3                       1.0                          0.5   \n",
       "4                       1.0                          0.5   \n",
       "\n",
       "  correctness/citations_precision quality/answer_relevance  \\\n",
       "0                             1.0                 0.730736   \n",
       "1                             1.0                 0.822013   \n",
       "2                             1.0                 0.730736   \n",
       "3                             1.0                 0.965509   \n",
       "4                             1.0                 0.974511   \n",
       "\n",
       "                                quality/new_question  \n",
       "0  What is the relationship between Jordan Subban...  \n",
       "1  What professional hockey player was drafted fi...  \n",
       "2  What is the relationship between Jordan Subban...  \n",
       "3  What is the name of the lobbying group that wa...  \n",
       "4  What is the name of the lobbying group that wa...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def results_as_pandas(filename):\n",
    "    path = os.path.join(RESULTS_DIR, filename)\n",
    "    with open(path, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "    data = [json.loads(d) for d in data]\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    if len(data) == 0:\n",
    "        print(f\"empty file: {filename}\")\n",
    "        return data\n",
    "\n",
    "    params = filename_to_obj(filename)\n",
    "    for k, v in params.items():\n",
    "        data[k] = v\n",
    "\n",
    "    data = data.explode(\"evaluations\")\n",
    "    data = data.rename_axis(\"question_idx\").reset_index()\n",
    "\n",
    "    data = pd.concat([data, data[\"evaluations\"].apply(pd.Series)], axis=1)\n",
    "    evaluation_keys = data[\"evaluations\"].apply(pd.Series).columns\n",
    "    for col in evaluation_keys:\n",
    "        data = pd.concat([data, data[col].apply(pd.Series).add_prefix(f\"{col}/\")], axis=1)\n",
    "        data = data.drop(columns=col)\n",
    "    data = data.drop(columns=[\"evaluations\"])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "files = os.listdir(RESULTS_DIR)\n",
    "params_names = list(filename_to_obj(files[0]).keys())\n",
    "all_results = pd.concat([results_as_pandas(f) for f in tqdm(files)])\n",
    "all_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns: ['citations/correct_citations', 'citations/sentences', 'quality/new_question', 'citations/citations', 'citations/supported', 'citations/out_of_range']\n"
     ]
    }
   ],
   "source": [
    "all_obj_cols = all_results.select_dtypes(include=[\"object\"]).columns\n",
    "drop_obj_cols = list(set(all_obj_cols) - set(params_names))\n",
    "drop_obj_cols.remove(\"question_id\")\n",
    "print(f\"Dropping columns: {drop_obj_cols}\")\n",
    "all_num_results = all_results.drop(columns=drop_obj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_split = all_num_results[all_num_results[\"question_idx\"] < EVAL_SIZE]\n",
    "train_split = all_num_results[all_num_results[\"question_idx\"] >= EVAL_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(split):\n",
    "    split = split.drop(columns=[\"question_idx\"])\n",
    "    results_with_std_for_each_question = split.groupby([*params_names, \"question_id\"]).agg([\"mean\", \"std\"])\n",
    "    results_for_each_model = results_with_std_for_each_question.groupby(params_names)\n",
    "    results = results_for_each_model.mean()\n",
    "    results[\"n_questions\"] = results_for_each_model.size()\n",
    "    return results\n",
    "\n",
    "\n",
    "eval_results = aggregate(eval_split)\n",
    "train_results = aggregate(train_split)\n",
    "\n",
    "if eval_results[\"n_questions\"].nunique() != 1:\n",
    "    print(\"Warning: not all rows in evaluation have the same number of examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Prompts comparison"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_sentences</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_total_citations</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_correct_citations</th>\n",
       "      <th>...</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "      <th>n_questions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>ellm</th>\n",
       "      <th>sim</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.871517</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>2.573333</td>\n",
       "      <td>0.212475</td>\n",
       "      <td>3.016667</td>\n",
       "      <td>0.372709</td>\n",
       "      <td>2.676667</td>\n",
       "      <td>0.302403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.721619</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.028340</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.501540</td>\n",
       "      <td>0.066146</td>\n",
       "      <td>0.862167</td>\n",
       "      <td>0.034978</td>\n",
       "      <td>2.473333</td>\n",
       "      <td>0.204254</td>\n",
       "      <td>2.883333</td>\n",
       "      <td>0.333316</td>\n",
       "      <td>2.536667</td>\n",
       "      <td>0.298675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027905</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.043301</td>\n",
       "      <td>0.670627</td>\n",
       "      <td>0.046655</td>\n",
       "      <td>0.704898</td>\n",
       "      <td>0.030174</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.580222</td>\n",
       "      <td>0.045033</td>\n",
       "      <td>0.890076</td>\n",
       "      <td>0.024787</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>0.156519</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>0.282902</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>0.240940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.042370</td>\n",
       "      <td>0.658884</td>\n",
       "      <td>0.027177</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 citations/ais_recall  \\\n",
       "                                                                                                                                 mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                     \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.575644   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.501540   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.580222   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.036560   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.066146   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.045033   \n",
       "\n",
       "                                                                                                                 citations/ais_precision  \\\n",
       "                                                                                                                                    mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                        \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.871517   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.862167   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.890076   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.038350   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034978   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.024787   \n",
       "\n",
       "                                                                                                                 citations/n_sentences  \\\n",
       "                                                                                                                                  mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                      \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.573333   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.473333   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.980000   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.212475   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.204254   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.156519   \n",
       "\n",
       "                                                                                                                 citations/n_total_citations  \\\n",
       "                                                                                                                                        mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                            \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    3.016667   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.883333   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.416667   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.372709   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.333316   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.282902   \n",
       "\n",
       "                                                                                                                 citations/n_correct_citations  \\\n",
       "                                                                                                                                          mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                              \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.676667   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.536667   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.150000   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.302403   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.298675   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.240940   \n",
       "\n",
       "                                                                                                                  ...  \\\n",
       "                                                                                                                  ...   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim               ...   \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "\n",
       "                                                                                                                 correctness/answer_overlap  \\\n",
       "                                                                                                                                        std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                           \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.014915   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.027905   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.017321   \n",
       "\n",
       "                                                                                                                 correctness/answer_entail  \\\n",
       "                                                                                                                                      mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.886667   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.860000   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.863333   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.011547   \n",
       "\n",
       "                                                                                                                 correctness/citations_recall  \\\n",
       "                                                                                                                                         mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                             \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.751667   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.770000   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.665000   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.025981   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.043301   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034641   \n",
       "\n",
       "                                                                                                                 correctness/citations_precision  \\\n",
       "                                                                                                                                            mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                                \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.721619   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.670627   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.658333   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.050125   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.046655   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.042370   \n",
       "\n",
       "                                                                                                                 quality/answer_relevance  \\\n",
       "                                                                                                                                     mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                         \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.720431   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.704898   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.658884   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.028340   \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.030174   \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.027177   \n",
       "\n",
       "                                                                                                                 n_questions  \n",
       "                                                                                                                              \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                           \n",
       "Mistral-7B-Instruct-v0.2 1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "                         2         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "                         3         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Prompts comparison\"))\n",
    "parameter_results = eval_results[eval_results.index.get_level_values(\"llm\") == \"Mistral-7B-Instruct-v0.2\"]\n",
    "parameter_results[parameter_results.index.get_level_values(\"temperature\") == \"0.1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Temperature comparison"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_sentences</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_total_citations</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_correct_citations</th>\n",
       "      <th>...</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "      <th>n_questions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>ellm</th>\n",
       "      <th>sim</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">Mistral-7B-Instruct-v0.2</th>\n",
       "      <th rowspan=\"13\" valign=\"top\">1</th>\n",
       "      <th>0.01</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.574825</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>0.889365</td>\n",
       "      <td>0.016922</td>\n",
       "      <td>2.576667</td>\n",
       "      <td>0.130745</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>0.223121</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.212073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.744357</td>\n",
       "      <td>0.023419</td>\n",
       "      <td>0.734959</td>\n",
       "      <td>0.015812</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.871517</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>2.573333</td>\n",
       "      <td>0.212475</td>\n",
       "      <td>3.016667</td>\n",
       "      <td>0.372709</td>\n",
       "      <td>2.676667</td>\n",
       "      <td>0.302403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.721619</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.028340</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.544493</td>\n",
       "      <td>0.081991</td>\n",
       "      <td>0.877352</td>\n",
       "      <td>0.050804</td>\n",
       "      <td>2.626667</td>\n",
       "      <td>0.320651</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.600330</td>\n",
       "      <td>2.630000</td>\n",
       "      <td>0.482049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029793</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.741825</td>\n",
       "      <td>0.050897</td>\n",
       "      <td>0.725103</td>\n",
       "      <td>0.033120</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.566712</td>\n",
       "      <td>0.084729</td>\n",
       "      <td>0.863762</td>\n",
       "      <td>0.066155</td>\n",
       "      <td>2.546667</td>\n",
       "      <td>0.455952</td>\n",
       "      <td>2.913333</td>\n",
       "      <td>0.668395</td>\n",
       "      <td>2.536667</td>\n",
       "      <td>0.568113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045707</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.059848</td>\n",
       "      <td>0.749746</td>\n",
       "      <td>0.067481</td>\n",
       "      <td>0.723474</td>\n",
       "      <td>0.047856</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.580572</td>\n",
       "      <td>0.150051</td>\n",
       "      <td>0.877947</td>\n",
       "      <td>0.108934</td>\n",
       "      <td>2.623333</td>\n",
       "      <td>0.659426</td>\n",
       "      <td>3.006667</td>\n",
       "      <td>0.822505</td>\n",
       "      <td>2.623333</td>\n",
       "      <td>0.761222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044607</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.096603</td>\n",
       "      <td>0.738476</td>\n",
       "      <td>0.099659</td>\n",
       "      <td>0.721409</td>\n",
       "      <td>0.049850</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.569651</td>\n",
       "      <td>0.144597</td>\n",
       "      <td>0.881010</td>\n",
       "      <td>0.085049</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>0.579914</td>\n",
       "      <td>2.903333</td>\n",
       "      <td>0.792816</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>0.685930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073768</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>0.082169</td>\n",
       "      <td>0.737151</td>\n",
       "      <td>0.114113</td>\n",
       "      <td>0.707704</td>\n",
       "      <td>0.059824</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.519373</td>\n",
       "      <td>0.168079</td>\n",
       "      <td>0.856773</td>\n",
       "      <td>0.110804</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>0.631519</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.936496</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>0.813529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049038</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.121810</td>\n",
       "      <td>0.738574</td>\n",
       "      <td>0.125848</td>\n",
       "      <td>0.715341</td>\n",
       "      <td>0.064925</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.555853</td>\n",
       "      <td>0.182757</td>\n",
       "      <td>0.858316</td>\n",
       "      <td>0.115458</td>\n",
       "      <td>2.550000</td>\n",
       "      <td>0.585797</td>\n",
       "      <td>2.996667</td>\n",
       "      <td>0.863642</td>\n",
       "      <td>2.553333</td>\n",
       "      <td>0.708564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047054</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.118923</td>\n",
       "      <td>0.736230</td>\n",
       "      <td>0.132095</td>\n",
       "      <td>0.727172</td>\n",
       "      <td>0.058840</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.505895</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.842402</td>\n",
       "      <td>0.131938</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.702563</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>1.059032</td>\n",
       "      <td>2.506667</td>\n",
       "      <td>0.900543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062564</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.086603</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.119697</td>\n",
       "      <td>0.719730</td>\n",
       "      <td>0.123992</td>\n",
       "      <td>0.725166</td>\n",
       "      <td>0.070362</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.572745</td>\n",
       "      <td>0.204617</td>\n",
       "      <td>0.876745</td>\n",
       "      <td>0.127270</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>0.696808</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>0.846552</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>0.789139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074434</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.149130</td>\n",
       "      <td>0.731516</td>\n",
       "      <td>0.152158</td>\n",
       "      <td>0.695873</td>\n",
       "      <td>0.073964</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.550218</td>\n",
       "      <td>0.202885</td>\n",
       "      <td>0.858579</td>\n",
       "      <td>0.139181</td>\n",
       "      <td>2.213333</td>\n",
       "      <td>0.587042</td>\n",
       "      <td>2.460000</td>\n",
       "      <td>0.796912</td>\n",
       "      <td>2.196667</td>\n",
       "      <td>0.753401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066776</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.063509</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.144130</td>\n",
       "      <td>0.707476</td>\n",
       "      <td>0.164076</td>\n",
       "      <td>0.686019</td>\n",
       "      <td>0.081091</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.524532</td>\n",
       "      <td>0.221513</td>\n",
       "      <td>0.856628</td>\n",
       "      <td>0.156983</td>\n",
       "      <td>2.436667</td>\n",
       "      <td>0.795766</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.952201</td>\n",
       "      <td>2.340000</td>\n",
       "      <td>0.775175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074745</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.069282</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.178205</td>\n",
       "      <td>0.711397</td>\n",
       "      <td>0.160805</td>\n",
       "      <td>0.696656</td>\n",
       "      <td>0.077673</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.463269</td>\n",
       "      <td>0.259358</td>\n",
       "      <td>0.785161</td>\n",
       "      <td>0.220605</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>1.167374</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>1.582522</td>\n",
       "      <td>2.596667</td>\n",
       "      <td>1.230488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089997</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.223412</td>\n",
       "      <td>0.658788</td>\n",
       "      <td>0.225945</td>\n",
       "      <td>0.695753</td>\n",
       "      <td>0.089034</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 citations/ais_recall  \\\n",
       "                                                                                                                                 mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                     \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.574825   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.575644   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.544493   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.566712   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.580572   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.569651   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.519373   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.555853   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.505895   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.572745   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.550218   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.524532   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.463269   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.027143   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.036560   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.081991   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.084729   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.150051   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.144597   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.168079   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.182757   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.195393   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.204617   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.202885   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.221513   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.259358   \n",
       "\n",
       "                                                                                                                 citations/ais_precision  \\\n",
       "                                                                                                                                    mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                        \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.889365   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.871517   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.877352   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.863762   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.877947   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.881010   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.856773   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.858316   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.842402   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.876745   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.858579   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.856628   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.785161   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.016922   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.038350   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.050804   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.066155   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.108934   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.085049   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.110804   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.115458   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.131938   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.127270   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.139181   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.156983   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.220605   \n",
       "\n",
       "                                                                                                                 citations/n_sentences  \\\n",
       "                                                                                                                                  mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                      \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.576667   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.573333   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.626667   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.546667   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.623333   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.510000   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.583333   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.550000   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.600000   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.380000   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.213333   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.436667   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.740000   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.130745   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.212475   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.320651   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.455952   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.659426   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.579914   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.631519   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.585797   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.702563   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.696808   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.587042   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.795766   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.167374   \n",
       "\n",
       "                                                                                                                 citations/n_total_citations  \\\n",
       "                                                                                                                                        mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                            \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.966667   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    3.016667   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    3.000000   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.913333   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    3.006667   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.903333   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    3.000000   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.996667   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    3.030000   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.583333   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.460000   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.750000   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    3.240000   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.223121   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.372709   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.600330   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.668395   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.822505   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.792816   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.936496   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.863642   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.059032   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.846552   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.796912   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.952201   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.582522   \n",
       "\n",
       "                                                                                                                 citations/n_correct_citations  \\\n",
       "                                                                                                                                          mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                              \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.666667   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.676667   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.630000   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.536667   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.623333   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.570000   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.453333   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.553333   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.506667   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.320000   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.196667   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.340000   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.596667   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.212073   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.302403   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.482049   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.568113   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.761222   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.685930   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.813529   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.708564   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.900543   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.789139   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.753401   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.775175   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.230488   \n",
       "\n",
       "                                                                                                                  ...  \\\n",
       "                                                                                                                  ...   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim               ...   \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "\n",
       "                                                                                                                 correctness/answer_overlap  \\\n",
       "                                                                                                                                        std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                           \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.012990   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.014915   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.029793   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.045707   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.044607   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.073768   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.049038   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.047054   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.062564   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.074434   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.066776   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.074745   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.089997   \n",
       "\n",
       "                                                                                                                 correctness/answer_entail  \\\n",
       "                                                                                                                                      mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.883333   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.886667   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.886667   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.883333   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.886667   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.880000   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.870000   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.873333   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.860000   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.856667   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.836667   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.853333   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.830000   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.028868   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034641   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040415   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.028868   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.086603   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.057735   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.063509   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.069282   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.075056   \n",
       "\n",
       "                                                                                                                 correctness/citations_recall  \\\n",
       "                                                                                                                                         mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                             \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.758333   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.751667   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.770000   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.776667   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.775000   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.761667   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.758333   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.770000   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.751667   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.751667   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.706667   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.753333   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.770000   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.014434   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.025981   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.051962   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.059848   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.096603   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.082169   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.121810   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.118923   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.119697   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.149130   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.144130   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.178205   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.223412   \n",
       "\n",
       "                                                                                                                 correctness/citations_precision  \\\n",
       "                                                                                                                                            mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                                \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.744357   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.721619   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.741825   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.749746   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.738476   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.737151   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.738574   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.736230   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.719730   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.731516   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.707476   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.711397   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.658788   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023419   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.050125   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.050897   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.067481   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.099659   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.114113   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.125848   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.132095   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.123992   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.152158   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.164076   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.160805   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.225945   \n",
       "\n",
       "                                                                                                                 quality/answer_relevance  \\\n",
       "                                                                                                                                     mean   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                                         \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.734959   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.720431   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.725103   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.723474   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.721409   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.707704   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.715341   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.727172   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.725166   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.695873   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.686019   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.696656   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.695753   \n",
       "\n",
       "                                                                                                                            \\\n",
       "                                                                                                                       std   \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                          \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.015812   \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.028340   \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.033120   \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.047856   \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.049850   \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.059824   \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.064925   \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.058840   \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.070362   \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.073964   \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.081091   \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.077673   \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.089034   \n",
       "\n",
       "                                                                                                                 n_questions  \n",
       "                                                                                                                              \n",
       "llm                      prompt_id temperature nli                     ellm                     sim                           \n",
       "Mistral-7B-Instruct-v0.2 1         0.01        t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "                                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "                                   0.2         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "                                   0.3         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "                                   0.4         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "                                   0.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "                                   0.6         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "                                   0.7         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "                                   0.8         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "                                   0.9         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "                                   1.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "                                   1.5         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "                                   2.0         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "\n",
       "[13 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Temperature comparison\"))\n",
    "parameter_results[parameter_results.index.get_level_values(\"prompt_id\") == \"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Evaluation results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_sentences</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_total_citations</th>\n",
       "      <th>citations/n_correct_citations</th>\n",
       "      <th>...</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "      <th>n_questions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>ellm</th>\n",
       "      <th>sim</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mixtral-8x7b-instruct-v0.1.Q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.604452</td>\n",
       "      <td>0.084171</td>\n",
       "      <td>0.921198</td>\n",
       "      <td>0.053556</td>\n",
       "      <td>2.746667</td>\n",
       "      <td>0.294585</td>\n",
       "      <td>2.893333</td>\n",
       "      <td>0.438508</td>\n",
       "      <td>2.696667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.821722</td>\n",
       "      <td>0.066027</td>\n",
       "      <td>0.711417</td>\n",
       "      <td>0.048184</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.737556</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>0.214022</td>\n",
       "      <td>2.143333</td>\n",
       "      <td>0.207846</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>0.041098</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.928603</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.148564</td>\n",
       "      <td>2.290000</td>\n",
       "      <td>0.205801</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.726039</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>1.593333</td>\n",
       "      <td>0.170111</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>0.090331</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.938778</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.747313</td>\n",
       "      <td>0.033935</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>1.463333</td>\n",
       "      <td>0.063509</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>0.069282</td>\n",
       "      <td>1.796667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.752517</td>\n",
       "      <td>0.027829</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.492702</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.951210</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>2.186667</td>\n",
       "      <td>0.194752</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>0.180710</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.720451</td>\n",
       "      <td>0.031690</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.871517</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>2.573333</td>\n",
       "      <td>0.212475</td>\n",
       "      <td>3.016667</td>\n",
       "      <td>0.372709</td>\n",
       "      <td>2.676667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.721619</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.028340</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.528167</td>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>1.976667</td>\n",
       "      <td>0.222073</td>\n",
       "      <td>1.673333</td>\n",
       "      <td>0.127017</td>\n",
       "      <td>1.623333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.929889</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.737396</td>\n",
       "      <td>0.055224</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.406690</td>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.910524</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.395182</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>0.653154</td>\n",
       "      <td>2.343333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.727884</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.715053</td>\n",
       "      <td>0.041852</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.252796</td>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>2.654658</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>0.296180</td>\n",
       "      <td>1.490000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.457889</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.663574</td>\n",
       "      <td>0.037250</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinyllama-1.1b-chat-v1.0.Q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.041361</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>2.340000</td>\n",
       "      <td>0.333174</td>\n",
       "      <td>0.363333</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028318</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.564932</td>\n",
       "      <td>0.044756</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.046111</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>1.443333</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.708830</td>\n",
       "      <td>0.019533</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.396667</td>\n",
       "      <td>0.135995</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737850</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              prompt_id  \\\n",
       "                                                                                                                          \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "\n",
       "                                                                                                              citations/ais_recall  \\\n",
       "                                                                                                                              mean   \n",
       "llm                             temperature nli                     ellm                     sim                                     \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.604452   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.737556   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.653500   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.733013   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.691944   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.492702   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.575644   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.528167   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.406690   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.252796   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.041361   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.006667   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.005000   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.084171   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.072604   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.061199   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.045401   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.049556   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.060547   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.036560   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.095486   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.090558   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.030503   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.010585   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                              citations/ais_precision  \\\n",
       "                                                                                                                                 mean   \n",
       "llm                             temperature nli                     ellm                     sim                                        \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.921198   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.995833   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.928603   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.985000   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.955556   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.951210   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.871517   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.976111   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.910524   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.578455   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.125000   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.046111   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.010000   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.053556   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.002887   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.029692   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017802   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.022033   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.038350   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.026943   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.068665   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.069580   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.031754   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.009623   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                              citations/n_sentences  \\\n",
       "                                                                                                                               mean   \n",
       "llm                             temperature nli                     ellm                     sim                                      \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.746667   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.020000   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.100000   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.593333   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.463333   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.186667   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.573333   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.976667   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              3.280000   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              8.400000   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.340000   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.443333   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.396667   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.294585   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.214022   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.148564   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.170111   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.063509   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.194752   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.212475   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.222073   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.395182   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  2.654658   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.333174   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040415   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.135995   \n",
       "\n",
       "                                                                                                              citations/n_total_citations  \\\n",
       "                                                                                                                                     mean   \n",
       "llm                             temperature nli                     ellm                     sim                                            \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.893333   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.143333   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.290000   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.790000   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.880000   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.040000   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    3.016667   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.673333   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.570000   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.633333   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    0.363333   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    0.113333   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    0.030000   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.438508   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.207846   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.205801   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.090331   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.069282   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.180710   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.372709   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.127017   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.653154   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.296180   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.075056   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034641   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                              citations/n_correct_citations  \\\n",
       "                                                                                                                                       mean   \n",
       "llm                             temperature nli                     ellm                     sim                                              \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.696667   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.130000   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.120000   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.760000   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.796667   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.910000   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.676667   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.623333   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.343333   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.490000   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.370000   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.076667   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.030000   \n",
       "\n",
       "                                                                                                               ...  \\\n",
       "                                                                                                               ...   \n",
       "llm                             temperature nli                     ellm                     sim               ...   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "\n",
       "                                                                                                              correctness/answer_overlap  \\\n",
       "                                                                                                                                     std   \n",
       "llm                             temperature nli                     ellm                     sim                                           \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.007698   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.012990   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.001443   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.007661   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.020651   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.000000   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.014915   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.020207   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.028674   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.012317   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.028318   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.038105   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.014434   \n",
       "\n",
       "                                                                                                              correctness/answer_entail  \\\n",
       "                                                                                                                                   mean   \n",
       "llm                             temperature nli                     ellm                     sim                                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.856667   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.910000   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.896667   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.900000   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.873333   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.903333   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.886667   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.893333   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.866667   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.780000   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.616667   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.670000   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.826667   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.011547   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.011547   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.011547   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.046188   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.057735   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040415   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "\n",
       "                                                                                                              correctness/citations_recall  \\\n",
       "                                                                                                                                      mean   \n",
       "llm                             temperature nli                     ellm                     sim                                             \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.871667   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.853333   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.825000   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.795000   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.785000   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.753333   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.751667   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.735000   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.626667   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.451667   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.051667   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.033333   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.010000   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.046188   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034641   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.028868   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.025981   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.051962   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.080056   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.051188   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.002887   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                              correctness/citations_precision  \\\n",
       "                                                                                                                                         mean   \n",
       "llm                             temperature nli                     ellm                     sim                                                \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.821722   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.941667   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.875556   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.938778   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.907556   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.907556   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.721619   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.929889   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.727884   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.457889   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.036111   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.042778   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.006667   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.066027   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023671   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.037528   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.010585   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.009623   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.018283   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.050125   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023286   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.088494   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.064275   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.006736   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.006736   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                              quality/answer_relevance  \\\n",
       "                                                                                                                                  mean   \n",
       "llm                             temperature nli                     ellm                     sim                                         \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.711417   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.751901   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.726039   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.747313   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.752517   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.720451   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.720431   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.737396   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.715053   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.663574   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.564932   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.708830   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.737850   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.048184   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.041098   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.030875   \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.033935   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.027829   \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.031690   \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.028340   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.055224   \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.041852   \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.037250   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.044756   \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.019533   \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.027130   \n",
       "\n",
       "                                                                                                              n_questions  \n",
       "                                                                                                                           \n",
       "llm                             temperature nli                     ellm                     sim                           \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "gpt-4-turbo                     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Meta-Llama-3-8B-Instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Mistral-7B-Instruct-v0.2        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "zephyr-7b-beta                  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Phi-3-mini-4k-instruct          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "gemma-1.1-2b-it                 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Mistral-7B-Instruct-v0.1        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "\n",
       "[13 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Evaluation results\"))\n",
    "eval_display = eval_results[eval_results.index.get_level_values(\"prompt_id\") == \"1\"]\n",
    "eval_display = eval_display[eval_display.index.get_level_values(\"temperature\") == \"0.1\"]\n",
    "eval_display = remove_index(eval_display, \"prompt_id\")\n",
    "eval_display = eval_display.sort_values(by=(\"correctness/citations_recall\", \"mean\"), ascending=False)\n",
    "eval_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mixtral-8x7b-instruct-v0.1.Q8_0</th>\n",
       "      <td>0.604452</td>\n",
       "      <td>0.084171</td>\n",
       "      <td>0.921198</td>\n",
       "      <td>0.053556</td>\n",
       "      <td>0.882598</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.821722</td>\n",
       "      <td>0.066027</td>\n",
       "      <td>0.711417</td>\n",
       "      <td>0.048184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.737556</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.928603</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.909923</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.726039</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.877302</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.938778</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.747313</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.865923</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.752517</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.492702</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.951210</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.720451</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.871517</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.872812</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.721619</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.528167</td>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.867315</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.929889</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.737396</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.406690</td>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.910524</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.853718</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.727884</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.715053</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.252796</td>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.711068</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.457889</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.663574</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinyllama-1.1b-chat-v1.0.Q8_0</th>\n",
       "      <td>0.041361</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>0.566297</td>\n",
       "      <td>0.028318</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.564932</td>\n",
       "      <td>0.044756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.046111</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.630654</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.708830</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790410</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737850</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                citations/ais_recall            \\\n",
       "                                                mean       std   \n",
       "llm                                                              \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0             0.604452  0.084171   \n",
       "gpt-3.5-turbo-0125                          0.737556  0.072604   \n",
       "Mixtral-8x7B-Instruct-v0.1                  0.653500  0.061199   \n",
       "gpt-4-turbo                                 0.733013  0.045401   \n",
       "Meta-Llama-3-70B-Instruct                   0.691944  0.049556   \n",
       "Meta-Llama-3-8B-Instruct                    0.492702  0.060547   \n",
       "Mistral-7B-Instruct-v0.2                    0.575644  0.036560   \n",
       "qwen1_5-110b-chat                           0.528167  0.095486   \n",
       "zephyr-7b-beta                              0.406690  0.090558   \n",
       "Phi-3-mini-4k-instruct                      0.252796  0.030503   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0               0.041361  0.010585   \n",
       "gemma-1.1-2b-it                             0.006667  0.005774   \n",
       "Mistral-7B-Instruct-v0.1                    0.005000  0.000000   \n",
       "\n",
       "                                citations/ais_precision            \\\n",
       "                                                   mean       std   \n",
       "llm                                                                 \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0                0.921198  0.053556   \n",
       "gpt-3.5-turbo-0125                             0.995833  0.002887   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.928603  0.029692   \n",
       "gpt-4-turbo                                    0.985000  0.005774   \n",
       "Meta-Llama-3-70B-Instruct                      0.955556  0.017802   \n",
       "Meta-Llama-3-8B-Instruct                       0.951210  0.022033   \n",
       "Mistral-7B-Instruct-v0.2                       0.871517  0.038350   \n",
       "qwen1_5-110b-chat                              0.976111  0.026943   \n",
       "zephyr-7b-beta                                 0.910524  0.068665   \n",
       "Phi-3-mini-4k-instruct                         0.578455  0.069580   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                  0.125000  0.031754   \n",
       "gemma-1.1-2b-it                                0.046111  0.009623   \n",
       "Mistral-7B-Instruct-v0.1                       0.010000  0.000000   \n",
       "\n",
       "                                correctness/answer_overlap            \\\n",
       "                                                      mean       std   \n",
       "llm                                                                    \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0                   0.882598  0.007698   \n",
       "gpt-3.5-turbo-0125                                0.884244  0.012990   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.909923  0.001443   \n",
       "gpt-4-turbo                                       0.877302  0.007661   \n",
       "Meta-Llama-3-70B-Instruct                         0.865923  0.020651   \n",
       "Meta-Llama-3-8B-Instruct                          0.917846  0.000000   \n",
       "Mistral-7B-Instruct-v0.2                          0.872812  0.014915   \n",
       "qwen1_5-110b-chat                                 0.867315  0.020207   \n",
       "zephyr-7b-beta                                    0.853718  0.028674   \n",
       "Phi-3-mini-4k-instruct                            0.711068  0.012317   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                     0.566297  0.028318   \n",
       "gemma-1.1-2b-it                                   0.630654  0.038105   \n",
       "Mistral-7B-Instruct-v0.1                          0.790410  0.014434   \n",
       "\n",
       "                                correctness/answer_entail            \\\n",
       "                                                     mean       std   \n",
       "llm                                                                   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0                  0.856667  0.023094   \n",
       "gpt-3.5-turbo-0125                               0.910000  0.011547   \n",
       "Mixtral-8x7B-Instruct-v0.1                       0.896667  0.011547   \n",
       "gpt-4-turbo                                      0.900000  0.011547   \n",
       "Meta-Llama-3-70B-Instruct                        0.873333  0.017321   \n",
       "Meta-Llama-3-8B-Instruct                         0.903333  0.005774   \n",
       "Mistral-7B-Instruct-v0.2                         0.886667  0.017321   \n",
       "qwen1_5-110b-chat                                0.893333  0.017321   \n",
       "zephyr-7b-beta                                   0.866667  0.046188   \n",
       "Phi-3-mini-4k-instruct                           0.780000  0.023094   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                    0.616667  0.057735   \n",
       "gemma-1.1-2b-it                                  0.670000  0.040415   \n",
       "Mistral-7B-Instruct-v0.1                         0.826667  0.017321   \n",
       "\n",
       "                                correctness/citations_recall            \\\n",
       "                                                        mean       std   \n",
       "llm                                                                      \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0                     0.871667  0.046188   \n",
       "gpt-3.5-turbo-0125                                  0.853333  0.023094   \n",
       "Mixtral-8x7B-Instruct-v0.1                          0.825000  0.034641   \n",
       "gpt-4-turbo                                         0.795000  0.028868   \n",
       "Meta-Llama-3-70B-Instruct                           0.785000  0.017321   \n",
       "Meta-Llama-3-8B-Instruct                            0.753333  0.023094   \n",
       "Mistral-7B-Instruct-v0.2                            0.751667  0.025981   \n",
       "qwen1_5-110b-chat                                   0.735000  0.051962   \n",
       "zephyr-7b-beta                                      0.626667  0.080056   \n",
       "Phi-3-mini-4k-instruct                              0.451667  0.051188   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                       0.051667  0.002887   \n",
       "gemma-1.1-2b-it                                     0.033333  0.005774   \n",
       "Mistral-7B-Instruct-v0.1                            0.010000  0.000000   \n",
       "\n",
       "                                correctness/citations_precision            \\\n",
       "                                                           mean       std   \n",
       "llm                                                                         \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0                        0.821722  0.066027   \n",
       "gpt-3.5-turbo-0125                                     0.941667  0.023671   \n",
       "Mixtral-8x7B-Instruct-v0.1                             0.875556  0.037528   \n",
       "gpt-4-turbo                                            0.938778  0.010585   \n",
       "Meta-Llama-3-70B-Instruct                              0.907556  0.009623   \n",
       "Meta-Llama-3-8B-Instruct                               0.907556  0.018283   \n",
       "Mistral-7B-Instruct-v0.2                               0.721619  0.050125   \n",
       "qwen1_5-110b-chat                                      0.929889  0.023286   \n",
       "zephyr-7b-beta                                         0.727884  0.088494   \n",
       "Phi-3-mini-4k-instruct                                 0.457889  0.064275   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                          0.036111  0.006736   \n",
       "gemma-1.1-2b-it                                        0.042778  0.006736   \n",
       "Mistral-7B-Instruct-v0.1                               0.006667  0.000000   \n",
       "\n",
       "                                quality/answer_relevance            \n",
       "                                                    mean       std  \n",
       "llm                                                                 \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0                 0.711417  0.048184  \n",
       "gpt-3.5-turbo-0125                              0.751901  0.041098  \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.726039  0.030875  \n",
       "gpt-4-turbo                                     0.747313  0.033935  \n",
       "Meta-Llama-3-70B-Instruct                       0.752517  0.027829  \n",
       "Meta-Llama-3-8B-Instruct                        0.720451  0.031690  \n",
       "Mistral-7B-Instruct-v0.2                        0.720431  0.028340  \n",
       "qwen1_5-110b-chat                               0.737396  0.055224  \n",
       "zephyr-7b-beta                                  0.715053  0.041852  \n",
       "Phi-3-mini-4k-instruct                          0.663574  0.037250  \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                   0.564932  0.044756  \n",
       "gemma-1.1-2b-it                                 0.708830  0.019533  \n",
       "Mistral-7B-Instruct-v0.1                        0.737850  0.027130  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_cleaned_results(short_eval_display):\n",
    "    short_eval_display = remove_index(short_eval_display, \"temperature\")\n",
    "    short_eval_display = remove_index(short_eval_display, \"nli\")\n",
    "    short_eval_display = remove_index(short_eval_display, \"ellm\")\n",
    "    short_eval_display = remove_index(short_eval_display, \"sim\")\n",
    "    important_columns = [\"citations/ais_recall\", \"citations/ais_precision\", \"correctness/answer_overlap\", \"correctness/answer_entail\", \"correctness/citations_recall\", \"correctness/citations_precision\", \"quality/answer_relevance\"]\n",
    "    short_eval_display = short_eval_display[important_columns]\n",
    "    return short_eval_display\n",
    "\n",
    "\n",
    "show_cleaned_results(eval_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Training results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_sentences</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_total_citations</th>\n",
       "      <th>citations/n_correct_citations</th>\n",
       "      <th>...</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "      <th>n_questions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>ellm</th>\n",
       "      <th>sim</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mixtral-8x7b-instruct-v0.1.Q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.62231</td>\n",
       "      <td>0.075736</td>\n",
       "      <td>0.901109</td>\n",
       "      <td>0.037999</td>\n",
       "      <td>2.654258</td>\n",
       "      <td>0.295822</td>\n",
       "      <td>3.021252</td>\n",
       "      <td>0.412071</td>\n",
       "      <td>2.755955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019962</td>\n",
       "      <td>0.875624</td>\n",
       "      <td>0.022234</td>\n",
       "      <td>0.844066</td>\n",
       "      <td>0.040573</td>\n",
       "      <td>0.798038</td>\n",
       "      <td>0.049704</td>\n",
       "      <td>0.724411</td>\n",
       "      <td>0.038496</td>\n",
       "      <td>4674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.56492</td>\n",
       "      <td>0.117130</td>\n",
       "      <td>0.964120</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>1.936333</td>\n",
       "      <td>0.256917</td>\n",
       "      <td>1.789667</td>\n",
       "      <td>0.213576</td>\n",
       "      <td>1.687333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022317</td>\n",
       "      <td>0.874333</td>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.737167</td>\n",
       "      <td>0.053828</td>\n",
       "      <td>0.909575</td>\n",
       "      <td>0.036772</td>\n",
       "      <td>0.725493</td>\n",
       "      <td>0.043379</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              prompt_id  \\\n",
       "                                                                                                                          \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "\n",
       "                                                                                                              citations/ais_recall  \\\n",
       "                                                                                                                              mean   \n",
       "llm                             temperature nli                     ellm                     sim                                     \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              0.62231   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              0.56492   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.075736   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.117130   \n",
       "\n",
       "                                                                                                              citations/ais_precision  \\\n",
       "                                                                                                                                 mean   \n",
       "llm                             temperature nli                     ellm                     sim                                        \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.901109   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.964120   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.037999   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.030177   \n",
       "\n",
       "                                                                                                              citations/n_sentences  \\\n",
       "                                                                                                                               mean   \n",
       "llm                             temperature nli                     ellm                     sim                                      \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.654258   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.936333   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.295822   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.256917   \n",
       "\n",
       "                                                                                                              citations/n_total_citations  \\\n",
       "                                                                                                                                     mean   \n",
       "llm                             temperature nli                     ellm                     sim                                            \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    3.021252   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.789667   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.412071   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.213576   \n",
       "\n",
       "                                                                                                              citations/n_correct_citations  \\\n",
       "                                                                                                                                       mean   \n",
       "llm                             temperature nli                     ellm                     sim                                              \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.755955   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.687333   \n",
       "\n",
       "                                                                                                               ...  \\\n",
       "                                                                                                               ...   \n",
       "llm                             temperature nli                     ellm                     sim               ...   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "\n",
       "                                                                                                              correctness/answer_overlap  \\\n",
       "                                                                                                                                     std   \n",
       "llm                             temperature nli                     ellm                     sim                                           \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.019962   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.022317   \n",
       "\n",
       "                                                                                                              correctness/answer_entail  \\\n",
       "                                                                                                                                   mean   \n",
       "llm                             temperature nli                     ellm                     sim                                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.875624   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.874333   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.022234   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.025403   \n",
       "\n",
       "                                                                                                              correctness/citations_recall  \\\n",
       "                                                                                                                                      mean   \n",
       "llm                             temperature nli                     ellm                     sim                                             \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.844066   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.737167   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040573   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.053828   \n",
       "\n",
       "                                                                                                              correctness/citations_precision  \\\n",
       "                                                                                                                                         mean   \n",
       "llm                             temperature nli                     ellm                     sim                                                \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.798038   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.909575   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.049704   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.036772   \n",
       "\n",
       "                                                                                                              quality/answer_relevance  \\\n",
       "                                                                                                                                  mean   \n",
       "llm                             temperature nli                     ellm                     sim                                         \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.724411   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.725493   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.038496   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.043379   \n",
       "\n",
       "                                                                                                              n_questions  \n",
       "                                                                                                                           \n",
       "llm                             temperature nli                     ellm                     sim                           \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2        4674  \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2        1000  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Training results\"))\n",
    "train_display = remove_index(train_results, \"prompt_id\")\n",
    "train_display"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
