{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tdolega/miniconda/envs/p311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from common.consts import RESULTS_DIR, EVAL_SIZE\n",
    "from common.utils import filename_to_obj, remove_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [02:00<00:00,  2.94s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_idx</th>\n",
       "      <th>question_id</th>\n",
       "      <th>llm</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>ellm</th>\n",
       "      <th>sim</th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>citations/supported</th>\n",
       "      <th>citations/citations</th>\n",
       "      <th>citations/correct_citations</th>\n",
       "      <th>citations/out_of_range</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "      <th>quality/new_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "      <td>[[], [], [3], [4]]</td>\n",
       "      <td>[[], [], [True], [True]]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.649022</td>\n",
       "      <td>Which of P.K. Subban's brothers was drafted fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.875</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[[], [], [3], [4], [6], [], [], [], [], [4, 5]...</td>\n",
       "      <td>[[], [], [True], [True], [True], [], [], [], [...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.757470</td>\n",
       "      <td>Who are the two professional hockey players, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[[], [], [4], [6], [], []]</td>\n",
       "      <td>[[], [], [True], [True], [], []]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.770844</td>\n",
       "      <td>Who are the two professional hockey players, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5a761900554299109176e648</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[[1]]</td>\n",
       "      <td>[[True]]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.450042</td>\n",
       "      <td>What is the name of the intelligence firm that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5a761900554299109176e648</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[[0, 1], [0, 1]]</td>\n",
       "      <td>[[True, True], [True, True]]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.772082</td>\n",
       "      <td>What is the name of the lobbying group founded...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_idx               question_id                       llm prompt_id  \\\n",
       "0             0  5abab42e55429955dce3eed2  Mistral-7B-Instruct-v0.2         1   \n",
       "1             0  5abab42e55429955dce3eed2  Mistral-7B-Instruct-v0.2         1   \n",
       "2             0  5abab42e55429955dce3eed2  Mistral-7B-Instruct-v0.2         1   \n",
       "3             1  5a761900554299109176e648  Mistral-7B-Instruct-v0.2         1   \n",
       "4             1  5a761900554299109176e648  Mistral-7B-Instruct-v0.2         1   \n",
       "\n",
       "  temperature                      nli                      ellm  \\\n",
       "0         0.8  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "1         0.8  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "2         0.8  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "3         0.8  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "4         0.8  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "\n",
       "                sim  citations/ais_recall  citations/ais_precision  ...  \\\n",
       "0  all-MiniLM-L6-v2              0.250000                    1.000  ...   \n",
       "1  all-MiniLM-L6-v2              0.083333                    0.875  ...   \n",
       "2  all-MiniLM-L6-v2              0.000000                    1.000  ...   \n",
       "3  all-MiniLM-L6-v2              1.000000                    1.000  ...   \n",
       "4  all-MiniLM-L6-v2              1.000000                    1.000  ...   \n",
       "\n",
       "                    citations/supported  \\\n",
       "0                          [0, 0, 0, 1]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "2                    [0, 0, 0, 0, 0, 0]   \n",
       "3                                   [1]   \n",
       "4                                [1, 1]   \n",
       "\n",
       "                                 citations/citations  \\\n",
       "0                                 [[], [], [3], [4]]   \n",
       "1  [[], [], [3], [4], [6], [], [], [], [], [4, 5]...   \n",
       "2                         [[], [], [4], [6], [], []]   \n",
       "3                                              [[1]]   \n",
       "4                                   [[0, 1], [0, 1]]   \n",
       "\n",
       "                         citations/correct_citations  \\\n",
       "0                           [[], [], [True], [True]]   \n",
       "1  [[], [], [True], [True], [True], [], [], [], [...   \n",
       "2                   [[], [], [True], [True], [], []]   \n",
       "3                                           [[True]]   \n",
       "4                       [[True, True], [True, True]]   \n",
       "\n",
       "                 citations/out_of_range  correctness/answer_overlap  \\\n",
       "0                          [0, 0, 0, 0]                         1.0   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                         1.0   \n",
       "2                    [0, 0, 0, 0, 0, 0]                         0.5   \n",
       "3                                   [0]                         1.0   \n",
       "4                                [0, 0]                         1.0   \n",
       "\n",
       "  correctness/answer_entail correctness/citations_recall  \\\n",
       "0                       1.0                          1.0   \n",
       "1                       0.0                          1.0   \n",
       "2                       0.0                          0.5   \n",
       "3                       1.0                          0.5   \n",
       "4                       1.0                          1.0   \n",
       "\n",
       "  correctness/citations_precision quality/answer_relevance  \\\n",
       "0                             1.0                 0.649022   \n",
       "1                             0.5                 0.757470   \n",
       "2                             0.5                 0.770844   \n",
       "3                             1.0                 0.450042   \n",
       "4                             1.0                 0.772082   \n",
       "\n",
       "                                quality/new_question  \n",
       "0  Which of P.K. Subban's brothers was drafted fi...  \n",
       "1  Who are the two professional hockey players, b...  \n",
       "2  Who are the two professional hockey players, b...  \n",
       "3  What is the name of the intelligence firm that...  \n",
       "4  What is the name of the lobbying group founded...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def results_as_pandas(filename):\n",
    "    path = os.path.join(RESULTS_DIR, filename)\n",
    "    data = pd.read_json(path, lines=True)\n",
    "\n",
    "    if len(data) == 0:\n",
    "        print(f\"empty file: {filename}\")\n",
    "        return data\n",
    "\n",
    "    params = filename_to_obj(filename)\n",
    "    for k, v in params.items():\n",
    "        data[k] = v\n",
    "\n",
    "    data = data.explode(\"evaluations\")\n",
    "    data = data.rename_axis(\"question_idx\").reset_index()\n",
    "\n",
    "    data = pd.concat([data, data[\"evaluations\"].apply(pd.Series)], axis=1)\n",
    "    evaluation_keys = data[\"evaluations\"].apply(pd.Series).columns\n",
    "    for col in evaluation_keys:\n",
    "        data = pd.concat([data, data[col].apply(pd.Series).add_prefix(f\"{col}/\")], axis=1)\n",
    "        data = data.drop(columns=col)\n",
    "    data = data.drop(columns=[\"evaluations\"])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "files = os.listdir(RESULTS_DIR)\n",
    "params_names = list(filename_to_obj(files[0]).keys())\n",
    "all_results = pd.concat([results_as_pandas(f) for f in tqdm(files)])\n",
    "all_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns: ['citations/sentences', 'citations/citations', 'quality/new_question', 'citations/correct_citations', 'citations/out_of_range', 'citations/supported']\n"
     ]
    }
   ],
   "source": [
    "all_obj_cols = all_results.select_dtypes(include=[\"object\"]).columns\n",
    "drop_obj_cols = list(set(all_obj_cols) - set(params_names))\n",
    "drop_obj_cols.remove(\"question_id\")\n",
    "print(f\"Dropping columns: {drop_obj_cols}\")\n",
    "all_num_results = all_results.drop(columns=drop_obj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_split = all_num_results[all_num_results[\"question_idx\"] < EVAL_SIZE]\n",
    "train_split = all_num_results[all_num_results[\"question_idx\"] >= EVAL_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGG_FUNC = \"max\"\n",
    "\n",
    "\n",
    "def aggregate(split):\n",
    "    split = split.drop(columns=[\"question_idx\"])\n",
    "    results_with_std_for_each_question = split.groupby([*params_names, \"question_id\"]).agg([AGG_FUNC, \"std\"])\n",
    "    results_for_each_model = results_with_std_for_each_question.groupby(params_names)\n",
    "    results = results_for_each_model.mean()\n",
    "    results[\"n_questions\"] = results_for_each_model.size()\n",
    "    return results\n",
    "\n",
    "\n",
    "eval_results = aggregate(eval_split)\n",
    "train_results = aggregate(train_split)\n",
    "\n",
    "if eval_results[\"n_questions\"].nunique() != 1:\n",
    "    print(\"Warning: not all rows in evaluation have the same number of examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Prompts comparison"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.606238</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.901424</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.883923</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.762833</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.743680</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.559952</td>\n",
       "      <td>0.066146</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.034978</td>\n",
       "      <td>0.877269</td>\n",
       "      <td>0.027905</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.043301</td>\n",
       "      <td>0.705500</td>\n",
       "      <td>0.046655</td>\n",
       "      <td>0.729335</td>\n",
       "      <td>0.030174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.621500</td>\n",
       "      <td>0.045033</td>\n",
       "      <td>0.913500</td>\n",
       "      <td>0.024787</td>\n",
       "      <td>0.869269</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.690167</td>\n",
       "      <td>0.042370</td>\n",
       "      <td>0.681964</td>\n",
       "      <td>0.027177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.050999</td>\n",
       "      <td>0.864286</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.862603</td>\n",
       "      <td>0.024249</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>0.719024</td>\n",
       "      <td>0.036335</td>\n",
       "      <td>0.701345</td>\n",
       "      <td>0.026870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   citations/ais_recall            \\\n",
       "                                                    max       std   \n",
       "llm                      prompt_id                                  \n",
       "Mistral-7B-Instruct-v0.2 1                     0.606238  0.036560   \n",
       "                         2                     0.559952  0.066146   \n",
       "                         3                     0.621500  0.045033   \n",
       "                         4                     0.550000  0.050999   \n",
       "\n",
       "                                   citations/ais_precision            \\\n",
       "                                                       max       std   \n",
       "llm                      prompt_id                                     \n",
       "Mistral-7B-Instruct-v0.2 1                        0.901424  0.038350   \n",
       "                         2                        0.887500  0.034978   \n",
       "                         3                        0.913500  0.024787   \n",
       "                         4                        0.864286  0.044519   \n",
       "\n",
       "                                   correctness/answer_overlap            \\\n",
       "                                                          max       std   \n",
       "llm                      prompt_id                                        \n",
       "Mistral-7B-Instruct-v0.2 1                           0.883923  0.014915   \n",
       "                         2                           0.877269  0.027905   \n",
       "                         3                           0.869269  0.017321   \n",
       "                         4                           0.862603  0.024249   \n",
       "\n",
       "                                   correctness/answer_entail            \\\n",
       "                                                         max       std   \n",
       "llm                      prompt_id                                       \n",
       "Mistral-7B-Instruct-v0.2 1                              0.90  0.017321   \n",
       "                         2                              0.88  0.023094   \n",
       "                         3                              0.87  0.011547   \n",
       "                         4                              0.85  0.011547   \n",
       "\n",
       "                                   correctness/citations_recall            \\\n",
       "                                                            max       std   \n",
       "llm                      prompt_id                                          \n",
       "Mistral-7B-Instruct-v0.2 1                                0.775  0.025981   \n",
       "                         2                                0.800  0.043301   \n",
       "                         3                                0.690  0.034641   \n",
       "                         4                                0.625  0.031754   \n",
       "\n",
       "                                   correctness/citations_precision            \\\n",
       "                                                               max       std   \n",
       "llm                      prompt_id                                             \n",
       "Mistral-7B-Instruct-v0.2 1                                0.762833  0.050125   \n",
       "                         2                                0.705500  0.046655   \n",
       "                         3                                0.690167  0.042370   \n",
       "                         4                                0.719024  0.036335   \n",
       "\n",
       "                                   quality/answer_relevance            \n",
       "                                                        max       std  \n",
       "llm                      prompt_id                                     \n",
       "Mistral-7B-Instruct-v0.2 1                         0.743680  0.028340  \n",
       "                         2                         0.729335  0.030174  \n",
       "                         3                         0.681964  0.027177  \n",
       "                         4                         0.701345  0.026870  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Prompts comparison\"))\n",
    "parameter_results = eval_results[eval_results.index.get_level_values(\"llm\") == \"Mistral-7B-Instruct-v0.2\"]\n",
    "\n",
    "\n",
    "def show_cleaned_results(short_eval_display, keep_index_name=None):\n",
    "    short_eval_display = short_eval_display.copy()\n",
    "    for index_name in [\"temperature\", \"nli\", \"ellm\", \"sim\", \"prompt_id\"]:\n",
    "        if index_name == keep_index_name:\n",
    "            continue\n",
    "        short_eval_display = remove_index(short_eval_display, index_name)\n",
    "    important_columns = [\"citations/ais_recall\", \"citations/ais_precision\", \"correctness/answer_overlap\", \"correctness/answer_entail\", \"correctness/citations_recall\", \"correctness/citations_precision\", \"quality/answer_relevance\"]\n",
    "    short_eval_display = short_eval_display[important_columns]\n",
    "    return short_eval_display\n",
    "\n",
    "\n",
    "show_cleaned_results(parameter_results[parameter_results.index.get_level_values(\"temperature\") == \"0.1\"], keep_index_name=\"prompt_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Temperature comparison"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>temperature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>0.01</th>\n",
       "      <td>0.597643</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>0.901955</td>\n",
       "      <td>0.016922</td>\n",
       "      <td>0.870590</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.761024</td>\n",
       "      <td>0.023419</td>\n",
       "      <td>0.749056</td>\n",
       "      <td>0.015812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.606238</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.901424</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.883923</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.762833</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.743680</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.614048</td>\n",
       "      <td>0.081991</td>\n",
       "      <td>0.918591</td>\n",
       "      <td>0.050804</td>\n",
       "      <td>0.887192</td>\n",
       "      <td>0.029793</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.786190</td>\n",
       "      <td>0.050897</td>\n",
       "      <td>0.754883</td>\n",
       "      <td>0.033120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.638214</td>\n",
       "      <td>0.084729</td>\n",
       "      <td>0.914333</td>\n",
       "      <td>0.066155</td>\n",
       "      <td>0.908923</td>\n",
       "      <td>0.045707</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.059848</td>\n",
       "      <td>0.808857</td>\n",
       "      <td>0.067481</td>\n",
       "      <td>0.765330</td>\n",
       "      <td>0.047856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.717048</td>\n",
       "      <td>0.150051</td>\n",
       "      <td>0.963996</td>\n",
       "      <td>0.108934</td>\n",
       "      <td>0.908923</td>\n",
       "      <td>0.044607</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.096603</td>\n",
       "      <td>0.827857</td>\n",
       "      <td>0.099659</td>\n",
       "      <td>0.767508</td>\n",
       "      <td>0.049850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.144597</td>\n",
       "      <td>0.942603</td>\n",
       "      <td>0.085049</td>\n",
       "      <td>0.910923</td>\n",
       "      <td>0.073768</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.082169</td>\n",
       "      <td>0.830952</td>\n",
       "      <td>0.114113</td>\n",
       "      <td>0.760321</td>\n",
       "      <td>0.059824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.667405</td>\n",
       "      <td>0.168079</td>\n",
       "      <td>0.941042</td>\n",
       "      <td>0.110804</td>\n",
       "      <td>0.886359</td>\n",
       "      <td>0.049038</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.121810</td>\n",
       "      <td>0.841357</td>\n",
       "      <td>0.125848</td>\n",
       "      <td>0.773600</td>\n",
       "      <td>0.064925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.712095</td>\n",
       "      <td>0.182757</td>\n",
       "      <td>0.941048</td>\n",
       "      <td>0.115458</td>\n",
       "      <td>0.905590</td>\n",
       "      <td>0.047054</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.118923</td>\n",
       "      <td>0.843690</td>\n",
       "      <td>0.132095</td>\n",
       "      <td>0.780154</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.693667</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.959667</td>\n",
       "      <td>0.131938</td>\n",
       "      <td>0.914192</td>\n",
       "      <td>0.062564</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.086603</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.119697</td>\n",
       "      <td>0.829690</td>\n",
       "      <td>0.123992</td>\n",
       "      <td>0.792152</td>\n",
       "      <td>0.070362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.750833</td>\n",
       "      <td>0.204617</td>\n",
       "      <td>0.968500</td>\n",
       "      <td>0.127270</td>\n",
       "      <td>0.892859</td>\n",
       "      <td>0.074434</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.149130</td>\n",
       "      <td>0.853524</td>\n",
       "      <td>0.152158</td>\n",
       "      <td>0.765121</td>\n",
       "      <td>0.073964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.730298</td>\n",
       "      <td>0.202885</td>\n",
       "      <td>0.968500</td>\n",
       "      <td>0.139181</td>\n",
       "      <td>0.884769</td>\n",
       "      <td>0.066776</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.063509</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.144130</td>\n",
       "      <td>0.853690</td>\n",
       "      <td>0.164076</td>\n",
       "      <td>0.759617</td>\n",
       "      <td>0.081091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.221513</td>\n",
       "      <td>0.976333</td>\n",
       "      <td>0.156983</td>\n",
       "      <td>0.903282</td>\n",
       "      <td>0.074745</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.069282</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.178205</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.160805</td>\n",
       "      <td>0.769376</td>\n",
       "      <td>0.077673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.259358</td>\n",
       "      <td>0.963143</td>\n",
       "      <td>0.220605</td>\n",
       "      <td>0.878385</td>\n",
       "      <td>0.089997</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.223412</td>\n",
       "      <td>0.842333</td>\n",
       "      <td>0.225945</td>\n",
       "      <td>0.777230</td>\n",
       "      <td>0.089034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5</th>\n",
       "      <td>0.538024</td>\n",
       "      <td>0.262768</td>\n",
       "      <td>0.922635</td>\n",
       "      <td>0.240513</td>\n",
       "      <td>0.876949</td>\n",
       "      <td>0.186147</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.161658</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.283620</td>\n",
       "      <td>0.783833</td>\n",
       "      <td>0.258627</td>\n",
       "      <td>0.796268</td>\n",
       "      <td>0.097187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     citations/ais_recall            \\\n",
       "                                                      max       std   \n",
       "llm                      temperature                                  \n",
       "Mistral-7B-Instruct-v0.2 0.01                    0.597643  0.027143   \n",
       "                         0.1                     0.606238  0.036560   \n",
       "                         0.2                     0.614048  0.081991   \n",
       "                         0.3                     0.638214  0.084729   \n",
       "                         0.4                     0.717048  0.150051   \n",
       "                         0.5                     0.693750  0.144597   \n",
       "                         0.6                     0.667405  0.168079   \n",
       "                         0.7                     0.712095  0.182757   \n",
       "                         0.8                     0.693667  0.195393   \n",
       "                         0.9                     0.750833  0.204617   \n",
       "                         1.0                     0.730298  0.202885   \n",
       "                         1.5                     0.725000  0.221513   \n",
       "                         2.0                     0.702500  0.259358   \n",
       "                         2.5                     0.538024  0.262768   \n",
       "\n",
       "                                     citations/ais_precision            \\\n",
       "                                                         max       std   \n",
       "llm                      temperature                                     \n",
       "Mistral-7B-Instruct-v0.2 0.01                       0.901955  0.016922   \n",
       "                         0.1                        0.901424  0.038350   \n",
       "                         0.2                        0.918591  0.050804   \n",
       "                         0.3                        0.914333  0.066155   \n",
       "                         0.4                        0.963996  0.108934   \n",
       "                         0.5                        0.942603  0.085049   \n",
       "                         0.6                        0.941042  0.110804   \n",
       "                         0.7                        0.941048  0.115458   \n",
       "                         0.8                        0.959667  0.131938   \n",
       "                         0.9                        0.968500  0.127270   \n",
       "                         1.0                        0.968500  0.139181   \n",
       "                         1.5                        0.976333  0.156983   \n",
       "                         2.0                        0.963143  0.220605   \n",
       "                         2.5                        0.922635  0.240513   \n",
       "\n",
       "                                     correctness/answer_overlap            \\\n",
       "                                                            max       std   \n",
       "llm                      temperature                                        \n",
       "Mistral-7B-Instruct-v0.2 0.01                          0.870590  0.012990   \n",
       "                         0.1                           0.883923  0.014915   \n",
       "                         0.2                           0.887192  0.029793   \n",
       "                         0.3                           0.908923  0.045707   \n",
       "                         0.4                           0.908923  0.044607   \n",
       "                         0.5                           0.910923  0.073768   \n",
       "                         0.6                           0.886359  0.049038   \n",
       "                         0.7                           0.905590  0.047054   \n",
       "                         0.8                           0.914192  0.062564   \n",
       "                         0.9                           0.892859  0.074434   \n",
       "                         1.0                           0.884769  0.066776   \n",
       "                         1.5                           0.903282  0.074745   \n",
       "                         2.0                           0.878385  0.089997   \n",
       "                         2.5                           0.876949  0.186147   \n",
       "\n",
       "                                     correctness/answer_entail            \\\n",
       "                                                           max       std   \n",
       "llm                      temperature                                       \n",
       "Mistral-7B-Instruct-v0.2 0.01                             0.90  0.017321   \n",
       "                         0.1                              0.90  0.017321   \n",
       "                         0.2                              0.89  0.005774   \n",
       "                         0.3                              0.90  0.023094   \n",
       "                         0.4                              0.91  0.028868   \n",
       "                         0.5                              0.91  0.034641   \n",
       "                         0.6                              0.90  0.040415   \n",
       "                         0.7                              0.90  0.028868   \n",
       "                         0.8                              0.93  0.086603   \n",
       "                         0.9                              0.90  0.057735   \n",
       "                         1.0                              0.89  0.063509   \n",
       "                         1.5                              0.91  0.069282   \n",
       "                         2.0                              0.89  0.075056   \n",
       "                         2.5                              0.89  0.161658   \n",
       "\n",
       "                                     correctness/citations_recall            \\\n",
       "                                                              max       std   \n",
       "llm                      temperature                                          \n",
       "Mistral-7B-Instruct-v0.2 0.01                               0.770  0.014434   \n",
       "                         0.1                                0.775  0.025981   \n",
       "                         0.2                                0.815  0.051962   \n",
       "                         0.3                                0.835  0.059848   \n",
       "                         0.4                                0.850  0.096603   \n",
       "                         0.5                                0.820  0.082169   \n",
       "                         0.6                                0.855  0.121810   \n",
       "                         0.7                                0.865  0.118923   \n",
       "                         0.8                                0.860  0.119697   \n",
       "                         0.9                                0.875  0.149130   \n",
       "                         1.0                                0.840  0.144130   \n",
       "                         1.5                                0.900  0.178205   \n",
       "                         2.0                                0.945  0.223412   \n",
       "                         2.5                                0.915  0.283620   \n",
       "\n",
       "                                     correctness/citations_precision  \\\n",
       "                                                                 max   \n",
       "llm                      temperature                                   \n",
       "Mistral-7B-Instruct-v0.2 0.01                               0.761024   \n",
       "                         0.1                                0.762833   \n",
       "                         0.2                                0.786190   \n",
       "                         0.3                                0.808857   \n",
       "                         0.4                                0.827857   \n",
       "                         0.5                                0.830952   \n",
       "                         0.6                                0.841357   \n",
       "                         0.7                                0.843690   \n",
       "                         0.8                                0.829690   \n",
       "                         0.9                                0.853524   \n",
       "                         1.0                                0.853690   \n",
       "                         1.5                                0.841000   \n",
       "                         2.0                                0.842333   \n",
       "                         2.5                                0.783833   \n",
       "\n",
       "                                               quality/answer_relevance  \\\n",
       "                                           std                      max   \n",
       "llm                      temperature                                      \n",
       "Mistral-7B-Instruct-v0.2 0.01         0.023419                 0.749056   \n",
       "                         0.1          0.050125                 0.743680   \n",
       "                         0.2          0.050897                 0.754883   \n",
       "                         0.3          0.067481                 0.765330   \n",
       "                         0.4          0.099659                 0.767508   \n",
       "                         0.5          0.114113                 0.760321   \n",
       "                         0.6          0.125848                 0.773600   \n",
       "                         0.7          0.132095                 0.780154   \n",
       "                         0.8          0.123992                 0.792152   \n",
       "                         0.9          0.152158                 0.765121   \n",
       "                         1.0          0.164076                 0.759617   \n",
       "                         1.5          0.160805                 0.769376   \n",
       "                         2.0          0.225945                 0.777230   \n",
       "                         2.5          0.258627                 0.796268   \n",
       "\n",
       "                                                \n",
       "                                           std  \n",
       "llm                      temperature            \n",
       "Mistral-7B-Instruct-v0.2 0.01         0.015812  \n",
       "                         0.1          0.028340  \n",
       "                         0.2          0.033120  \n",
       "                         0.3          0.047856  \n",
       "                         0.4          0.049850  \n",
       "                         0.5          0.059824  \n",
       "                         0.6          0.064925  \n",
       "                         0.7          0.058840  \n",
       "                         0.8          0.070362  \n",
       "                         0.9          0.073964  \n",
       "                         1.0          0.081091  \n",
       "                         1.5          0.077673  \n",
       "                         2.0          0.089034  \n",
       "                         2.5          0.097187  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Temperature comparison\"))\n",
    "show_cleaned_results(parameter_results[parameter_results.index.get_level_values(\"prompt_id\") == \"1\"], keep_index_name=\"temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Evaluation results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_sentences</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_total_citations</th>\n",
       "      <th>citations/n_correct_citations</th>\n",
       "      <th>...</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "      <th>n_questions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>ellm</th>\n",
       "      <th>sim</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.855570</td>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.979417</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1.208135</td>\n",
       "      <td>6.64</td>\n",
       "      <td>1.148101</td>\n",
       "      <td>6.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.780416</td>\n",
       "      <td>0.055383</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.734354</td>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.978560</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>9.28</td>\n",
       "      <td>1.170721</td>\n",
       "      <td>9.81</td>\n",
       "      <td>1.338763</td>\n",
       "      <td>9.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.858667</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.798084</td>\n",
       "      <td>0.071202</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.813959</td>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.984115</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>6.97</td>\n",
       "      <td>1.424317</td>\n",
       "      <td>7.54</td>\n",
       "      <td>1.360671</td>\n",
       "      <td>7.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.918333</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.782177</td>\n",
       "      <td>0.063220</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.769950</td>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.049620</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.022228</td>\n",
       "      <td>9.59</td>\n",
       "      <td>1.261849</td>\n",
       "      <td>8.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.877024</td>\n",
       "      <td>0.135618</td>\n",
       "      <td>0.808191</td>\n",
       "      <td>0.066080</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.975167</td>\n",
       "      <td>0.029156</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.175386</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.232623</td>\n",
       "      <td>2.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045041</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.790450</td>\n",
       "      <td>0.033242</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.082330</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.129697</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.124972</td>\n",
       "      <td>2.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.796144</td>\n",
       "      <td>0.040207</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.864167</td>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.974167</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.261624</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.306084</td>\n",
       "      <td>3.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.936190</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.779305</td>\n",
       "      <td>0.040067</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.801167</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.214022</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.207846</td>\n",
       "      <td>2.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.962333</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.787486</td>\n",
       "      <td>0.041098</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.537167</td>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.873897</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.366975</td>\n",
       "      <td>6.15</td>\n",
       "      <td>1.293896</td>\n",
       "      <td>4.52</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.643667</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.746003</td>\n",
       "      <td>0.059428</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.148564</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.205801</td>\n",
       "      <td>2.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.751501</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.170111</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.090331</td>\n",
       "      <td>1.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.777481</td>\n",
       "      <td>0.033935</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.063509</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.069282</td>\n",
       "      <td>1.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.776388</td>\n",
       "      <td>0.027829</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.607500</td>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.222073</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.127017</td>\n",
       "      <td>1.73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.947333</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.787043</td>\n",
       "      <td>0.055224</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.549357</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.972143</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.194752</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.180710</td>\n",
       "      <td>2.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.748064</td>\n",
       "      <td>0.031690</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.606238</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.901424</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.212475</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.372709</td>\n",
       "      <td>2.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.762833</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.743680</td>\n",
       "      <td>0.028340</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.485310</td>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.977167</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.395182</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.653154</td>\n",
       "      <td>2.97</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.815278</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.751837</td>\n",
       "      <td>0.041852</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.086603</td>\n",
       "      <td>1.61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.754467</td>\n",
       "      <td>0.038641</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.534167</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.069282</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.027321</td>\n",
       "      <td>1.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731615</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.763250</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.102376</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.274993</td>\n",
       "      <td>1.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.691690</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.679352</td>\n",
       "      <td>0.046987</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.291167</td>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.227846</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.217846</td>\n",
       "      <td>1.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.797259</td>\n",
       "      <td>0.034364</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.161244</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.150111</td>\n",
       "      <td>1.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.753667</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.043209</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.281933</td>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.640500</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>10.63</td>\n",
       "      <td>2.654658</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.296180</td>\n",
       "      <td>1.73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.513667</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.695867</td>\n",
       "      <td>0.037250</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.725417</td>\n",
       "      <td>0.019533</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.135995</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.760995</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                         prompt_id  \\\n",
       "                                                                                                                     \n",
       "llm                        temperature nli                     ellm                     sim                          \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         0   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         4   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         4   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "\n",
       "                                                                                                         citations/ais_recall  \\\n",
       "                                                                                                                          max   \n",
       "llm                        temperature nli                     ellm                     sim                                     \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.855570   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.734354   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.813959   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.769950   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.875667   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.854167   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.864167   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.801167   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.537167   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.707500   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.775000   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.736667   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.607500   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.549357   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.606238   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.485310   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.676667   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.534167   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.457500   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.291167   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.483333   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.281933   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.010000   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.005000   \n",
       "\n",
       "                                                                                                                    \\\n",
       "                                                                                                               std   \n",
       "llm                        temperature nli                     ellm                     sim                          \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.134646   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.100349   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.146211   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.120419   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.075100   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.082330   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.060520   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.072604   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.134222   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.061199   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.045401   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.049556   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.095486   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.060547   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.036560   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.090558   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.042339   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.031856   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.060382   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.063671   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.122999   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.030503   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                         citations/ais_precision  \\\n",
       "                                                                                                                             max   \n",
       "llm                        temperature nli                     ellm                     sim                                        \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.979417   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.978560   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.984115   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.984613   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.975167   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.970000   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.974167   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.997500   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.873897   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.957500   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.990000   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.970000   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.993333   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.972143   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.901424   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.977167   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.983333   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.996667   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.763250   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.910000   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.850000   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.640500   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.055000   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.010000   \n",
       "\n",
       "                                                                                                                    \\\n",
       "                                                                                                               std   \n",
       "llm                        temperature nli                     ellm                     sim                          \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.031338   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.030020   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.032981   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.049620   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.029156   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023575   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.021027   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.002887   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.101052   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.029692   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017802   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.026943   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.022033   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.038350   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.068665   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.008660   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.002887   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.061399   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.057158   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.082995   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.069580   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.009623   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                         citations/n_sentences  \\\n",
       "                                                                                                                           max   \n",
       "llm                        temperature nli                     ellm                     sim                                      \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  5.94   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  9.28   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  6.97   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  8.44   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  1.69   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  1.70   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  2.47   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  2.21   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  2.35   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  2.22   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  1.77   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  1.51   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  2.18   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  2.37   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  2.76   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  3.66   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  1.47   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  1.67   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  2.18   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  2.62   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  1.47   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 10.63   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  1.48   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  1.53   \n",
       "\n",
       "                                                                                                                    \\\n",
       "                                                                                                               std   \n",
       "llm                        temperature nli                     ellm                     sim                          \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.208135   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.170721   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.424317   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.022228   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.175386   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.129697   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.261624   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.214022   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.366975   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.148564   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.170111   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.063509   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.222073   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.194752   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.212475   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.395182   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.075056   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.069282   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.102376   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.227846   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.161244   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  2.654658   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040415   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.135995   \n",
       "\n",
       "                                                                                                         citations/n_total_citations  \\\n",
       "                                                                                                                                 max   \n",
       "llm                        temperature nli                     ellm                     sim                                            \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        6.64   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        9.81   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        7.54   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        9.59   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        2.61   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        2.33   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        3.25   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        2.32   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        6.15   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        2.47   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        1.87   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        1.94   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        1.78   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        2.21   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        3.36   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        3.21   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        1.67   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        1.42   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        2.01   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        1.49   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        1.50   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        1.88   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.15   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.03   \n",
       "\n",
       "                                                                                                                    \\\n",
       "                                                                                                               std   \n",
       "llm                        temperature nli                     ellm                     sim                          \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.148101   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.338763   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.360671   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.261849   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.232623   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.124972   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.306084   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.207846   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.293896   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.205801   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.090331   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.069282   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.127017   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.180710   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.372709   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.653154   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.086603   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.027321   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.274993   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.217846   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.150111   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.296180   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034641   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                         citations/n_correct_citations  \\\n",
       "                                                                                                                                   max   \n",
       "llm                        temperature nli                     ellm                     sim                                              \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          6.35   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          9.17   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          7.17   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          8.93   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          2.48   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          2.21   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          3.05   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          2.30   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          4.52   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          2.28   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          1.85   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          1.86   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          1.73   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          2.07   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          2.94   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          2.97   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          1.61   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          1.41   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          1.92   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          1.42   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          1.33   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          1.73   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          0.10   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                          0.03   \n",
       "\n",
       "                                                                                                          ...  \\\n",
       "                                                                                                          ...   \n",
       "llm                        temperature nli                     ellm                     sim               ...   \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "\n",
       "                                                                                                         correctness/answer_overlap  \\\n",
       "                                                                                                                                std   \n",
       "llm                        temperature nli                     ellm                     sim                                           \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.017918   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.013723   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.030777   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.015031   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.045041   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.031858   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.012892   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.012990   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.060333   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.001443   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.007661   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.020651   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.020207   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.000000   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.014915   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.028674   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.006598   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.005774   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.023094   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.024118   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.075822   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.012317   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.038105   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.014434   \n",
       "\n",
       "                                                                                                         correctness/answer_entail  \\\n",
       "                                                                                                                               max   \n",
       "llm                        temperature nli                     ellm                     sim                                          \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.91   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.94   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.92   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.97   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.92   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.95   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.87   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.92   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.89   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.91   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.91   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.89   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.91   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.91   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.90   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.91   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.87   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.90   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.88   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.86   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.79   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.80   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.71   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.84   \n",
       "\n",
       "                                                                                                                    \\\n",
       "                                                                                                               std   \n",
       "llm                        temperature nli                     ellm                     sim                          \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.011547   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040415   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.028868   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.011547   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040415   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.011547   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.011547   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.046188   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.075056   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040415   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "\n",
       "                                                                                                         correctness/citations_recall  \\\n",
       "                                                                                                                                  max   \n",
       "llm                        temperature nli                     ellm                     sim                                             \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.995   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.995   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.990   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.985   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.955   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.955   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.930   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.875   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.855   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.855   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.820   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.800   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.780   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.775   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.775   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.705   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.690   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.660   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.615   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.605   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.545   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.495   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.040   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.010   \n",
       "\n",
       "                                                                                                                    \\\n",
       "                                                                                                               std   \n",
       "llm                        temperature nli                     ellm                     sim                          \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.025981   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.008660   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.025981   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.025207   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.092376   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034641   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.028868   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.051962   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.025981   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.080056   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.030981   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.008660   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.043868   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.074282   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.080829   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.051188   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                         correctness/citations_precision  \\\n",
       "                                                                                                                                     max   \n",
       "llm                        temperature nli                     ellm                     sim                                                \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.933333   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.858667   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.918333   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.877024   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.955333   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.976667   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.936190   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.962333   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.643667   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.908333   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.949333   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.915333   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.947333   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.922000   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.762833   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.815278   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.931667   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.961667   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.691690   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.864000   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.753667   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.513667   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.050000   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.006667   \n",
       "\n",
       "                                                                                                                    \\\n",
       "                                                                                                               std   \n",
       "llm                        temperature nli                     ellm                     sim                          \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.070338   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.098810   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.084337   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.135618   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.008660   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.018283   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040843   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023671   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.108477   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.037528   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.010585   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.009623   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023286   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.018283   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.050125   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.088494   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.016358   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.054568   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.078327   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.101471   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.064275   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.006736   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                         quality/answer_relevance  \\\n",
       "                                                                                                                              max   \n",
       "llm                        temperature nli                     ellm                     sim                                         \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.780416   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.798084   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.782177   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.808191   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.790450   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.796144   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.779305   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.787486   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.746003   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.751501   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.777481   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.776388   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.787043   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.748064   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.743680   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.751837   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.754467   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.731615   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.679352   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.797259   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.776772   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.695867   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.725417   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.760995   \n",
       "\n",
       "                                                                                                                    \\\n",
       "                                                                                                               std   \n",
       "llm                        temperature nli                     ellm                     sim                          \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.055383   \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.071202   \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.063220   \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.066080   \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.033242   \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040207   \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040067   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.041098   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.059428   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.030875   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.033935   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.027829   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.055224   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.031690   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.028340   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.041852   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.038641   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.026912   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.046987   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034364   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.043209   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.037250   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.019533   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.027130   \n",
       "\n",
       "                                                                                                         n_questions  \n",
       "                                                                                                                      \n",
       "llm                        temperature nli                     ellm                     sim                           \n",
       "rag-tge_Mistral_v2-4480    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "rag-tge_Llama-3-8B_v1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "rag-tge_Mistral_v2-3360    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "rag-tge_Llama-3-8B_v2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "rag-tge_Llama-3-8B_v3      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "rag-tge_Mistral_v6         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "rag-tge_Mistral.Q8         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "\n",
       "[24 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Evaluation results\"))\n",
    "eval_not_mistral = eval_results[eval_results.index.get_level_values(\"llm\") != \"Mistral-7B-Instruct-v0.2\"]\n",
    "eval_mistral = eval_results[(eval_results.index.get_level_values(\"llm\") == \"Mistral-7B-Instruct-v0.2\") & (eval_results.index.get_level_values(\"prompt_id\") == \"1\") & (eval_results.index.get_level_values(\"temperature\") == \"0.1\")]\n",
    "eval_display = pd.concat([eval_not_mistral, eval_mistral])\n",
    "eval_display = eval_display[eval_display.index.get_level_values(\"llm\") != \"Mixtral-8x7B-Instruct-v0.1.Q8_0\"]  # use this model only for training data, because we already have same model without quantization\n",
    "eval_display = remove_index(eval_display, \"prompt_id\")\n",
    "eval_display = eval_display.sort_values(by=(\"correctness/citations_recall\", AGG_FUNC), ascending=False)\n",
    "eval_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# max"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: citations/ais_recall"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.975167</td>\n",
       "      <td>0.895744</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.790450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.864167</td>\n",
       "      <td>0.974167</td>\n",
       "      <td>0.870923</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.936190</td>\n",
       "      <td>0.779305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.855570</td>\n",
       "      <td>0.979417</td>\n",
       "      <td>0.934590</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.780416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.796144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.813959</td>\n",
       "      <td>0.984115</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.918333</td>\n",
       "      <td>0.782177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.801167</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.895910</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.962333</td>\n",
       "      <td>0.787486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.885892</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.777481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <td>0.769950</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.949359</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.877024</td>\n",
       "      <td>0.808191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>0.776388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.734354</td>\n",
       "      <td>0.978560</td>\n",
       "      <td>0.959359</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.858667</td>\n",
       "      <td>0.798084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.911590</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.751501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.880154</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>0.754467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.607500</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.888982</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.947333</td>\n",
       "      <td>0.787043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.606238</td>\n",
       "      <td>0.901424</td>\n",
       "      <td>0.883923</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.762833</td>\n",
       "      <td>0.743680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.549357</td>\n",
       "      <td>0.972143</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.748064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.537167</td>\n",
       "      <td>0.873897</td>\n",
       "      <td>0.852077</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.643667</td>\n",
       "      <td>0.746003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.534167</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.880392</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.731615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.485310</td>\n",
       "      <td>0.977167</td>\n",
       "      <td>0.874256</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.815278</td>\n",
       "      <td>0.751837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.790846</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.753667</td>\n",
       "      <td>0.776772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.763250</td>\n",
       "      <td>0.757623</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.691690</td>\n",
       "      <td>0.679352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.291167</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.886821</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.797259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.281933</td>\n",
       "      <td>0.640500</td>\n",
       "      <td>0.720846</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.513667</td>\n",
       "      <td>0.695867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.667987</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.725417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.802077</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.760995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall citations/ais_precision  \\\n",
       "                                            max                     max   \n",
       "llm                                                                       \n",
       "rag-tge_Llama-3-8B_v3                  0.875667                0.975167   \n",
       "rag-tge_Mistral.Q8                     0.864167                0.974167   \n",
       "rag-tge_Mistral_v2-4480                0.855570                0.979417   \n",
       "rag-tge_Mistral_v6                     0.854167                0.970000   \n",
       "rag-tge_Mistral_v2-3360                0.813959                0.984115   \n",
       "gpt-3.5-turbo-0125                     0.801167                0.997500   \n",
       "gpt-4-turbo                            0.775000                0.990000   \n",
       "rag-tge_Llama-3-8B_v2                  0.769950                0.984613   \n",
       "Meta-Llama-3-70B-Instruct              0.736667                0.970000   \n",
       "rag-tge_Llama-3-8B_v1                  0.734354                0.978560   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.707500                0.957500   \n",
       "qwen1_5-14b-chat-q8_0                  0.676667                0.983333   \n",
       "qwen1_5-110b-chat                      0.607500                0.993333   \n",
       "Mistral-7B-Instruct-v0.2               0.606238                0.901424   \n",
       "Meta-Llama-3-8B-Instruct               0.549357                0.972143   \n",
       "zephyr-orpo-141b-A35b-v0.1             0.537167                0.873897   \n",
       "qwen1_5-32b-chat-q8_0                  0.534167                0.996667   \n",
       "zephyr-7b-beta                         0.485310                0.977167   \n",
       "gemma-1.1-7b-it                        0.483333                0.850000   \n",
       "c4ai-command-r-plus                    0.457500                0.763250   \n",
       "qwen1_5-7b-chat-q8_0                   0.291167                0.910000   \n",
       "Phi-3-mini-4k-instruct                 0.281933                0.640500   \n",
       "gemma-1.1-2b-it                        0.010000                0.055000   \n",
       "Mistral-7B-Instruct-v0.1               0.005000                0.010000   \n",
       "\n",
       "                           correctness/answer_overlap  \\\n",
       "                                                  max   \n",
       "llm                                                     \n",
       "rag-tge_Llama-3-8B_v3                        0.895744   \n",
       "rag-tge_Mistral.Q8                           0.870923   \n",
       "rag-tge_Mistral_v2-4480                      0.934590   \n",
       "rag-tge_Mistral_v6                           0.931256   \n",
       "rag-tge_Mistral_v2-3360                      0.961667   \n",
       "gpt-3.5-turbo-0125                           0.895910   \n",
       "gpt-4-turbo                                  0.885892   \n",
       "rag-tge_Llama-3-8B_v2                        0.949359   \n",
       "Meta-Llama-3-70B-Instruct                    0.886179   \n",
       "rag-tge_Llama-3-8B_v1                        0.959359   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.911590   \n",
       "qwen1_5-14b-chat-q8_0                        0.880154   \n",
       "qwen1_5-110b-chat                            0.888982   \n",
       "Mistral-7B-Instruct-v0.2                     0.883923   \n",
       "Meta-Llama-3-8B-Instruct                     0.917846   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.852077   \n",
       "qwen1_5-32b-chat-q8_0                        0.880392   \n",
       "zephyr-7b-beta                               0.874256   \n",
       "gemma-1.1-7b-it                              0.790846   \n",
       "c4ai-command-r-plus                          0.757623   \n",
       "qwen1_5-7b-chat-q8_0                         0.886821   \n",
       "Phi-3-mini-4k-instruct                       0.720846   \n",
       "gemma-1.1-2b-it                              0.667987   \n",
       "Mistral-7B-Instruct-v0.1                     0.802077   \n",
       "\n",
       "                           correctness/answer_entail  \\\n",
       "                                                 max   \n",
       "llm                                                    \n",
       "rag-tge_Llama-3-8B_v3                           0.92   \n",
       "rag-tge_Mistral.Q8                              0.87   \n",
       "rag-tge_Mistral_v2-4480                         0.91   \n",
       "rag-tge_Mistral_v6                              0.95   \n",
       "rag-tge_Mistral_v2-3360                         0.92   \n",
       "gpt-3.5-turbo-0125                              0.92   \n",
       "gpt-4-turbo                                     0.91   \n",
       "rag-tge_Llama-3-8B_v2                           0.97   \n",
       "Meta-Llama-3-70B-Instruct                       0.89   \n",
       "rag-tge_Llama-3-8B_v1                           0.94   \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.91   \n",
       "qwen1_5-14b-chat-q8_0                           0.87   \n",
       "qwen1_5-110b-chat                               0.91   \n",
       "Mistral-7B-Instruct-v0.2                        0.90   \n",
       "Meta-Llama-3-8B-Instruct                        0.91   \n",
       "zephyr-orpo-141b-A35b-v0.1                      0.89   \n",
       "qwen1_5-32b-chat-q8_0                           0.90   \n",
       "zephyr-7b-beta                                  0.91   \n",
       "gemma-1.1-7b-it                                 0.79   \n",
       "c4ai-command-r-plus                             0.88   \n",
       "qwen1_5-7b-chat-q8_0                            0.86   \n",
       "Phi-3-mini-4k-instruct                          0.80   \n",
       "gemma-1.1-2b-it                                 0.71   \n",
       "Mistral-7B-Instruct-v0.1                        0.84   \n",
       "\n",
       "                           correctness/citations_recall  \\\n",
       "                                                    max   \n",
       "llm                                                       \n",
       "rag-tge_Llama-3-8B_v3                             0.955   \n",
       "rag-tge_Mistral.Q8                                0.930   \n",
       "rag-tge_Mistral_v2-4480                           0.995   \n",
       "rag-tge_Mistral_v6                                0.955   \n",
       "rag-tge_Mistral_v2-3360                           0.990   \n",
       "gpt-3.5-turbo-0125                                0.875   \n",
       "gpt-4-turbo                                       0.820   \n",
       "rag-tge_Llama-3-8B_v2                             0.985   \n",
       "Meta-Llama-3-70B-Instruct                         0.800   \n",
       "rag-tge_Llama-3-8B_v1                             0.995   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.855   \n",
       "qwen1_5-14b-chat-q8_0                             0.690   \n",
       "qwen1_5-110b-chat                                 0.780   \n",
       "Mistral-7B-Instruct-v0.2                          0.775   \n",
       "Meta-Llama-3-8B-Instruct                          0.775   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.855   \n",
       "qwen1_5-32b-chat-q8_0                             0.660   \n",
       "zephyr-7b-beta                                    0.705   \n",
       "gemma-1.1-7b-it                                   0.545   \n",
       "c4ai-command-r-plus                               0.615   \n",
       "qwen1_5-7b-chat-q8_0                              0.605   \n",
       "Phi-3-mini-4k-instruct                            0.495   \n",
       "gemma-1.1-2b-it                                   0.040   \n",
       "Mistral-7B-Instruct-v0.1                          0.010   \n",
       "\n",
       "                           correctness/citations_precision  \\\n",
       "                                                       max   \n",
       "llm                                                          \n",
       "rag-tge_Llama-3-8B_v3                             0.955333   \n",
       "rag-tge_Mistral.Q8                                0.936190   \n",
       "rag-tge_Mistral_v2-4480                           0.933333   \n",
       "rag-tge_Mistral_v6                                0.976667   \n",
       "rag-tge_Mistral_v2-3360                           0.918333   \n",
       "gpt-3.5-turbo-0125                                0.962333   \n",
       "gpt-4-turbo                                       0.949333   \n",
       "rag-tge_Llama-3-8B_v2                             0.877024   \n",
       "Meta-Llama-3-70B-Instruct                         0.915333   \n",
       "rag-tge_Llama-3-8B_v1                             0.858667   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.908333   \n",
       "qwen1_5-14b-chat-q8_0                             0.931667   \n",
       "qwen1_5-110b-chat                                 0.947333   \n",
       "Mistral-7B-Instruct-v0.2                          0.762833   \n",
       "Meta-Llama-3-8B-Instruct                          0.922000   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.643667   \n",
       "qwen1_5-32b-chat-q8_0                             0.961667   \n",
       "zephyr-7b-beta                                    0.815278   \n",
       "gemma-1.1-7b-it                                   0.753667   \n",
       "c4ai-command-r-plus                               0.691690   \n",
       "qwen1_5-7b-chat-q8_0                              0.864000   \n",
       "Phi-3-mini-4k-instruct                            0.513667   \n",
       "gemma-1.1-2b-it                                   0.050000   \n",
       "Mistral-7B-Instruct-v0.1                          0.006667   \n",
       "\n",
       "                           quality/answer_relevance  \n",
       "                                                max  \n",
       "llm                                                  \n",
       "rag-tge_Llama-3-8B_v3                      0.790450  \n",
       "rag-tge_Mistral.Q8                         0.779305  \n",
       "rag-tge_Mistral_v2-4480                    0.780416  \n",
       "rag-tge_Mistral_v6                         0.796144  \n",
       "rag-tge_Mistral_v2-3360                    0.782177  \n",
       "gpt-3.5-turbo-0125                         0.787486  \n",
       "gpt-4-turbo                                0.777481  \n",
       "rag-tge_Llama-3-8B_v2                      0.808191  \n",
       "Meta-Llama-3-70B-Instruct                  0.776388  \n",
       "rag-tge_Llama-3-8B_v1                      0.798084  \n",
       "Mixtral-8x7B-Instruct-v0.1                 0.751501  \n",
       "qwen1_5-14b-chat-q8_0                      0.754467  \n",
       "qwen1_5-110b-chat                          0.787043  \n",
       "Mistral-7B-Instruct-v0.2                   0.743680  \n",
       "Meta-Llama-3-8B-Instruct                   0.748064  \n",
       "zephyr-orpo-141b-A35b-v0.1                 0.746003  \n",
       "qwen1_5-32b-chat-q8_0                      0.731615  \n",
       "zephyr-7b-beta                             0.751837  \n",
       "gemma-1.1-7b-it                            0.776772  \n",
       "c4ai-command-r-plus                        0.679352  \n",
       "qwen1_5-7b-chat-q8_0                       0.797259  \n",
       "Phi-3-mini-4k-instruct                     0.695867  \n",
       "gemma-1.1-2b-it                            0.725417  \n",
       "Mistral-7B-Instruct-v0.1                   0.760995  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: citations/ais_precision"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.801167</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.895910</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.962333</td>\n",
       "      <td>0.787486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.534167</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.880392</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.731615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.607500</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.888982</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.947333</td>\n",
       "      <td>0.787043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.885892</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.777481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <td>0.769950</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.949359</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.877024</td>\n",
       "      <td>0.808191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.813959</td>\n",
       "      <td>0.984115</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.918333</td>\n",
       "      <td>0.782177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.880154</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>0.754467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.855570</td>\n",
       "      <td>0.979417</td>\n",
       "      <td>0.934590</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.780416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.734354</td>\n",
       "      <td>0.978560</td>\n",
       "      <td>0.959359</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.858667</td>\n",
       "      <td>0.798084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.485310</td>\n",
       "      <td>0.977167</td>\n",
       "      <td>0.874256</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.815278</td>\n",
       "      <td>0.751837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.975167</td>\n",
       "      <td>0.895744</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.790450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.864167</td>\n",
       "      <td>0.974167</td>\n",
       "      <td>0.870923</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.936190</td>\n",
       "      <td>0.779305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.549357</td>\n",
       "      <td>0.972143</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.748064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.796144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>0.776388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.911590</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.751501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.291167</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.886821</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.797259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.606238</td>\n",
       "      <td>0.901424</td>\n",
       "      <td>0.883923</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.762833</td>\n",
       "      <td>0.743680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.537167</td>\n",
       "      <td>0.873897</td>\n",
       "      <td>0.852077</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.643667</td>\n",
       "      <td>0.746003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.790846</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.753667</td>\n",
       "      <td>0.776772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.763250</td>\n",
       "      <td>0.757623</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.691690</td>\n",
       "      <td>0.679352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.281933</td>\n",
       "      <td>0.640500</td>\n",
       "      <td>0.720846</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.513667</td>\n",
       "      <td>0.695867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.667987</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.725417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.802077</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.760995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall citations/ais_precision  \\\n",
       "                                            max                     max   \n",
       "llm                                                                       \n",
       "gpt-3.5-turbo-0125                     0.801167                0.997500   \n",
       "qwen1_5-32b-chat-q8_0                  0.534167                0.996667   \n",
       "qwen1_5-110b-chat                      0.607500                0.993333   \n",
       "gpt-4-turbo                            0.775000                0.990000   \n",
       "rag-tge_Llama-3-8B_v2                  0.769950                0.984613   \n",
       "rag-tge_Mistral_v2-3360                0.813959                0.984115   \n",
       "qwen1_5-14b-chat-q8_0                  0.676667                0.983333   \n",
       "rag-tge_Mistral_v2-4480                0.855570                0.979417   \n",
       "rag-tge_Llama-3-8B_v1                  0.734354                0.978560   \n",
       "zephyr-7b-beta                         0.485310                0.977167   \n",
       "rag-tge_Llama-3-8B_v3                  0.875667                0.975167   \n",
       "rag-tge_Mistral.Q8                     0.864167                0.974167   \n",
       "Meta-Llama-3-8B-Instruct               0.549357                0.972143   \n",
       "rag-tge_Mistral_v6                     0.854167                0.970000   \n",
       "Meta-Llama-3-70B-Instruct              0.736667                0.970000   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.707500                0.957500   \n",
       "qwen1_5-7b-chat-q8_0                   0.291167                0.910000   \n",
       "Mistral-7B-Instruct-v0.2               0.606238                0.901424   \n",
       "zephyr-orpo-141b-A35b-v0.1             0.537167                0.873897   \n",
       "gemma-1.1-7b-it                        0.483333                0.850000   \n",
       "c4ai-command-r-plus                    0.457500                0.763250   \n",
       "Phi-3-mini-4k-instruct                 0.281933                0.640500   \n",
       "gemma-1.1-2b-it                        0.010000                0.055000   \n",
       "Mistral-7B-Instruct-v0.1               0.005000                0.010000   \n",
       "\n",
       "                           correctness/answer_overlap  \\\n",
       "                                                  max   \n",
       "llm                                                     \n",
       "gpt-3.5-turbo-0125                           0.895910   \n",
       "qwen1_5-32b-chat-q8_0                        0.880392   \n",
       "qwen1_5-110b-chat                            0.888982   \n",
       "gpt-4-turbo                                  0.885892   \n",
       "rag-tge_Llama-3-8B_v2                        0.949359   \n",
       "rag-tge_Mistral_v2-3360                      0.961667   \n",
       "qwen1_5-14b-chat-q8_0                        0.880154   \n",
       "rag-tge_Mistral_v2-4480                      0.934590   \n",
       "rag-tge_Llama-3-8B_v1                        0.959359   \n",
       "zephyr-7b-beta                               0.874256   \n",
       "rag-tge_Llama-3-8B_v3                        0.895744   \n",
       "rag-tge_Mistral.Q8                           0.870923   \n",
       "Meta-Llama-3-8B-Instruct                     0.917846   \n",
       "rag-tge_Mistral_v6                           0.931256   \n",
       "Meta-Llama-3-70B-Instruct                    0.886179   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.911590   \n",
       "qwen1_5-7b-chat-q8_0                         0.886821   \n",
       "Mistral-7B-Instruct-v0.2                     0.883923   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.852077   \n",
       "gemma-1.1-7b-it                              0.790846   \n",
       "c4ai-command-r-plus                          0.757623   \n",
       "Phi-3-mini-4k-instruct                       0.720846   \n",
       "gemma-1.1-2b-it                              0.667987   \n",
       "Mistral-7B-Instruct-v0.1                     0.802077   \n",
       "\n",
       "                           correctness/answer_entail  \\\n",
       "                                                 max   \n",
       "llm                                                    \n",
       "gpt-3.5-turbo-0125                              0.92   \n",
       "qwen1_5-32b-chat-q8_0                           0.90   \n",
       "qwen1_5-110b-chat                               0.91   \n",
       "gpt-4-turbo                                     0.91   \n",
       "rag-tge_Llama-3-8B_v2                           0.97   \n",
       "rag-tge_Mistral_v2-3360                         0.92   \n",
       "qwen1_5-14b-chat-q8_0                           0.87   \n",
       "rag-tge_Mistral_v2-4480                         0.91   \n",
       "rag-tge_Llama-3-8B_v1                           0.94   \n",
       "zephyr-7b-beta                                  0.91   \n",
       "rag-tge_Llama-3-8B_v3                           0.92   \n",
       "rag-tge_Mistral.Q8                              0.87   \n",
       "Meta-Llama-3-8B-Instruct                        0.91   \n",
       "rag-tge_Mistral_v6                              0.95   \n",
       "Meta-Llama-3-70B-Instruct                       0.89   \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.91   \n",
       "qwen1_5-7b-chat-q8_0                            0.86   \n",
       "Mistral-7B-Instruct-v0.2                        0.90   \n",
       "zephyr-orpo-141b-A35b-v0.1                      0.89   \n",
       "gemma-1.1-7b-it                                 0.79   \n",
       "c4ai-command-r-plus                             0.88   \n",
       "Phi-3-mini-4k-instruct                          0.80   \n",
       "gemma-1.1-2b-it                                 0.71   \n",
       "Mistral-7B-Instruct-v0.1                        0.84   \n",
       "\n",
       "                           correctness/citations_recall  \\\n",
       "                                                    max   \n",
       "llm                                                       \n",
       "gpt-3.5-turbo-0125                                0.875   \n",
       "qwen1_5-32b-chat-q8_0                             0.660   \n",
       "qwen1_5-110b-chat                                 0.780   \n",
       "gpt-4-turbo                                       0.820   \n",
       "rag-tge_Llama-3-8B_v2                             0.985   \n",
       "rag-tge_Mistral_v2-3360                           0.990   \n",
       "qwen1_5-14b-chat-q8_0                             0.690   \n",
       "rag-tge_Mistral_v2-4480                           0.995   \n",
       "rag-tge_Llama-3-8B_v1                             0.995   \n",
       "zephyr-7b-beta                                    0.705   \n",
       "rag-tge_Llama-3-8B_v3                             0.955   \n",
       "rag-tge_Mistral.Q8                                0.930   \n",
       "Meta-Llama-3-8B-Instruct                          0.775   \n",
       "rag-tge_Mistral_v6                                0.955   \n",
       "Meta-Llama-3-70B-Instruct                         0.800   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.855   \n",
       "qwen1_5-7b-chat-q8_0                              0.605   \n",
       "Mistral-7B-Instruct-v0.2                          0.775   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.855   \n",
       "gemma-1.1-7b-it                                   0.545   \n",
       "c4ai-command-r-plus                               0.615   \n",
       "Phi-3-mini-4k-instruct                            0.495   \n",
       "gemma-1.1-2b-it                                   0.040   \n",
       "Mistral-7B-Instruct-v0.1                          0.010   \n",
       "\n",
       "                           correctness/citations_precision  \\\n",
       "                                                       max   \n",
       "llm                                                          \n",
       "gpt-3.5-turbo-0125                                0.962333   \n",
       "qwen1_5-32b-chat-q8_0                             0.961667   \n",
       "qwen1_5-110b-chat                                 0.947333   \n",
       "gpt-4-turbo                                       0.949333   \n",
       "rag-tge_Llama-3-8B_v2                             0.877024   \n",
       "rag-tge_Mistral_v2-3360                           0.918333   \n",
       "qwen1_5-14b-chat-q8_0                             0.931667   \n",
       "rag-tge_Mistral_v2-4480                           0.933333   \n",
       "rag-tge_Llama-3-8B_v1                             0.858667   \n",
       "zephyr-7b-beta                                    0.815278   \n",
       "rag-tge_Llama-3-8B_v3                             0.955333   \n",
       "rag-tge_Mistral.Q8                                0.936190   \n",
       "Meta-Llama-3-8B-Instruct                          0.922000   \n",
       "rag-tge_Mistral_v6                                0.976667   \n",
       "Meta-Llama-3-70B-Instruct                         0.915333   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.908333   \n",
       "qwen1_5-7b-chat-q8_0                              0.864000   \n",
       "Mistral-7B-Instruct-v0.2                          0.762833   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.643667   \n",
       "gemma-1.1-7b-it                                   0.753667   \n",
       "c4ai-command-r-plus                               0.691690   \n",
       "Phi-3-mini-4k-instruct                            0.513667   \n",
       "gemma-1.1-2b-it                                   0.050000   \n",
       "Mistral-7B-Instruct-v0.1                          0.006667   \n",
       "\n",
       "                           quality/answer_relevance  \n",
       "                                                max  \n",
       "llm                                                  \n",
       "gpt-3.5-turbo-0125                         0.787486  \n",
       "qwen1_5-32b-chat-q8_0                      0.731615  \n",
       "qwen1_5-110b-chat                          0.787043  \n",
       "gpt-4-turbo                                0.777481  \n",
       "rag-tge_Llama-3-8B_v2                      0.808191  \n",
       "rag-tge_Mistral_v2-3360                    0.782177  \n",
       "qwen1_5-14b-chat-q8_0                      0.754467  \n",
       "rag-tge_Mistral_v2-4480                    0.780416  \n",
       "rag-tge_Llama-3-8B_v1                      0.798084  \n",
       "zephyr-7b-beta                             0.751837  \n",
       "rag-tge_Llama-3-8B_v3                      0.790450  \n",
       "rag-tge_Mistral.Q8                         0.779305  \n",
       "Meta-Llama-3-8B-Instruct                   0.748064  \n",
       "rag-tge_Mistral_v6                         0.796144  \n",
       "Meta-Llama-3-70B-Instruct                  0.776388  \n",
       "Mixtral-8x7B-Instruct-v0.1                 0.751501  \n",
       "qwen1_5-7b-chat-q8_0                       0.797259  \n",
       "Mistral-7B-Instruct-v0.2                   0.743680  \n",
       "zephyr-orpo-141b-A35b-v0.1                 0.746003  \n",
       "gemma-1.1-7b-it                            0.776772  \n",
       "c4ai-command-r-plus                        0.679352  \n",
       "Phi-3-mini-4k-instruct                     0.695867  \n",
       "gemma-1.1-2b-it                            0.725417  \n",
       "Mistral-7B-Instruct-v0.1                   0.760995  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/answer_overlap"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.813959</td>\n",
       "      <td>0.984115</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.918333</td>\n",
       "      <td>0.782177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.734354</td>\n",
       "      <td>0.978560</td>\n",
       "      <td>0.959359</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.858667</td>\n",
       "      <td>0.798084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <td>0.769950</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.949359</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.877024</td>\n",
       "      <td>0.808191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.855570</td>\n",
       "      <td>0.979417</td>\n",
       "      <td>0.934590</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.780416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.796144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.549357</td>\n",
       "      <td>0.972143</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.748064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.911590</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.751501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.801167</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.895910</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.962333</td>\n",
       "      <td>0.787486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.975167</td>\n",
       "      <td>0.895744</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.790450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.607500</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.888982</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.947333</td>\n",
       "      <td>0.787043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.291167</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.886821</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.797259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>0.776388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.885892</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.777481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.606238</td>\n",
       "      <td>0.901424</td>\n",
       "      <td>0.883923</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.762833</td>\n",
       "      <td>0.743680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.534167</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.880392</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.731615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.880154</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>0.754467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.485310</td>\n",
       "      <td>0.977167</td>\n",
       "      <td>0.874256</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.815278</td>\n",
       "      <td>0.751837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.864167</td>\n",
       "      <td>0.974167</td>\n",
       "      <td>0.870923</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.936190</td>\n",
       "      <td>0.779305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.537167</td>\n",
       "      <td>0.873897</td>\n",
       "      <td>0.852077</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.643667</td>\n",
       "      <td>0.746003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.802077</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.760995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.790846</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.753667</td>\n",
       "      <td>0.776772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.763250</td>\n",
       "      <td>0.757623</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.691690</td>\n",
       "      <td>0.679352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.281933</td>\n",
       "      <td>0.640500</td>\n",
       "      <td>0.720846</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.513667</td>\n",
       "      <td>0.695867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.667987</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.725417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall citations/ais_precision  \\\n",
       "                                            max                     max   \n",
       "llm                                                                       \n",
       "rag-tge_Mistral_v2-3360                0.813959                0.984115   \n",
       "rag-tge_Llama-3-8B_v1                  0.734354                0.978560   \n",
       "rag-tge_Llama-3-8B_v2                  0.769950                0.984613   \n",
       "rag-tge_Mistral_v2-4480                0.855570                0.979417   \n",
       "rag-tge_Mistral_v6                     0.854167                0.970000   \n",
       "Meta-Llama-3-8B-Instruct               0.549357                0.972143   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.707500                0.957500   \n",
       "gpt-3.5-turbo-0125                     0.801167                0.997500   \n",
       "rag-tge_Llama-3-8B_v3                  0.875667                0.975167   \n",
       "qwen1_5-110b-chat                      0.607500                0.993333   \n",
       "qwen1_5-7b-chat-q8_0                   0.291167                0.910000   \n",
       "Meta-Llama-3-70B-Instruct              0.736667                0.970000   \n",
       "gpt-4-turbo                            0.775000                0.990000   \n",
       "Mistral-7B-Instruct-v0.2               0.606238                0.901424   \n",
       "qwen1_5-32b-chat-q8_0                  0.534167                0.996667   \n",
       "qwen1_5-14b-chat-q8_0                  0.676667                0.983333   \n",
       "zephyr-7b-beta                         0.485310                0.977167   \n",
       "rag-tge_Mistral.Q8                     0.864167                0.974167   \n",
       "zephyr-orpo-141b-A35b-v0.1             0.537167                0.873897   \n",
       "Mistral-7B-Instruct-v0.1               0.005000                0.010000   \n",
       "gemma-1.1-7b-it                        0.483333                0.850000   \n",
       "c4ai-command-r-plus                    0.457500                0.763250   \n",
       "Phi-3-mini-4k-instruct                 0.281933                0.640500   \n",
       "gemma-1.1-2b-it                        0.010000                0.055000   \n",
       "\n",
       "                           correctness/answer_overlap  \\\n",
       "                                                  max   \n",
       "llm                                                     \n",
       "rag-tge_Mistral_v2-3360                      0.961667   \n",
       "rag-tge_Llama-3-8B_v1                        0.959359   \n",
       "rag-tge_Llama-3-8B_v2                        0.949359   \n",
       "rag-tge_Mistral_v2-4480                      0.934590   \n",
       "rag-tge_Mistral_v6                           0.931256   \n",
       "Meta-Llama-3-8B-Instruct                     0.917846   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.911590   \n",
       "gpt-3.5-turbo-0125                           0.895910   \n",
       "rag-tge_Llama-3-8B_v3                        0.895744   \n",
       "qwen1_5-110b-chat                            0.888982   \n",
       "qwen1_5-7b-chat-q8_0                         0.886821   \n",
       "Meta-Llama-3-70B-Instruct                    0.886179   \n",
       "gpt-4-turbo                                  0.885892   \n",
       "Mistral-7B-Instruct-v0.2                     0.883923   \n",
       "qwen1_5-32b-chat-q8_0                        0.880392   \n",
       "qwen1_5-14b-chat-q8_0                        0.880154   \n",
       "zephyr-7b-beta                               0.874256   \n",
       "rag-tge_Mistral.Q8                           0.870923   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.852077   \n",
       "Mistral-7B-Instruct-v0.1                     0.802077   \n",
       "gemma-1.1-7b-it                              0.790846   \n",
       "c4ai-command-r-plus                          0.757623   \n",
       "Phi-3-mini-4k-instruct                       0.720846   \n",
       "gemma-1.1-2b-it                              0.667987   \n",
       "\n",
       "                           correctness/answer_entail  \\\n",
       "                                                 max   \n",
       "llm                                                    \n",
       "rag-tge_Mistral_v2-3360                         0.92   \n",
       "rag-tge_Llama-3-8B_v1                           0.94   \n",
       "rag-tge_Llama-3-8B_v2                           0.97   \n",
       "rag-tge_Mistral_v2-4480                         0.91   \n",
       "rag-tge_Mistral_v6                              0.95   \n",
       "Meta-Llama-3-8B-Instruct                        0.91   \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.91   \n",
       "gpt-3.5-turbo-0125                              0.92   \n",
       "rag-tge_Llama-3-8B_v3                           0.92   \n",
       "qwen1_5-110b-chat                               0.91   \n",
       "qwen1_5-7b-chat-q8_0                            0.86   \n",
       "Meta-Llama-3-70B-Instruct                       0.89   \n",
       "gpt-4-turbo                                     0.91   \n",
       "Mistral-7B-Instruct-v0.2                        0.90   \n",
       "qwen1_5-32b-chat-q8_0                           0.90   \n",
       "qwen1_5-14b-chat-q8_0                           0.87   \n",
       "zephyr-7b-beta                                  0.91   \n",
       "rag-tge_Mistral.Q8                              0.87   \n",
       "zephyr-orpo-141b-A35b-v0.1                      0.89   \n",
       "Mistral-7B-Instruct-v0.1                        0.84   \n",
       "gemma-1.1-7b-it                                 0.79   \n",
       "c4ai-command-r-plus                             0.88   \n",
       "Phi-3-mini-4k-instruct                          0.80   \n",
       "gemma-1.1-2b-it                                 0.71   \n",
       "\n",
       "                           correctness/citations_recall  \\\n",
       "                                                    max   \n",
       "llm                                                       \n",
       "rag-tge_Mistral_v2-3360                           0.990   \n",
       "rag-tge_Llama-3-8B_v1                             0.995   \n",
       "rag-tge_Llama-3-8B_v2                             0.985   \n",
       "rag-tge_Mistral_v2-4480                           0.995   \n",
       "rag-tge_Mistral_v6                                0.955   \n",
       "Meta-Llama-3-8B-Instruct                          0.775   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.855   \n",
       "gpt-3.5-turbo-0125                                0.875   \n",
       "rag-tge_Llama-3-8B_v3                             0.955   \n",
       "qwen1_5-110b-chat                                 0.780   \n",
       "qwen1_5-7b-chat-q8_0                              0.605   \n",
       "Meta-Llama-3-70B-Instruct                         0.800   \n",
       "gpt-4-turbo                                       0.820   \n",
       "Mistral-7B-Instruct-v0.2                          0.775   \n",
       "qwen1_5-32b-chat-q8_0                             0.660   \n",
       "qwen1_5-14b-chat-q8_0                             0.690   \n",
       "zephyr-7b-beta                                    0.705   \n",
       "rag-tge_Mistral.Q8                                0.930   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.855   \n",
       "Mistral-7B-Instruct-v0.1                          0.010   \n",
       "gemma-1.1-7b-it                                   0.545   \n",
       "c4ai-command-r-plus                               0.615   \n",
       "Phi-3-mini-4k-instruct                            0.495   \n",
       "gemma-1.1-2b-it                                   0.040   \n",
       "\n",
       "                           correctness/citations_precision  \\\n",
       "                                                       max   \n",
       "llm                                                          \n",
       "rag-tge_Mistral_v2-3360                           0.918333   \n",
       "rag-tge_Llama-3-8B_v1                             0.858667   \n",
       "rag-tge_Llama-3-8B_v2                             0.877024   \n",
       "rag-tge_Mistral_v2-4480                           0.933333   \n",
       "rag-tge_Mistral_v6                                0.976667   \n",
       "Meta-Llama-3-8B-Instruct                          0.922000   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.908333   \n",
       "gpt-3.5-turbo-0125                                0.962333   \n",
       "rag-tge_Llama-3-8B_v3                             0.955333   \n",
       "qwen1_5-110b-chat                                 0.947333   \n",
       "qwen1_5-7b-chat-q8_0                              0.864000   \n",
       "Meta-Llama-3-70B-Instruct                         0.915333   \n",
       "gpt-4-turbo                                       0.949333   \n",
       "Mistral-7B-Instruct-v0.2                          0.762833   \n",
       "qwen1_5-32b-chat-q8_0                             0.961667   \n",
       "qwen1_5-14b-chat-q8_0                             0.931667   \n",
       "zephyr-7b-beta                                    0.815278   \n",
       "rag-tge_Mistral.Q8                                0.936190   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.643667   \n",
       "Mistral-7B-Instruct-v0.1                          0.006667   \n",
       "gemma-1.1-7b-it                                   0.753667   \n",
       "c4ai-command-r-plus                               0.691690   \n",
       "Phi-3-mini-4k-instruct                            0.513667   \n",
       "gemma-1.1-2b-it                                   0.050000   \n",
       "\n",
       "                           quality/answer_relevance  \n",
       "                                                max  \n",
       "llm                                                  \n",
       "rag-tge_Mistral_v2-3360                    0.782177  \n",
       "rag-tge_Llama-3-8B_v1                      0.798084  \n",
       "rag-tge_Llama-3-8B_v2                      0.808191  \n",
       "rag-tge_Mistral_v2-4480                    0.780416  \n",
       "rag-tge_Mistral_v6                         0.796144  \n",
       "Meta-Llama-3-8B-Instruct                   0.748064  \n",
       "Mixtral-8x7B-Instruct-v0.1                 0.751501  \n",
       "gpt-3.5-turbo-0125                         0.787486  \n",
       "rag-tge_Llama-3-8B_v3                      0.790450  \n",
       "qwen1_5-110b-chat                          0.787043  \n",
       "qwen1_5-7b-chat-q8_0                       0.797259  \n",
       "Meta-Llama-3-70B-Instruct                  0.776388  \n",
       "gpt-4-turbo                                0.777481  \n",
       "Mistral-7B-Instruct-v0.2                   0.743680  \n",
       "qwen1_5-32b-chat-q8_0                      0.731615  \n",
       "qwen1_5-14b-chat-q8_0                      0.754467  \n",
       "zephyr-7b-beta                             0.751837  \n",
       "rag-tge_Mistral.Q8                         0.779305  \n",
       "zephyr-orpo-141b-A35b-v0.1                 0.746003  \n",
       "Mistral-7B-Instruct-v0.1                   0.760995  \n",
       "gemma-1.1-7b-it                            0.776772  \n",
       "c4ai-command-r-plus                        0.679352  \n",
       "Phi-3-mini-4k-instruct                     0.695867  \n",
       "gemma-1.1-2b-it                            0.725417  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/answer_entail"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <td>0.769950</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.949359</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.877024</td>\n",
       "      <td>0.808191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.796144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.734354</td>\n",
       "      <td>0.978560</td>\n",
       "      <td>0.959359</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.858667</td>\n",
       "      <td>0.798084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.813959</td>\n",
       "      <td>0.984115</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.918333</td>\n",
       "      <td>0.782177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.801167</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.895910</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.962333</td>\n",
       "      <td>0.787486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.975167</td>\n",
       "      <td>0.895744</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.790450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.855570</td>\n",
       "      <td>0.979417</td>\n",
       "      <td>0.934590</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.780416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.911590</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.751501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.485310</td>\n",
       "      <td>0.977167</td>\n",
       "      <td>0.874256</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.815278</td>\n",
       "      <td>0.751837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.885892</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.777481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.549357</td>\n",
       "      <td>0.972143</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.748064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.607500</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.888982</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.947333</td>\n",
       "      <td>0.787043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.534167</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.880392</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.731615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.606238</td>\n",
       "      <td>0.901424</td>\n",
       "      <td>0.883923</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.762833</td>\n",
       "      <td>0.743680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.537167</td>\n",
       "      <td>0.873897</td>\n",
       "      <td>0.852077</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.643667</td>\n",
       "      <td>0.746003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>0.776388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.763250</td>\n",
       "      <td>0.757623</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.691690</td>\n",
       "      <td>0.679352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.864167</td>\n",
       "      <td>0.974167</td>\n",
       "      <td>0.870923</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.936190</td>\n",
       "      <td>0.779305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.880154</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>0.754467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.291167</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.886821</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.797259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.802077</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.760995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.281933</td>\n",
       "      <td>0.640500</td>\n",
       "      <td>0.720846</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.513667</td>\n",
       "      <td>0.695867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.790846</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.753667</td>\n",
       "      <td>0.776772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.667987</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.725417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall citations/ais_precision  \\\n",
       "                                            max                     max   \n",
       "llm                                                                       \n",
       "rag-tge_Llama-3-8B_v2                  0.769950                0.984613   \n",
       "rag-tge_Mistral_v6                     0.854167                0.970000   \n",
       "rag-tge_Llama-3-8B_v1                  0.734354                0.978560   \n",
       "rag-tge_Mistral_v2-3360                0.813959                0.984115   \n",
       "gpt-3.5-turbo-0125                     0.801167                0.997500   \n",
       "rag-tge_Llama-3-8B_v3                  0.875667                0.975167   \n",
       "rag-tge_Mistral_v2-4480                0.855570                0.979417   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.707500                0.957500   \n",
       "zephyr-7b-beta                         0.485310                0.977167   \n",
       "gpt-4-turbo                            0.775000                0.990000   \n",
       "Meta-Llama-3-8B-Instruct               0.549357                0.972143   \n",
       "qwen1_5-110b-chat                      0.607500                0.993333   \n",
       "qwen1_5-32b-chat-q8_0                  0.534167                0.996667   \n",
       "Mistral-7B-Instruct-v0.2               0.606238                0.901424   \n",
       "zephyr-orpo-141b-A35b-v0.1             0.537167                0.873897   \n",
       "Meta-Llama-3-70B-Instruct              0.736667                0.970000   \n",
       "c4ai-command-r-plus                    0.457500                0.763250   \n",
       "rag-tge_Mistral.Q8                     0.864167                0.974167   \n",
       "qwen1_5-14b-chat-q8_0                  0.676667                0.983333   \n",
       "qwen1_5-7b-chat-q8_0                   0.291167                0.910000   \n",
       "Mistral-7B-Instruct-v0.1               0.005000                0.010000   \n",
       "Phi-3-mini-4k-instruct                 0.281933                0.640500   \n",
       "gemma-1.1-7b-it                        0.483333                0.850000   \n",
       "gemma-1.1-2b-it                        0.010000                0.055000   \n",
       "\n",
       "                           correctness/answer_overlap  \\\n",
       "                                                  max   \n",
       "llm                                                     \n",
       "rag-tge_Llama-3-8B_v2                        0.949359   \n",
       "rag-tge_Mistral_v6                           0.931256   \n",
       "rag-tge_Llama-3-8B_v1                        0.959359   \n",
       "rag-tge_Mistral_v2-3360                      0.961667   \n",
       "gpt-3.5-turbo-0125                           0.895910   \n",
       "rag-tge_Llama-3-8B_v3                        0.895744   \n",
       "rag-tge_Mistral_v2-4480                      0.934590   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.911590   \n",
       "zephyr-7b-beta                               0.874256   \n",
       "gpt-4-turbo                                  0.885892   \n",
       "Meta-Llama-3-8B-Instruct                     0.917846   \n",
       "qwen1_5-110b-chat                            0.888982   \n",
       "qwen1_5-32b-chat-q8_0                        0.880392   \n",
       "Mistral-7B-Instruct-v0.2                     0.883923   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.852077   \n",
       "Meta-Llama-3-70B-Instruct                    0.886179   \n",
       "c4ai-command-r-plus                          0.757623   \n",
       "rag-tge_Mistral.Q8                           0.870923   \n",
       "qwen1_5-14b-chat-q8_0                        0.880154   \n",
       "qwen1_5-7b-chat-q8_0                         0.886821   \n",
       "Mistral-7B-Instruct-v0.1                     0.802077   \n",
       "Phi-3-mini-4k-instruct                       0.720846   \n",
       "gemma-1.1-7b-it                              0.790846   \n",
       "gemma-1.1-2b-it                              0.667987   \n",
       "\n",
       "                           correctness/answer_entail  \\\n",
       "                                                 max   \n",
       "llm                                                    \n",
       "rag-tge_Llama-3-8B_v2                           0.97   \n",
       "rag-tge_Mistral_v6                              0.95   \n",
       "rag-tge_Llama-3-8B_v1                           0.94   \n",
       "rag-tge_Mistral_v2-3360                         0.92   \n",
       "gpt-3.5-turbo-0125                              0.92   \n",
       "rag-tge_Llama-3-8B_v3                           0.92   \n",
       "rag-tge_Mistral_v2-4480                         0.91   \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.91   \n",
       "zephyr-7b-beta                                  0.91   \n",
       "gpt-4-turbo                                     0.91   \n",
       "Meta-Llama-3-8B-Instruct                        0.91   \n",
       "qwen1_5-110b-chat                               0.91   \n",
       "qwen1_5-32b-chat-q8_0                           0.90   \n",
       "Mistral-7B-Instruct-v0.2                        0.90   \n",
       "zephyr-orpo-141b-A35b-v0.1                      0.89   \n",
       "Meta-Llama-3-70B-Instruct                       0.89   \n",
       "c4ai-command-r-plus                             0.88   \n",
       "rag-tge_Mistral.Q8                              0.87   \n",
       "qwen1_5-14b-chat-q8_0                           0.87   \n",
       "qwen1_5-7b-chat-q8_0                            0.86   \n",
       "Mistral-7B-Instruct-v0.1                        0.84   \n",
       "Phi-3-mini-4k-instruct                          0.80   \n",
       "gemma-1.1-7b-it                                 0.79   \n",
       "gemma-1.1-2b-it                                 0.71   \n",
       "\n",
       "                           correctness/citations_recall  \\\n",
       "                                                    max   \n",
       "llm                                                       \n",
       "rag-tge_Llama-3-8B_v2                             0.985   \n",
       "rag-tge_Mistral_v6                                0.955   \n",
       "rag-tge_Llama-3-8B_v1                             0.995   \n",
       "rag-tge_Mistral_v2-3360                           0.990   \n",
       "gpt-3.5-turbo-0125                                0.875   \n",
       "rag-tge_Llama-3-8B_v3                             0.955   \n",
       "rag-tge_Mistral_v2-4480                           0.995   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.855   \n",
       "zephyr-7b-beta                                    0.705   \n",
       "gpt-4-turbo                                       0.820   \n",
       "Meta-Llama-3-8B-Instruct                          0.775   \n",
       "qwen1_5-110b-chat                                 0.780   \n",
       "qwen1_5-32b-chat-q8_0                             0.660   \n",
       "Mistral-7B-Instruct-v0.2                          0.775   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.855   \n",
       "Meta-Llama-3-70B-Instruct                         0.800   \n",
       "c4ai-command-r-plus                               0.615   \n",
       "rag-tge_Mistral.Q8                                0.930   \n",
       "qwen1_5-14b-chat-q8_0                             0.690   \n",
       "qwen1_5-7b-chat-q8_0                              0.605   \n",
       "Mistral-7B-Instruct-v0.1                          0.010   \n",
       "Phi-3-mini-4k-instruct                            0.495   \n",
       "gemma-1.1-7b-it                                   0.545   \n",
       "gemma-1.1-2b-it                                   0.040   \n",
       "\n",
       "                           correctness/citations_precision  \\\n",
       "                                                       max   \n",
       "llm                                                          \n",
       "rag-tge_Llama-3-8B_v2                             0.877024   \n",
       "rag-tge_Mistral_v6                                0.976667   \n",
       "rag-tge_Llama-3-8B_v1                             0.858667   \n",
       "rag-tge_Mistral_v2-3360                           0.918333   \n",
       "gpt-3.5-turbo-0125                                0.962333   \n",
       "rag-tge_Llama-3-8B_v3                             0.955333   \n",
       "rag-tge_Mistral_v2-4480                           0.933333   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.908333   \n",
       "zephyr-7b-beta                                    0.815278   \n",
       "gpt-4-turbo                                       0.949333   \n",
       "Meta-Llama-3-8B-Instruct                          0.922000   \n",
       "qwen1_5-110b-chat                                 0.947333   \n",
       "qwen1_5-32b-chat-q8_0                             0.961667   \n",
       "Mistral-7B-Instruct-v0.2                          0.762833   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.643667   \n",
       "Meta-Llama-3-70B-Instruct                         0.915333   \n",
       "c4ai-command-r-plus                               0.691690   \n",
       "rag-tge_Mistral.Q8                                0.936190   \n",
       "qwen1_5-14b-chat-q8_0                             0.931667   \n",
       "qwen1_5-7b-chat-q8_0                              0.864000   \n",
       "Mistral-7B-Instruct-v0.1                          0.006667   \n",
       "Phi-3-mini-4k-instruct                            0.513667   \n",
       "gemma-1.1-7b-it                                   0.753667   \n",
       "gemma-1.1-2b-it                                   0.050000   \n",
       "\n",
       "                           quality/answer_relevance  \n",
       "                                                max  \n",
       "llm                                                  \n",
       "rag-tge_Llama-3-8B_v2                      0.808191  \n",
       "rag-tge_Mistral_v6                         0.796144  \n",
       "rag-tge_Llama-3-8B_v1                      0.798084  \n",
       "rag-tge_Mistral_v2-3360                    0.782177  \n",
       "gpt-3.5-turbo-0125                         0.787486  \n",
       "rag-tge_Llama-3-8B_v3                      0.790450  \n",
       "rag-tge_Mistral_v2-4480                    0.780416  \n",
       "Mixtral-8x7B-Instruct-v0.1                 0.751501  \n",
       "zephyr-7b-beta                             0.751837  \n",
       "gpt-4-turbo                                0.777481  \n",
       "Meta-Llama-3-8B-Instruct                   0.748064  \n",
       "qwen1_5-110b-chat                          0.787043  \n",
       "qwen1_5-32b-chat-q8_0                      0.731615  \n",
       "Mistral-7B-Instruct-v0.2                   0.743680  \n",
       "zephyr-orpo-141b-A35b-v0.1                 0.746003  \n",
       "Meta-Llama-3-70B-Instruct                  0.776388  \n",
       "c4ai-command-r-plus                        0.679352  \n",
       "rag-tge_Mistral.Q8                         0.779305  \n",
       "qwen1_5-14b-chat-q8_0                      0.754467  \n",
       "qwen1_5-7b-chat-q8_0                       0.797259  \n",
       "Mistral-7B-Instruct-v0.1                   0.760995  \n",
       "Phi-3-mini-4k-instruct                     0.695867  \n",
       "gemma-1.1-7b-it                            0.776772  \n",
       "gemma-1.1-2b-it                            0.725417  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/citations_recall"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.855570</td>\n",
       "      <td>0.979417</td>\n",
       "      <td>0.934590</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.780416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.734354</td>\n",
       "      <td>0.978560</td>\n",
       "      <td>0.959359</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.858667</td>\n",
       "      <td>0.798084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.813959</td>\n",
       "      <td>0.984115</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.918333</td>\n",
       "      <td>0.782177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <td>0.769950</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.949359</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.877024</td>\n",
       "      <td>0.808191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.975167</td>\n",
       "      <td>0.895744</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.790450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.796144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.864167</td>\n",
       "      <td>0.974167</td>\n",
       "      <td>0.870923</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.936190</td>\n",
       "      <td>0.779305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.801167</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.895910</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.962333</td>\n",
       "      <td>0.787486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.537167</td>\n",
       "      <td>0.873897</td>\n",
       "      <td>0.852077</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.643667</td>\n",
       "      <td>0.746003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.911590</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.751501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.885892</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.777481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>0.776388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.607500</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.888982</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.947333</td>\n",
       "      <td>0.787043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.549357</td>\n",
       "      <td>0.972143</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.748064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.606238</td>\n",
       "      <td>0.901424</td>\n",
       "      <td>0.883923</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.762833</td>\n",
       "      <td>0.743680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.485310</td>\n",
       "      <td>0.977167</td>\n",
       "      <td>0.874256</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.815278</td>\n",
       "      <td>0.751837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.880154</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>0.754467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.534167</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.880392</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.731615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.763250</td>\n",
       "      <td>0.757623</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.691690</td>\n",
       "      <td>0.679352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.291167</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.886821</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.797259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.790846</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.753667</td>\n",
       "      <td>0.776772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.281933</td>\n",
       "      <td>0.640500</td>\n",
       "      <td>0.720846</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.513667</td>\n",
       "      <td>0.695867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.667987</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.725417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.802077</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.760995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall citations/ais_precision  \\\n",
       "                                            max                     max   \n",
       "llm                                                                       \n",
       "rag-tge_Mistral_v2-4480                0.855570                0.979417   \n",
       "rag-tge_Llama-3-8B_v1                  0.734354                0.978560   \n",
       "rag-tge_Mistral_v2-3360                0.813959                0.984115   \n",
       "rag-tge_Llama-3-8B_v2                  0.769950                0.984613   \n",
       "rag-tge_Llama-3-8B_v3                  0.875667                0.975167   \n",
       "rag-tge_Mistral_v6                     0.854167                0.970000   \n",
       "rag-tge_Mistral.Q8                     0.864167                0.974167   \n",
       "gpt-3.5-turbo-0125                     0.801167                0.997500   \n",
       "zephyr-orpo-141b-A35b-v0.1             0.537167                0.873897   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.707500                0.957500   \n",
       "gpt-4-turbo                            0.775000                0.990000   \n",
       "Meta-Llama-3-70B-Instruct              0.736667                0.970000   \n",
       "qwen1_5-110b-chat                      0.607500                0.993333   \n",
       "Meta-Llama-3-8B-Instruct               0.549357                0.972143   \n",
       "Mistral-7B-Instruct-v0.2               0.606238                0.901424   \n",
       "zephyr-7b-beta                         0.485310                0.977167   \n",
       "qwen1_5-14b-chat-q8_0                  0.676667                0.983333   \n",
       "qwen1_5-32b-chat-q8_0                  0.534167                0.996667   \n",
       "c4ai-command-r-plus                    0.457500                0.763250   \n",
       "qwen1_5-7b-chat-q8_0                   0.291167                0.910000   \n",
       "gemma-1.1-7b-it                        0.483333                0.850000   \n",
       "Phi-3-mini-4k-instruct                 0.281933                0.640500   \n",
       "gemma-1.1-2b-it                        0.010000                0.055000   \n",
       "Mistral-7B-Instruct-v0.1               0.005000                0.010000   \n",
       "\n",
       "                           correctness/answer_overlap  \\\n",
       "                                                  max   \n",
       "llm                                                     \n",
       "rag-tge_Mistral_v2-4480                      0.934590   \n",
       "rag-tge_Llama-3-8B_v1                        0.959359   \n",
       "rag-tge_Mistral_v2-3360                      0.961667   \n",
       "rag-tge_Llama-3-8B_v2                        0.949359   \n",
       "rag-tge_Llama-3-8B_v3                        0.895744   \n",
       "rag-tge_Mistral_v6                           0.931256   \n",
       "rag-tge_Mistral.Q8                           0.870923   \n",
       "gpt-3.5-turbo-0125                           0.895910   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.852077   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.911590   \n",
       "gpt-4-turbo                                  0.885892   \n",
       "Meta-Llama-3-70B-Instruct                    0.886179   \n",
       "qwen1_5-110b-chat                            0.888982   \n",
       "Meta-Llama-3-8B-Instruct                     0.917846   \n",
       "Mistral-7B-Instruct-v0.2                     0.883923   \n",
       "zephyr-7b-beta                               0.874256   \n",
       "qwen1_5-14b-chat-q8_0                        0.880154   \n",
       "qwen1_5-32b-chat-q8_0                        0.880392   \n",
       "c4ai-command-r-plus                          0.757623   \n",
       "qwen1_5-7b-chat-q8_0                         0.886821   \n",
       "gemma-1.1-7b-it                              0.790846   \n",
       "Phi-3-mini-4k-instruct                       0.720846   \n",
       "gemma-1.1-2b-it                              0.667987   \n",
       "Mistral-7B-Instruct-v0.1                     0.802077   \n",
       "\n",
       "                           correctness/answer_entail  \\\n",
       "                                                 max   \n",
       "llm                                                    \n",
       "rag-tge_Mistral_v2-4480                         0.91   \n",
       "rag-tge_Llama-3-8B_v1                           0.94   \n",
       "rag-tge_Mistral_v2-3360                         0.92   \n",
       "rag-tge_Llama-3-8B_v2                           0.97   \n",
       "rag-tge_Llama-3-8B_v3                           0.92   \n",
       "rag-tge_Mistral_v6                              0.95   \n",
       "rag-tge_Mistral.Q8                              0.87   \n",
       "gpt-3.5-turbo-0125                              0.92   \n",
       "zephyr-orpo-141b-A35b-v0.1                      0.89   \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.91   \n",
       "gpt-4-turbo                                     0.91   \n",
       "Meta-Llama-3-70B-Instruct                       0.89   \n",
       "qwen1_5-110b-chat                               0.91   \n",
       "Meta-Llama-3-8B-Instruct                        0.91   \n",
       "Mistral-7B-Instruct-v0.2                        0.90   \n",
       "zephyr-7b-beta                                  0.91   \n",
       "qwen1_5-14b-chat-q8_0                           0.87   \n",
       "qwen1_5-32b-chat-q8_0                           0.90   \n",
       "c4ai-command-r-plus                             0.88   \n",
       "qwen1_5-7b-chat-q8_0                            0.86   \n",
       "gemma-1.1-7b-it                                 0.79   \n",
       "Phi-3-mini-4k-instruct                          0.80   \n",
       "gemma-1.1-2b-it                                 0.71   \n",
       "Mistral-7B-Instruct-v0.1                        0.84   \n",
       "\n",
       "                           correctness/citations_recall  \\\n",
       "                                                    max   \n",
       "llm                                                       \n",
       "rag-tge_Mistral_v2-4480                           0.995   \n",
       "rag-tge_Llama-3-8B_v1                             0.995   \n",
       "rag-tge_Mistral_v2-3360                           0.990   \n",
       "rag-tge_Llama-3-8B_v2                             0.985   \n",
       "rag-tge_Llama-3-8B_v3                             0.955   \n",
       "rag-tge_Mistral_v6                                0.955   \n",
       "rag-tge_Mistral.Q8                                0.930   \n",
       "gpt-3.5-turbo-0125                                0.875   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.855   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.855   \n",
       "gpt-4-turbo                                       0.820   \n",
       "Meta-Llama-3-70B-Instruct                         0.800   \n",
       "qwen1_5-110b-chat                                 0.780   \n",
       "Meta-Llama-3-8B-Instruct                          0.775   \n",
       "Mistral-7B-Instruct-v0.2                          0.775   \n",
       "zephyr-7b-beta                                    0.705   \n",
       "qwen1_5-14b-chat-q8_0                             0.690   \n",
       "qwen1_5-32b-chat-q8_0                             0.660   \n",
       "c4ai-command-r-plus                               0.615   \n",
       "qwen1_5-7b-chat-q8_0                              0.605   \n",
       "gemma-1.1-7b-it                                   0.545   \n",
       "Phi-3-mini-4k-instruct                            0.495   \n",
       "gemma-1.1-2b-it                                   0.040   \n",
       "Mistral-7B-Instruct-v0.1                          0.010   \n",
       "\n",
       "                           correctness/citations_precision  \\\n",
       "                                                       max   \n",
       "llm                                                          \n",
       "rag-tge_Mistral_v2-4480                           0.933333   \n",
       "rag-tge_Llama-3-8B_v1                             0.858667   \n",
       "rag-tge_Mistral_v2-3360                           0.918333   \n",
       "rag-tge_Llama-3-8B_v2                             0.877024   \n",
       "rag-tge_Llama-3-8B_v3                             0.955333   \n",
       "rag-tge_Mistral_v6                                0.976667   \n",
       "rag-tge_Mistral.Q8                                0.936190   \n",
       "gpt-3.5-turbo-0125                                0.962333   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.643667   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.908333   \n",
       "gpt-4-turbo                                       0.949333   \n",
       "Meta-Llama-3-70B-Instruct                         0.915333   \n",
       "qwen1_5-110b-chat                                 0.947333   \n",
       "Meta-Llama-3-8B-Instruct                          0.922000   \n",
       "Mistral-7B-Instruct-v0.2                          0.762833   \n",
       "zephyr-7b-beta                                    0.815278   \n",
       "qwen1_5-14b-chat-q8_0                             0.931667   \n",
       "qwen1_5-32b-chat-q8_0                             0.961667   \n",
       "c4ai-command-r-plus                               0.691690   \n",
       "qwen1_5-7b-chat-q8_0                              0.864000   \n",
       "gemma-1.1-7b-it                                   0.753667   \n",
       "Phi-3-mini-4k-instruct                            0.513667   \n",
       "gemma-1.1-2b-it                                   0.050000   \n",
       "Mistral-7B-Instruct-v0.1                          0.006667   \n",
       "\n",
       "                           quality/answer_relevance  \n",
       "                                                max  \n",
       "llm                                                  \n",
       "rag-tge_Mistral_v2-4480                    0.780416  \n",
       "rag-tge_Llama-3-8B_v1                      0.798084  \n",
       "rag-tge_Mistral_v2-3360                    0.782177  \n",
       "rag-tge_Llama-3-8B_v2                      0.808191  \n",
       "rag-tge_Llama-3-8B_v3                      0.790450  \n",
       "rag-tge_Mistral_v6                         0.796144  \n",
       "rag-tge_Mistral.Q8                         0.779305  \n",
       "gpt-3.5-turbo-0125                         0.787486  \n",
       "zephyr-orpo-141b-A35b-v0.1                 0.746003  \n",
       "Mixtral-8x7B-Instruct-v0.1                 0.751501  \n",
       "gpt-4-turbo                                0.777481  \n",
       "Meta-Llama-3-70B-Instruct                  0.776388  \n",
       "qwen1_5-110b-chat                          0.787043  \n",
       "Meta-Llama-3-8B-Instruct                   0.748064  \n",
       "Mistral-7B-Instruct-v0.2                   0.743680  \n",
       "zephyr-7b-beta                             0.751837  \n",
       "qwen1_5-14b-chat-q8_0                      0.754467  \n",
       "qwen1_5-32b-chat-q8_0                      0.731615  \n",
       "c4ai-command-r-plus                        0.679352  \n",
       "qwen1_5-7b-chat-q8_0                       0.797259  \n",
       "gemma-1.1-7b-it                            0.776772  \n",
       "Phi-3-mini-4k-instruct                     0.695867  \n",
       "gemma-1.1-2b-it                            0.725417  \n",
       "Mistral-7B-Instruct-v0.1                   0.760995  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/citations_precision"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.796144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.801167</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.895910</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.962333</td>\n",
       "      <td>0.787486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.534167</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.880392</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.731615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.975167</td>\n",
       "      <td>0.895744</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.790450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.885892</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.777481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.607500</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.888982</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.947333</td>\n",
       "      <td>0.787043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.864167</td>\n",
       "      <td>0.974167</td>\n",
       "      <td>0.870923</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.936190</td>\n",
       "      <td>0.779305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.855570</td>\n",
       "      <td>0.979417</td>\n",
       "      <td>0.934590</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.780416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.880154</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>0.754467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.549357</td>\n",
       "      <td>0.972143</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.748064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.813959</td>\n",
       "      <td>0.984115</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.918333</td>\n",
       "      <td>0.782177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>0.776388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.911590</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.751501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <td>0.769950</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.949359</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.877024</td>\n",
       "      <td>0.808191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.291167</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.886821</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.797259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.734354</td>\n",
       "      <td>0.978560</td>\n",
       "      <td>0.959359</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.858667</td>\n",
       "      <td>0.798084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.485310</td>\n",
       "      <td>0.977167</td>\n",
       "      <td>0.874256</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.815278</td>\n",
       "      <td>0.751837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.606238</td>\n",
       "      <td>0.901424</td>\n",
       "      <td>0.883923</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.762833</td>\n",
       "      <td>0.743680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.790846</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.753667</td>\n",
       "      <td>0.776772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.763250</td>\n",
       "      <td>0.757623</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.691690</td>\n",
       "      <td>0.679352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.537167</td>\n",
       "      <td>0.873897</td>\n",
       "      <td>0.852077</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.643667</td>\n",
       "      <td>0.746003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.281933</td>\n",
       "      <td>0.640500</td>\n",
       "      <td>0.720846</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.513667</td>\n",
       "      <td>0.695867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.667987</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.725417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.802077</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.760995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall citations/ais_precision  \\\n",
       "                                            max                     max   \n",
       "llm                                                                       \n",
       "rag-tge_Mistral_v6                     0.854167                0.970000   \n",
       "gpt-3.5-turbo-0125                     0.801167                0.997500   \n",
       "qwen1_5-32b-chat-q8_0                  0.534167                0.996667   \n",
       "rag-tge_Llama-3-8B_v3                  0.875667                0.975167   \n",
       "gpt-4-turbo                            0.775000                0.990000   \n",
       "qwen1_5-110b-chat                      0.607500                0.993333   \n",
       "rag-tge_Mistral.Q8                     0.864167                0.974167   \n",
       "rag-tge_Mistral_v2-4480                0.855570                0.979417   \n",
       "qwen1_5-14b-chat-q8_0                  0.676667                0.983333   \n",
       "Meta-Llama-3-8B-Instruct               0.549357                0.972143   \n",
       "rag-tge_Mistral_v2-3360                0.813959                0.984115   \n",
       "Meta-Llama-3-70B-Instruct              0.736667                0.970000   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.707500                0.957500   \n",
       "rag-tge_Llama-3-8B_v2                  0.769950                0.984613   \n",
       "qwen1_5-7b-chat-q8_0                   0.291167                0.910000   \n",
       "rag-tge_Llama-3-8B_v1                  0.734354                0.978560   \n",
       "zephyr-7b-beta                         0.485310                0.977167   \n",
       "Mistral-7B-Instruct-v0.2               0.606238                0.901424   \n",
       "gemma-1.1-7b-it                        0.483333                0.850000   \n",
       "c4ai-command-r-plus                    0.457500                0.763250   \n",
       "zephyr-orpo-141b-A35b-v0.1             0.537167                0.873897   \n",
       "Phi-3-mini-4k-instruct                 0.281933                0.640500   \n",
       "gemma-1.1-2b-it                        0.010000                0.055000   \n",
       "Mistral-7B-Instruct-v0.1               0.005000                0.010000   \n",
       "\n",
       "                           correctness/answer_overlap  \\\n",
       "                                                  max   \n",
       "llm                                                     \n",
       "rag-tge_Mistral_v6                           0.931256   \n",
       "gpt-3.5-turbo-0125                           0.895910   \n",
       "qwen1_5-32b-chat-q8_0                        0.880392   \n",
       "rag-tge_Llama-3-8B_v3                        0.895744   \n",
       "gpt-4-turbo                                  0.885892   \n",
       "qwen1_5-110b-chat                            0.888982   \n",
       "rag-tge_Mistral.Q8                           0.870923   \n",
       "rag-tge_Mistral_v2-4480                      0.934590   \n",
       "qwen1_5-14b-chat-q8_0                        0.880154   \n",
       "Meta-Llama-3-8B-Instruct                     0.917846   \n",
       "rag-tge_Mistral_v2-3360                      0.961667   \n",
       "Meta-Llama-3-70B-Instruct                    0.886179   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.911590   \n",
       "rag-tge_Llama-3-8B_v2                        0.949359   \n",
       "qwen1_5-7b-chat-q8_0                         0.886821   \n",
       "rag-tge_Llama-3-8B_v1                        0.959359   \n",
       "zephyr-7b-beta                               0.874256   \n",
       "Mistral-7B-Instruct-v0.2                     0.883923   \n",
       "gemma-1.1-7b-it                              0.790846   \n",
       "c4ai-command-r-plus                          0.757623   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.852077   \n",
       "Phi-3-mini-4k-instruct                       0.720846   \n",
       "gemma-1.1-2b-it                              0.667987   \n",
       "Mistral-7B-Instruct-v0.1                     0.802077   \n",
       "\n",
       "                           correctness/answer_entail  \\\n",
       "                                                 max   \n",
       "llm                                                    \n",
       "rag-tge_Mistral_v6                              0.95   \n",
       "gpt-3.5-turbo-0125                              0.92   \n",
       "qwen1_5-32b-chat-q8_0                           0.90   \n",
       "rag-tge_Llama-3-8B_v3                           0.92   \n",
       "gpt-4-turbo                                     0.91   \n",
       "qwen1_5-110b-chat                               0.91   \n",
       "rag-tge_Mistral.Q8                              0.87   \n",
       "rag-tge_Mistral_v2-4480                         0.91   \n",
       "qwen1_5-14b-chat-q8_0                           0.87   \n",
       "Meta-Llama-3-8B-Instruct                        0.91   \n",
       "rag-tge_Mistral_v2-3360                         0.92   \n",
       "Meta-Llama-3-70B-Instruct                       0.89   \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.91   \n",
       "rag-tge_Llama-3-8B_v2                           0.97   \n",
       "qwen1_5-7b-chat-q8_0                            0.86   \n",
       "rag-tge_Llama-3-8B_v1                           0.94   \n",
       "zephyr-7b-beta                                  0.91   \n",
       "Mistral-7B-Instruct-v0.2                        0.90   \n",
       "gemma-1.1-7b-it                                 0.79   \n",
       "c4ai-command-r-plus                             0.88   \n",
       "zephyr-orpo-141b-A35b-v0.1                      0.89   \n",
       "Phi-3-mini-4k-instruct                          0.80   \n",
       "gemma-1.1-2b-it                                 0.71   \n",
       "Mistral-7B-Instruct-v0.1                        0.84   \n",
       "\n",
       "                           correctness/citations_recall  \\\n",
       "                                                    max   \n",
       "llm                                                       \n",
       "rag-tge_Mistral_v6                                0.955   \n",
       "gpt-3.5-turbo-0125                                0.875   \n",
       "qwen1_5-32b-chat-q8_0                             0.660   \n",
       "rag-tge_Llama-3-8B_v3                             0.955   \n",
       "gpt-4-turbo                                       0.820   \n",
       "qwen1_5-110b-chat                                 0.780   \n",
       "rag-tge_Mistral.Q8                                0.930   \n",
       "rag-tge_Mistral_v2-4480                           0.995   \n",
       "qwen1_5-14b-chat-q8_0                             0.690   \n",
       "Meta-Llama-3-8B-Instruct                          0.775   \n",
       "rag-tge_Mistral_v2-3360                           0.990   \n",
       "Meta-Llama-3-70B-Instruct                         0.800   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.855   \n",
       "rag-tge_Llama-3-8B_v2                             0.985   \n",
       "qwen1_5-7b-chat-q8_0                              0.605   \n",
       "rag-tge_Llama-3-8B_v1                             0.995   \n",
       "zephyr-7b-beta                                    0.705   \n",
       "Mistral-7B-Instruct-v0.2                          0.775   \n",
       "gemma-1.1-7b-it                                   0.545   \n",
       "c4ai-command-r-plus                               0.615   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.855   \n",
       "Phi-3-mini-4k-instruct                            0.495   \n",
       "gemma-1.1-2b-it                                   0.040   \n",
       "Mistral-7B-Instruct-v0.1                          0.010   \n",
       "\n",
       "                           correctness/citations_precision  \\\n",
       "                                                       max   \n",
       "llm                                                          \n",
       "rag-tge_Mistral_v6                                0.976667   \n",
       "gpt-3.5-turbo-0125                                0.962333   \n",
       "qwen1_5-32b-chat-q8_0                             0.961667   \n",
       "rag-tge_Llama-3-8B_v3                             0.955333   \n",
       "gpt-4-turbo                                       0.949333   \n",
       "qwen1_5-110b-chat                                 0.947333   \n",
       "rag-tge_Mistral.Q8                                0.936190   \n",
       "rag-tge_Mistral_v2-4480                           0.933333   \n",
       "qwen1_5-14b-chat-q8_0                             0.931667   \n",
       "Meta-Llama-3-8B-Instruct                          0.922000   \n",
       "rag-tge_Mistral_v2-3360                           0.918333   \n",
       "Meta-Llama-3-70B-Instruct                         0.915333   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.908333   \n",
       "rag-tge_Llama-3-8B_v2                             0.877024   \n",
       "qwen1_5-7b-chat-q8_0                              0.864000   \n",
       "rag-tge_Llama-3-8B_v1                             0.858667   \n",
       "zephyr-7b-beta                                    0.815278   \n",
       "Mistral-7B-Instruct-v0.2                          0.762833   \n",
       "gemma-1.1-7b-it                                   0.753667   \n",
       "c4ai-command-r-plus                               0.691690   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.643667   \n",
       "Phi-3-mini-4k-instruct                            0.513667   \n",
       "gemma-1.1-2b-it                                   0.050000   \n",
       "Mistral-7B-Instruct-v0.1                          0.006667   \n",
       "\n",
       "                           quality/answer_relevance  \n",
       "                                                max  \n",
       "llm                                                  \n",
       "rag-tge_Mistral_v6                         0.796144  \n",
       "gpt-3.5-turbo-0125                         0.787486  \n",
       "qwen1_5-32b-chat-q8_0                      0.731615  \n",
       "rag-tge_Llama-3-8B_v3                      0.790450  \n",
       "gpt-4-turbo                                0.777481  \n",
       "qwen1_5-110b-chat                          0.787043  \n",
       "rag-tge_Mistral.Q8                         0.779305  \n",
       "rag-tge_Mistral_v2-4480                    0.780416  \n",
       "qwen1_5-14b-chat-q8_0                      0.754467  \n",
       "Meta-Llama-3-8B-Instruct                   0.748064  \n",
       "rag-tge_Mistral_v2-3360                    0.782177  \n",
       "Meta-Llama-3-70B-Instruct                  0.776388  \n",
       "Mixtral-8x7B-Instruct-v0.1                 0.751501  \n",
       "rag-tge_Llama-3-8B_v2                      0.808191  \n",
       "qwen1_5-7b-chat-q8_0                       0.797259  \n",
       "rag-tge_Llama-3-8B_v1                      0.798084  \n",
       "zephyr-7b-beta                             0.751837  \n",
       "Mistral-7B-Instruct-v0.2                   0.743680  \n",
       "gemma-1.1-7b-it                            0.776772  \n",
       "c4ai-command-r-plus                        0.679352  \n",
       "zephyr-orpo-141b-A35b-v0.1                 0.746003  \n",
       "Phi-3-mini-4k-instruct                     0.695867  \n",
       "gemma-1.1-2b-it                            0.725417  \n",
       "Mistral-7B-Instruct-v0.1                   0.760995  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: quality/answer_relevance"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <td>0.769950</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.949359</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.877024</td>\n",
       "      <td>0.808191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.734354</td>\n",
       "      <td>0.978560</td>\n",
       "      <td>0.959359</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.858667</td>\n",
       "      <td>0.798084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.291167</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.886821</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.797259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.796144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.975167</td>\n",
       "      <td>0.895744</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.790450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.801167</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.895910</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.962333</td>\n",
       "      <td>0.787486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.607500</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.888982</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.947333</td>\n",
       "      <td>0.787043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.813959</td>\n",
       "      <td>0.984115</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.918333</td>\n",
       "      <td>0.782177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.855570</td>\n",
       "      <td>0.979417</td>\n",
       "      <td>0.934590</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.780416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.864167</td>\n",
       "      <td>0.974167</td>\n",
       "      <td>0.870923</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.936190</td>\n",
       "      <td>0.779305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.885892</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.777481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.790846</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.753667</td>\n",
       "      <td>0.776772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>0.776388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.802077</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.760995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.880154</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>0.754467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.485310</td>\n",
       "      <td>0.977167</td>\n",
       "      <td>0.874256</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.815278</td>\n",
       "      <td>0.751837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.911590</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.751501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.549357</td>\n",
       "      <td>0.972143</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.748064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.537167</td>\n",
       "      <td>0.873897</td>\n",
       "      <td>0.852077</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.643667</td>\n",
       "      <td>0.746003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.606238</td>\n",
       "      <td>0.901424</td>\n",
       "      <td>0.883923</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.762833</td>\n",
       "      <td>0.743680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.534167</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.880392</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.731615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.667987</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.725417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.281933</td>\n",
       "      <td>0.640500</td>\n",
       "      <td>0.720846</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.513667</td>\n",
       "      <td>0.695867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.763250</td>\n",
       "      <td>0.757623</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.691690</td>\n",
       "      <td>0.679352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall citations/ais_precision  \\\n",
       "                                            max                     max   \n",
       "llm                                                                       \n",
       "rag-tge_Llama-3-8B_v2                  0.769950                0.984613   \n",
       "rag-tge_Llama-3-8B_v1                  0.734354                0.978560   \n",
       "qwen1_5-7b-chat-q8_0                   0.291167                0.910000   \n",
       "rag-tge_Mistral_v6                     0.854167                0.970000   \n",
       "rag-tge_Llama-3-8B_v3                  0.875667                0.975167   \n",
       "gpt-3.5-turbo-0125                     0.801167                0.997500   \n",
       "qwen1_5-110b-chat                      0.607500                0.993333   \n",
       "rag-tge_Mistral_v2-3360                0.813959                0.984115   \n",
       "rag-tge_Mistral_v2-4480                0.855570                0.979417   \n",
       "rag-tge_Mistral.Q8                     0.864167                0.974167   \n",
       "gpt-4-turbo                            0.775000                0.990000   \n",
       "gemma-1.1-7b-it                        0.483333                0.850000   \n",
       "Meta-Llama-3-70B-Instruct              0.736667                0.970000   \n",
       "Mistral-7B-Instruct-v0.1               0.005000                0.010000   \n",
       "qwen1_5-14b-chat-q8_0                  0.676667                0.983333   \n",
       "zephyr-7b-beta                         0.485310                0.977167   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.707500                0.957500   \n",
       "Meta-Llama-3-8B-Instruct               0.549357                0.972143   \n",
       "zephyr-orpo-141b-A35b-v0.1             0.537167                0.873897   \n",
       "Mistral-7B-Instruct-v0.2               0.606238                0.901424   \n",
       "qwen1_5-32b-chat-q8_0                  0.534167                0.996667   \n",
       "gemma-1.1-2b-it                        0.010000                0.055000   \n",
       "Phi-3-mini-4k-instruct                 0.281933                0.640500   \n",
       "c4ai-command-r-plus                    0.457500                0.763250   \n",
       "\n",
       "                           correctness/answer_overlap  \\\n",
       "                                                  max   \n",
       "llm                                                     \n",
       "rag-tge_Llama-3-8B_v2                        0.949359   \n",
       "rag-tge_Llama-3-8B_v1                        0.959359   \n",
       "qwen1_5-7b-chat-q8_0                         0.886821   \n",
       "rag-tge_Mistral_v6                           0.931256   \n",
       "rag-tge_Llama-3-8B_v3                        0.895744   \n",
       "gpt-3.5-turbo-0125                           0.895910   \n",
       "qwen1_5-110b-chat                            0.888982   \n",
       "rag-tge_Mistral_v2-3360                      0.961667   \n",
       "rag-tge_Mistral_v2-4480                      0.934590   \n",
       "rag-tge_Mistral.Q8                           0.870923   \n",
       "gpt-4-turbo                                  0.885892   \n",
       "gemma-1.1-7b-it                              0.790846   \n",
       "Meta-Llama-3-70B-Instruct                    0.886179   \n",
       "Mistral-7B-Instruct-v0.1                     0.802077   \n",
       "qwen1_5-14b-chat-q8_0                        0.880154   \n",
       "zephyr-7b-beta                               0.874256   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.911590   \n",
       "Meta-Llama-3-8B-Instruct                     0.917846   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.852077   \n",
       "Mistral-7B-Instruct-v0.2                     0.883923   \n",
       "qwen1_5-32b-chat-q8_0                        0.880392   \n",
       "gemma-1.1-2b-it                              0.667987   \n",
       "Phi-3-mini-4k-instruct                       0.720846   \n",
       "c4ai-command-r-plus                          0.757623   \n",
       "\n",
       "                           correctness/answer_entail  \\\n",
       "                                                 max   \n",
       "llm                                                    \n",
       "rag-tge_Llama-3-8B_v2                           0.97   \n",
       "rag-tge_Llama-3-8B_v1                           0.94   \n",
       "qwen1_5-7b-chat-q8_0                            0.86   \n",
       "rag-tge_Mistral_v6                              0.95   \n",
       "rag-tge_Llama-3-8B_v3                           0.92   \n",
       "gpt-3.5-turbo-0125                              0.92   \n",
       "qwen1_5-110b-chat                               0.91   \n",
       "rag-tge_Mistral_v2-3360                         0.92   \n",
       "rag-tge_Mistral_v2-4480                         0.91   \n",
       "rag-tge_Mistral.Q8                              0.87   \n",
       "gpt-4-turbo                                     0.91   \n",
       "gemma-1.1-7b-it                                 0.79   \n",
       "Meta-Llama-3-70B-Instruct                       0.89   \n",
       "Mistral-7B-Instruct-v0.1                        0.84   \n",
       "qwen1_5-14b-chat-q8_0                           0.87   \n",
       "zephyr-7b-beta                                  0.91   \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.91   \n",
       "Meta-Llama-3-8B-Instruct                        0.91   \n",
       "zephyr-orpo-141b-A35b-v0.1                      0.89   \n",
       "Mistral-7B-Instruct-v0.2                        0.90   \n",
       "qwen1_5-32b-chat-q8_0                           0.90   \n",
       "gemma-1.1-2b-it                                 0.71   \n",
       "Phi-3-mini-4k-instruct                          0.80   \n",
       "c4ai-command-r-plus                             0.88   \n",
       "\n",
       "                           correctness/citations_recall  \\\n",
       "                                                    max   \n",
       "llm                                                       \n",
       "rag-tge_Llama-3-8B_v2                             0.985   \n",
       "rag-tge_Llama-3-8B_v1                             0.995   \n",
       "qwen1_5-7b-chat-q8_0                              0.605   \n",
       "rag-tge_Mistral_v6                                0.955   \n",
       "rag-tge_Llama-3-8B_v3                             0.955   \n",
       "gpt-3.5-turbo-0125                                0.875   \n",
       "qwen1_5-110b-chat                                 0.780   \n",
       "rag-tge_Mistral_v2-3360                           0.990   \n",
       "rag-tge_Mistral_v2-4480                           0.995   \n",
       "rag-tge_Mistral.Q8                                0.930   \n",
       "gpt-4-turbo                                       0.820   \n",
       "gemma-1.1-7b-it                                   0.545   \n",
       "Meta-Llama-3-70B-Instruct                         0.800   \n",
       "Mistral-7B-Instruct-v0.1                          0.010   \n",
       "qwen1_5-14b-chat-q8_0                             0.690   \n",
       "zephyr-7b-beta                                    0.705   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.855   \n",
       "Meta-Llama-3-8B-Instruct                          0.775   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.855   \n",
       "Mistral-7B-Instruct-v0.2                          0.775   \n",
       "qwen1_5-32b-chat-q8_0                             0.660   \n",
       "gemma-1.1-2b-it                                   0.040   \n",
       "Phi-3-mini-4k-instruct                            0.495   \n",
       "c4ai-command-r-plus                               0.615   \n",
       "\n",
       "                           correctness/citations_precision  \\\n",
       "                                                       max   \n",
       "llm                                                          \n",
       "rag-tge_Llama-3-8B_v2                             0.877024   \n",
       "rag-tge_Llama-3-8B_v1                             0.858667   \n",
       "qwen1_5-7b-chat-q8_0                              0.864000   \n",
       "rag-tge_Mistral_v6                                0.976667   \n",
       "rag-tge_Llama-3-8B_v3                             0.955333   \n",
       "gpt-3.5-turbo-0125                                0.962333   \n",
       "qwen1_5-110b-chat                                 0.947333   \n",
       "rag-tge_Mistral_v2-3360                           0.918333   \n",
       "rag-tge_Mistral_v2-4480                           0.933333   \n",
       "rag-tge_Mistral.Q8                                0.936190   \n",
       "gpt-4-turbo                                       0.949333   \n",
       "gemma-1.1-7b-it                                   0.753667   \n",
       "Meta-Llama-3-70B-Instruct                         0.915333   \n",
       "Mistral-7B-Instruct-v0.1                          0.006667   \n",
       "qwen1_5-14b-chat-q8_0                             0.931667   \n",
       "zephyr-7b-beta                                    0.815278   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.908333   \n",
       "Meta-Llama-3-8B-Instruct                          0.922000   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.643667   \n",
       "Mistral-7B-Instruct-v0.2                          0.762833   \n",
       "qwen1_5-32b-chat-q8_0                             0.961667   \n",
       "gemma-1.1-2b-it                                   0.050000   \n",
       "Phi-3-mini-4k-instruct                            0.513667   \n",
       "c4ai-command-r-plus                               0.691690   \n",
       "\n",
       "                           quality/answer_relevance  \n",
       "                                                max  \n",
       "llm                                                  \n",
       "rag-tge_Llama-3-8B_v2                      0.808191  \n",
       "rag-tge_Llama-3-8B_v1                      0.798084  \n",
       "qwen1_5-7b-chat-q8_0                       0.797259  \n",
       "rag-tge_Mistral_v6                         0.796144  \n",
       "rag-tge_Llama-3-8B_v3                      0.790450  \n",
       "gpt-3.5-turbo-0125                         0.787486  \n",
       "qwen1_5-110b-chat                          0.787043  \n",
       "rag-tge_Mistral_v2-3360                    0.782177  \n",
       "rag-tge_Mistral_v2-4480                    0.780416  \n",
       "rag-tge_Mistral.Q8                         0.779305  \n",
       "gpt-4-turbo                                0.777481  \n",
       "gemma-1.1-7b-it                            0.776772  \n",
       "Meta-Llama-3-70B-Instruct                  0.776388  \n",
       "Mistral-7B-Instruct-v0.1                   0.760995  \n",
       "qwen1_5-14b-chat-q8_0                      0.754467  \n",
       "zephyr-7b-beta                             0.751837  \n",
       "Mixtral-8x7B-Instruct-v0.1                 0.751501  \n",
       "Meta-Llama-3-8B-Instruct                   0.748064  \n",
       "zephyr-orpo-141b-A35b-v0.1                 0.746003  \n",
       "Mistral-7B-Instruct-v0.2                   0.743680  \n",
       "qwen1_5-32b-chat-q8_0                      0.731615  \n",
       "gemma-1.1-2b-it                            0.725417  \n",
       "Phi-3-mini-4k-instruct                     0.695867  \n",
       "c4ai-command-r-plus                        0.679352  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# std"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: citations/ais_recall"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.063220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.059428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.043209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.049620</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.135618</td>\n",
       "      <td>0.066080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.071202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <td>0.082330</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.040207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.029156</td>\n",
       "      <td>0.045041</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.034364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.046987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall citations/ais_precision  \\\n",
       "                                            std                     std   \n",
       "llm                                                                       \n",
       "rag-tge_Mistral_v2-3360                0.146211                0.032981   \n",
       "rag-tge_Mistral_v2-4480                0.134646                0.031338   \n",
       "zephyr-orpo-141b-A35b-v0.1             0.134222                0.101052   \n",
       "gemma-1.1-7b-it                        0.122999                0.082995   \n",
       "rag-tge_Llama-3-8B_v2                  0.120419                0.049620   \n",
       "rag-tge_Llama-3-8B_v1                  0.100349                0.030020   \n",
       "qwen1_5-110b-chat                      0.095486                0.026943   \n",
       "zephyr-7b-beta                         0.090558                0.068665   \n",
       "rag-tge_Mistral_v6                     0.082330                0.023575   \n",
       "rag-tge_Llama-3-8B_v3                  0.075100                0.029156   \n",
       "gpt-3.5-turbo-0125                     0.072604                0.002887   \n",
       "qwen1_5-7b-chat-q8_0                   0.063671                0.057158   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.061199                0.029692   \n",
       "Meta-Llama-3-8B-Instruct               0.060547                0.022033   \n",
       "rag-tge_Mistral.Q8                     0.060520                0.021027   \n",
       "c4ai-command-r-plus                    0.060382                0.061399   \n",
       "Meta-Llama-3-70B-Instruct              0.049556                0.017802   \n",
       "gpt-4-turbo                            0.045401                0.005774   \n",
       "qwen1_5-14b-chat-q8_0                  0.042339                0.008660   \n",
       "Mistral-7B-Instruct-v0.2               0.036560                0.038350   \n",
       "qwen1_5-32b-chat-q8_0                  0.031856                0.002887   \n",
       "Phi-3-mini-4k-instruct                 0.030503                0.069580   \n",
       "gemma-1.1-2b-it                        0.005774                0.009623   \n",
       "Mistral-7B-Instruct-v0.1               0.000000                0.000000   \n",
       "\n",
       "                           correctness/answer_overlap  \\\n",
       "                                                  std   \n",
       "llm                                                     \n",
       "rag-tge_Mistral_v2-3360                      0.030777   \n",
       "rag-tge_Mistral_v2-4480                      0.017918   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.060333   \n",
       "gemma-1.1-7b-it                              0.075822   \n",
       "rag-tge_Llama-3-8B_v2                        0.015031   \n",
       "rag-tge_Llama-3-8B_v1                        0.013723   \n",
       "qwen1_5-110b-chat                            0.020207   \n",
       "zephyr-7b-beta                               0.028674   \n",
       "rag-tge_Mistral_v6                           0.031858   \n",
       "rag-tge_Llama-3-8B_v3                        0.045041   \n",
       "gpt-3.5-turbo-0125                           0.012990   \n",
       "qwen1_5-7b-chat-q8_0                         0.024118   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.001443   \n",
       "Meta-Llama-3-8B-Instruct                     0.000000   \n",
       "rag-tge_Mistral.Q8                           0.012892   \n",
       "c4ai-command-r-plus                          0.023094   \n",
       "Meta-Llama-3-70B-Instruct                    0.020651   \n",
       "gpt-4-turbo                                  0.007661   \n",
       "qwen1_5-14b-chat-q8_0                        0.006598   \n",
       "Mistral-7B-Instruct-v0.2                     0.014915   \n",
       "qwen1_5-32b-chat-q8_0                        0.005774   \n",
       "Phi-3-mini-4k-instruct                       0.012317   \n",
       "gemma-1.1-2b-it                              0.038105   \n",
       "Mistral-7B-Instruct-v0.1                     0.014434   \n",
       "\n",
       "                           correctness/answer_entail  \\\n",
       "                                                 std   \n",
       "llm                                                    \n",
       "rag-tge_Mistral_v2-3360                     0.011547   \n",
       "rag-tge_Mistral_v2-4480                     0.023094   \n",
       "zephyr-orpo-141b-A35b-v0.1                  0.040415   \n",
       "gemma-1.1-7b-it                             0.075056   \n",
       "rag-tge_Llama-3-8B_v2                       0.040415   \n",
       "rag-tge_Llama-3-8B_v1                       0.023094   \n",
       "qwen1_5-110b-chat                           0.017321   \n",
       "zephyr-7b-beta                              0.046188   \n",
       "rag-tge_Mistral_v6                          0.028868   \n",
       "rag-tge_Llama-3-8B_v3                       0.023094   \n",
       "gpt-3.5-turbo-0125                          0.011547   \n",
       "qwen1_5-7b-chat-q8_0                        0.023094   \n",
       "Mixtral-8x7B-Instruct-v0.1                  0.011547   \n",
       "Meta-Llama-3-8B-Instruct                    0.005774   \n",
       "rag-tge_Mistral.Q8                          0.005774   \n",
       "c4ai-command-r-plus                         0.000000   \n",
       "Meta-Llama-3-70B-Instruct                   0.017321   \n",
       "gpt-4-turbo                                 0.011547   \n",
       "qwen1_5-14b-chat-q8_0                       0.005774   \n",
       "Mistral-7B-Instruct-v0.2                    0.017321   \n",
       "qwen1_5-32b-chat-q8_0                       0.005774   \n",
       "Phi-3-mini-4k-instruct                      0.023094   \n",
       "gemma-1.1-2b-it                             0.040415   \n",
       "Mistral-7B-Instruct-v0.1                    0.017321   \n",
       "\n",
       "                           correctness/citations_recall  \\\n",
       "                                                    std   \n",
       "llm                                                       \n",
       "rag-tge_Mistral_v2-3360                        0.025981   \n",
       "rag-tge_Mistral_v2-4480                        0.025981   \n",
       "zephyr-orpo-141b-A35b-v0.1                     0.092376   \n",
       "gemma-1.1-7b-it                                0.080829   \n",
       "rag-tge_Llama-3-8B_v2                          0.005774   \n",
       "rag-tge_Llama-3-8B_v1                          0.008660   \n",
       "qwen1_5-110b-chat                              0.051962   \n",
       "zephyr-7b-beta                                 0.080056   \n",
       "rag-tge_Mistral_v6                             0.023094   \n",
       "rag-tge_Llama-3-8B_v3                          0.025207   \n",
       "gpt-3.5-turbo-0125                             0.023094   \n",
       "qwen1_5-7b-chat-q8_0                           0.074282   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.034641   \n",
       "Meta-Llama-3-8B-Instruct                       0.023094   \n",
       "rag-tge_Mistral.Q8                             0.023094   \n",
       "c4ai-command-r-plus                            0.043868   \n",
       "Meta-Llama-3-70B-Instruct                      0.017321   \n",
       "gpt-4-turbo                                    0.028868   \n",
       "qwen1_5-14b-chat-q8_0                          0.030981   \n",
       "Mistral-7B-Instruct-v0.2                       0.025981   \n",
       "qwen1_5-32b-chat-q8_0                          0.008660   \n",
       "Phi-3-mini-4k-instruct                         0.051188   \n",
       "gemma-1.1-2b-it                                0.005774   \n",
       "Mistral-7B-Instruct-v0.1                       0.000000   \n",
       "\n",
       "                           correctness/citations_precision  \\\n",
       "                                                       std   \n",
       "llm                                                          \n",
       "rag-tge_Mistral_v2-3360                           0.084337   \n",
       "rag-tge_Mistral_v2-4480                           0.070338   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.108477   \n",
       "gemma-1.1-7b-it                                   0.101471   \n",
       "rag-tge_Llama-3-8B_v2                             0.135618   \n",
       "rag-tge_Llama-3-8B_v1                             0.098810   \n",
       "qwen1_5-110b-chat                                 0.023286   \n",
       "zephyr-7b-beta                                    0.088494   \n",
       "rag-tge_Mistral_v6                                0.018283   \n",
       "rag-tge_Llama-3-8B_v3                             0.008660   \n",
       "gpt-3.5-turbo-0125                                0.023671   \n",
       "qwen1_5-7b-chat-q8_0                              0.078327   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.037528   \n",
       "Meta-Llama-3-8B-Instruct                          0.018283   \n",
       "rag-tge_Mistral.Q8                                0.040843   \n",
       "c4ai-command-r-plus                               0.054568   \n",
       "Meta-Llama-3-70B-Instruct                         0.009623   \n",
       "gpt-4-turbo                                       0.010585   \n",
       "qwen1_5-14b-chat-q8_0                             0.016358   \n",
       "Mistral-7B-Instruct-v0.2                          0.050125   \n",
       "qwen1_5-32b-chat-q8_0                             0.000000   \n",
       "Phi-3-mini-4k-instruct                            0.064275   \n",
       "gemma-1.1-2b-it                                   0.006736   \n",
       "Mistral-7B-Instruct-v0.1                          0.000000   \n",
       "\n",
       "                           quality/answer_relevance  \n",
       "                                                std  \n",
       "llm                                                  \n",
       "rag-tge_Mistral_v2-3360                    0.063220  \n",
       "rag-tge_Mistral_v2-4480                    0.055383  \n",
       "zephyr-orpo-141b-A35b-v0.1                 0.059428  \n",
       "gemma-1.1-7b-it                            0.043209  \n",
       "rag-tge_Llama-3-8B_v2                      0.066080  \n",
       "rag-tge_Llama-3-8B_v1                      0.071202  \n",
       "qwen1_5-110b-chat                          0.055224  \n",
       "zephyr-7b-beta                             0.041852  \n",
       "rag-tge_Mistral_v6                         0.040207  \n",
       "rag-tge_Llama-3-8B_v3                      0.033242  \n",
       "gpt-3.5-turbo-0125                         0.041098  \n",
       "qwen1_5-7b-chat-q8_0                       0.034364  \n",
       "Mixtral-8x7B-Instruct-v0.1                 0.030875  \n",
       "Meta-Llama-3-8B-Instruct                   0.031690  \n",
       "rag-tge_Mistral.Q8                         0.040067  \n",
       "c4ai-command-r-plus                        0.046987  \n",
       "Meta-Llama-3-70B-Instruct                  0.027829  \n",
       "gpt-4-turbo                                0.033935  \n",
       "qwen1_5-14b-chat-q8_0                      0.038641  \n",
       "Mistral-7B-Instruct-v0.2                   0.028340  \n",
       "qwen1_5-32b-chat-q8_0                      0.026912  \n",
       "Phi-3-mini-4k-instruct                     0.037250  \n",
       "gemma-1.1-2b-it                            0.019533  \n",
       "Mistral-7B-Instruct-v0.1                   0.027130  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: citations/ais_precision"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.059428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.043209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.046987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.034364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.049620</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.135618</td>\n",
       "      <td>0.066080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.063220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.071202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.029156</td>\n",
       "      <td>0.045041</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <td>0.082330</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.040207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall citations/ais_precision  \\\n",
       "                                            std                     std   \n",
       "llm                                                                       \n",
       "zephyr-orpo-141b-A35b-v0.1             0.134222                0.101052   \n",
       "gemma-1.1-7b-it                        0.122999                0.082995   \n",
       "Phi-3-mini-4k-instruct                 0.030503                0.069580   \n",
       "zephyr-7b-beta                         0.090558                0.068665   \n",
       "c4ai-command-r-plus                    0.060382                0.061399   \n",
       "qwen1_5-7b-chat-q8_0                   0.063671                0.057158   \n",
       "rag-tge_Llama-3-8B_v2                  0.120419                0.049620   \n",
       "Mistral-7B-Instruct-v0.2               0.036560                0.038350   \n",
       "rag-tge_Mistral_v2-3360                0.146211                0.032981   \n",
       "rag-tge_Mistral_v2-4480                0.134646                0.031338   \n",
       "rag-tge_Llama-3-8B_v1                  0.100349                0.030020   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.061199                0.029692   \n",
       "rag-tge_Llama-3-8B_v3                  0.075100                0.029156   \n",
       "qwen1_5-110b-chat                      0.095486                0.026943   \n",
       "rag-tge_Mistral_v6                     0.082330                0.023575   \n",
       "Meta-Llama-3-8B-Instruct               0.060547                0.022033   \n",
       "rag-tge_Mistral.Q8                     0.060520                0.021027   \n",
       "Meta-Llama-3-70B-Instruct              0.049556                0.017802   \n",
       "gemma-1.1-2b-it                        0.005774                0.009623   \n",
       "qwen1_5-14b-chat-q8_0                  0.042339                0.008660   \n",
       "gpt-4-turbo                            0.045401                0.005774   \n",
       "gpt-3.5-turbo-0125                     0.072604                0.002887   \n",
       "qwen1_5-32b-chat-q8_0                  0.031856                0.002887   \n",
       "Mistral-7B-Instruct-v0.1               0.000000                0.000000   \n",
       "\n",
       "                           correctness/answer_overlap  \\\n",
       "                                                  std   \n",
       "llm                                                     \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.060333   \n",
       "gemma-1.1-7b-it                              0.075822   \n",
       "Phi-3-mini-4k-instruct                       0.012317   \n",
       "zephyr-7b-beta                               0.028674   \n",
       "c4ai-command-r-plus                          0.023094   \n",
       "qwen1_5-7b-chat-q8_0                         0.024118   \n",
       "rag-tge_Llama-3-8B_v2                        0.015031   \n",
       "Mistral-7B-Instruct-v0.2                     0.014915   \n",
       "rag-tge_Mistral_v2-3360                      0.030777   \n",
       "rag-tge_Mistral_v2-4480                      0.017918   \n",
       "rag-tge_Llama-3-8B_v1                        0.013723   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.001443   \n",
       "rag-tge_Llama-3-8B_v3                        0.045041   \n",
       "qwen1_5-110b-chat                            0.020207   \n",
       "rag-tge_Mistral_v6                           0.031858   \n",
       "Meta-Llama-3-8B-Instruct                     0.000000   \n",
       "rag-tge_Mistral.Q8                           0.012892   \n",
       "Meta-Llama-3-70B-Instruct                    0.020651   \n",
       "gemma-1.1-2b-it                              0.038105   \n",
       "qwen1_5-14b-chat-q8_0                        0.006598   \n",
       "gpt-4-turbo                                  0.007661   \n",
       "gpt-3.5-turbo-0125                           0.012990   \n",
       "qwen1_5-32b-chat-q8_0                        0.005774   \n",
       "Mistral-7B-Instruct-v0.1                     0.014434   \n",
       "\n",
       "                           correctness/answer_entail  \\\n",
       "                                                 std   \n",
       "llm                                                    \n",
       "zephyr-orpo-141b-A35b-v0.1                  0.040415   \n",
       "gemma-1.1-7b-it                             0.075056   \n",
       "Phi-3-mini-4k-instruct                      0.023094   \n",
       "zephyr-7b-beta                              0.046188   \n",
       "c4ai-command-r-plus                         0.000000   \n",
       "qwen1_5-7b-chat-q8_0                        0.023094   \n",
       "rag-tge_Llama-3-8B_v2                       0.040415   \n",
       "Mistral-7B-Instruct-v0.2                    0.017321   \n",
       "rag-tge_Mistral_v2-3360                     0.011547   \n",
       "rag-tge_Mistral_v2-4480                     0.023094   \n",
       "rag-tge_Llama-3-8B_v1                       0.023094   \n",
       "Mixtral-8x7B-Instruct-v0.1                  0.011547   \n",
       "rag-tge_Llama-3-8B_v3                       0.023094   \n",
       "qwen1_5-110b-chat                           0.017321   \n",
       "rag-tge_Mistral_v6                          0.028868   \n",
       "Meta-Llama-3-8B-Instruct                    0.005774   \n",
       "rag-tge_Mistral.Q8                          0.005774   \n",
       "Meta-Llama-3-70B-Instruct                   0.017321   \n",
       "gemma-1.1-2b-it                             0.040415   \n",
       "qwen1_5-14b-chat-q8_0                       0.005774   \n",
       "gpt-4-turbo                                 0.011547   \n",
       "gpt-3.5-turbo-0125                          0.011547   \n",
       "qwen1_5-32b-chat-q8_0                       0.005774   \n",
       "Mistral-7B-Instruct-v0.1                    0.017321   \n",
       "\n",
       "                           correctness/citations_recall  \\\n",
       "                                                    std   \n",
       "llm                                                       \n",
       "zephyr-orpo-141b-A35b-v0.1                     0.092376   \n",
       "gemma-1.1-7b-it                                0.080829   \n",
       "Phi-3-mini-4k-instruct                         0.051188   \n",
       "zephyr-7b-beta                                 0.080056   \n",
       "c4ai-command-r-plus                            0.043868   \n",
       "qwen1_5-7b-chat-q8_0                           0.074282   \n",
       "rag-tge_Llama-3-8B_v2                          0.005774   \n",
       "Mistral-7B-Instruct-v0.2                       0.025981   \n",
       "rag-tge_Mistral_v2-3360                        0.025981   \n",
       "rag-tge_Mistral_v2-4480                        0.025981   \n",
       "rag-tge_Llama-3-8B_v1                          0.008660   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.034641   \n",
       "rag-tge_Llama-3-8B_v3                          0.025207   \n",
       "qwen1_5-110b-chat                              0.051962   \n",
       "rag-tge_Mistral_v6                             0.023094   \n",
       "Meta-Llama-3-8B-Instruct                       0.023094   \n",
       "rag-tge_Mistral.Q8                             0.023094   \n",
       "Meta-Llama-3-70B-Instruct                      0.017321   \n",
       "gemma-1.1-2b-it                                0.005774   \n",
       "qwen1_5-14b-chat-q8_0                          0.030981   \n",
       "gpt-4-turbo                                    0.028868   \n",
       "gpt-3.5-turbo-0125                             0.023094   \n",
       "qwen1_5-32b-chat-q8_0                          0.008660   \n",
       "Mistral-7B-Instruct-v0.1                       0.000000   \n",
       "\n",
       "                           correctness/citations_precision  \\\n",
       "                                                       std   \n",
       "llm                                                          \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.108477   \n",
       "gemma-1.1-7b-it                                   0.101471   \n",
       "Phi-3-mini-4k-instruct                            0.064275   \n",
       "zephyr-7b-beta                                    0.088494   \n",
       "c4ai-command-r-plus                               0.054568   \n",
       "qwen1_5-7b-chat-q8_0                              0.078327   \n",
       "rag-tge_Llama-3-8B_v2                             0.135618   \n",
       "Mistral-7B-Instruct-v0.2                          0.050125   \n",
       "rag-tge_Mistral_v2-3360                           0.084337   \n",
       "rag-tge_Mistral_v2-4480                           0.070338   \n",
       "rag-tge_Llama-3-8B_v1                             0.098810   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.037528   \n",
       "rag-tge_Llama-3-8B_v3                             0.008660   \n",
       "qwen1_5-110b-chat                                 0.023286   \n",
       "rag-tge_Mistral_v6                                0.018283   \n",
       "Meta-Llama-3-8B-Instruct                          0.018283   \n",
       "rag-tge_Mistral.Q8                                0.040843   \n",
       "Meta-Llama-3-70B-Instruct                         0.009623   \n",
       "gemma-1.1-2b-it                                   0.006736   \n",
       "qwen1_5-14b-chat-q8_0                             0.016358   \n",
       "gpt-4-turbo                                       0.010585   \n",
       "gpt-3.5-turbo-0125                                0.023671   \n",
       "qwen1_5-32b-chat-q8_0                             0.000000   \n",
       "Mistral-7B-Instruct-v0.1                          0.000000   \n",
       "\n",
       "                           quality/answer_relevance  \n",
       "                                                std  \n",
       "llm                                                  \n",
       "zephyr-orpo-141b-A35b-v0.1                 0.059428  \n",
       "gemma-1.1-7b-it                            0.043209  \n",
       "Phi-3-mini-4k-instruct                     0.037250  \n",
       "zephyr-7b-beta                             0.041852  \n",
       "c4ai-command-r-plus                        0.046987  \n",
       "qwen1_5-7b-chat-q8_0                       0.034364  \n",
       "rag-tge_Llama-3-8B_v2                      0.066080  \n",
       "Mistral-7B-Instruct-v0.2                   0.028340  \n",
       "rag-tge_Mistral_v2-3360                    0.063220  \n",
       "rag-tge_Mistral_v2-4480                    0.055383  \n",
       "rag-tge_Llama-3-8B_v1                      0.071202  \n",
       "Mixtral-8x7B-Instruct-v0.1                 0.030875  \n",
       "rag-tge_Llama-3-8B_v3                      0.033242  \n",
       "qwen1_5-110b-chat                          0.055224  \n",
       "rag-tge_Mistral_v6                         0.040207  \n",
       "Meta-Llama-3-8B-Instruct                   0.031690  \n",
       "rag-tge_Mistral.Q8                         0.040067  \n",
       "Meta-Llama-3-70B-Instruct                  0.027829  \n",
       "gemma-1.1-2b-it                            0.019533  \n",
       "qwen1_5-14b-chat-q8_0                      0.038641  \n",
       "gpt-4-turbo                                0.033935  \n",
       "gpt-3.5-turbo-0125                         0.041098  \n",
       "qwen1_5-32b-chat-q8_0                      0.026912  \n",
       "Mistral-7B-Instruct-v0.1                   0.027130  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/answer_overlap"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.043209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.059428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.029156</td>\n",
       "      <td>0.045041</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <td>0.082330</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.040207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.063220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.034364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.046987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.049620</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.135618</td>\n",
       "      <td>0.066080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.071202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall citations/ais_precision  \\\n",
       "                                            std                     std   \n",
       "llm                                                                       \n",
       "gemma-1.1-7b-it                        0.122999                0.082995   \n",
       "zephyr-orpo-141b-A35b-v0.1             0.134222                0.101052   \n",
       "rag-tge_Llama-3-8B_v3                  0.075100                0.029156   \n",
       "gemma-1.1-2b-it                        0.005774                0.009623   \n",
       "rag-tge_Mistral_v6                     0.082330                0.023575   \n",
       "rag-tge_Mistral_v2-3360                0.146211                0.032981   \n",
       "zephyr-7b-beta                         0.090558                0.068665   \n",
       "qwen1_5-7b-chat-q8_0                   0.063671                0.057158   \n",
       "c4ai-command-r-plus                    0.060382                0.061399   \n",
       "Meta-Llama-3-70B-Instruct              0.049556                0.017802   \n",
       "qwen1_5-110b-chat                      0.095486                0.026943   \n",
       "rag-tge_Mistral_v2-4480                0.134646                0.031338   \n",
       "rag-tge_Llama-3-8B_v2                  0.120419                0.049620   \n",
       "Mistral-7B-Instruct-v0.2               0.036560                0.038350   \n",
       "Mistral-7B-Instruct-v0.1               0.000000                0.000000   \n",
       "rag-tge_Llama-3-8B_v1                  0.100349                0.030020   \n",
       "gpt-3.5-turbo-0125                     0.072604                0.002887   \n",
       "rag-tge_Mistral.Q8                     0.060520                0.021027   \n",
       "Phi-3-mini-4k-instruct                 0.030503                0.069580   \n",
       "gpt-4-turbo                            0.045401                0.005774   \n",
       "qwen1_5-14b-chat-q8_0                  0.042339                0.008660   \n",
       "qwen1_5-32b-chat-q8_0                  0.031856                0.002887   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.061199                0.029692   \n",
       "Meta-Llama-3-8B-Instruct               0.060547                0.022033   \n",
       "\n",
       "                           correctness/answer_overlap  \\\n",
       "                                                  std   \n",
       "llm                                                     \n",
       "gemma-1.1-7b-it                              0.075822   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.060333   \n",
       "rag-tge_Llama-3-8B_v3                        0.045041   \n",
       "gemma-1.1-2b-it                              0.038105   \n",
       "rag-tge_Mistral_v6                           0.031858   \n",
       "rag-tge_Mistral_v2-3360                      0.030777   \n",
       "zephyr-7b-beta                               0.028674   \n",
       "qwen1_5-7b-chat-q8_0                         0.024118   \n",
       "c4ai-command-r-plus                          0.023094   \n",
       "Meta-Llama-3-70B-Instruct                    0.020651   \n",
       "qwen1_5-110b-chat                            0.020207   \n",
       "rag-tge_Mistral_v2-4480                      0.017918   \n",
       "rag-tge_Llama-3-8B_v2                        0.015031   \n",
       "Mistral-7B-Instruct-v0.2                     0.014915   \n",
       "Mistral-7B-Instruct-v0.1                     0.014434   \n",
       "rag-tge_Llama-3-8B_v1                        0.013723   \n",
       "gpt-3.5-turbo-0125                           0.012990   \n",
       "rag-tge_Mistral.Q8                           0.012892   \n",
       "Phi-3-mini-4k-instruct                       0.012317   \n",
       "gpt-4-turbo                                  0.007661   \n",
       "qwen1_5-14b-chat-q8_0                        0.006598   \n",
       "qwen1_5-32b-chat-q8_0                        0.005774   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.001443   \n",
       "Meta-Llama-3-8B-Instruct                     0.000000   \n",
       "\n",
       "                           correctness/answer_entail  \\\n",
       "                                                 std   \n",
       "llm                                                    \n",
       "gemma-1.1-7b-it                             0.075056   \n",
       "zephyr-orpo-141b-A35b-v0.1                  0.040415   \n",
       "rag-tge_Llama-3-8B_v3                       0.023094   \n",
       "gemma-1.1-2b-it                             0.040415   \n",
       "rag-tge_Mistral_v6                          0.028868   \n",
       "rag-tge_Mistral_v2-3360                     0.011547   \n",
       "zephyr-7b-beta                              0.046188   \n",
       "qwen1_5-7b-chat-q8_0                        0.023094   \n",
       "c4ai-command-r-plus                         0.000000   \n",
       "Meta-Llama-3-70B-Instruct                   0.017321   \n",
       "qwen1_5-110b-chat                           0.017321   \n",
       "rag-tge_Mistral_v2-4480                     0.023094   \n",
       "rag-tge_Llama-3-8B_v2                       0.040415   \n",
       "Mistral-7B-Instruct-v0.2                    0.017321   \n",
       "Mistral-7B-Instruct-v0.1                    0.017321   \n",
       "rag-tge_Llama-3-8B_v1                       0.023094   \n",
       "gpt-3.5-turbo-0125                          0.011547   \n",
       "rag-tge_Mistral.Q8                          0.005774   \n",
       "Phi-3-mini-4k-instruct                      0.023094   \n",
       "gpt-4-turbo                                 0.011547   \n",
       "qwen1_5-14b-chat-q8_0                       0.005774   \n",
       "qwen1_5-32b-chat-q8_0                       0.005774   \n",
       "Mixtral-8x7B-Instruct-v0.1                  0.011547   \n",
       "Meta-Llama-3-8B-Instruct                    0.005774   \n",
       "\n",
       "                           correctness/citations_recall  \\\n",
       "                                                    std   \n",
       "llm                                                       \n",
       "gemma-1.1-7b-it                                0.080829   \n",
       "zephyr-orpo-141b-A35b-v0.1                     0.092376   \n",
       "rag-tge_Llama-3-8B_v3                          0.025207   \n",
       "gemma-1.1-2b-it                                0.005774   \n",
       "rag-tge_Mistral_v6                             0.023094   \n",
       "rag-tge_Mistral_v2-3360                        0.025981   \n",
       "zephyr-7b-beta                                 0.080056   \n",
       "qwen1_5-7b-chat-q8_0                           0.074282   \n",
       "c4ai-command-r-plus                            0.043868   \n",
       "Meta-Llama-3-70B-Instruct                      0.017321   \n",
       "qwen1_5-110b-chat                              0.051962   \n",
       "rag-tge_Mistral_v2-4480                        0.025981   \n",
       "rag-tge_Llama-3-8B_v2                          0.005774   \n",
       "Mistral-7B-Instruct-v0.2                       0.025981   \n",
       "Mistral-7B-Instruct-v0.1                       0.000000   \n",
       "rag-tge_Llama-3-8B_v1                          0.008660   \n",
       "gpt-3.5-turbo-0125                             0.023094   \n",
       "rag-tge_Mistral.Q8                             0.023094   \n",
       "Phi-3-mini-4k-instruct                         0.051188   \n",
       "gpt-4-turbo                                    0.028868   \n",
       "qwen1_5-14b-chat-q8_0                          0.030981   \n",
       "qwen1_5-32b-chat-q8_0                          0.008660   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.034641   \n",
       "Meta-Llama-3-8B-Instruct                       0.023094   \n",
       "\n",
       "                           correctness/citations_precision  \\\n",
       "                                                       std   \n",
       "llm                                                          \n",
       "gemma-1.1-7b-it                                   0.101471   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.108477   \n",
       "rag-tge_Llama-3-8B_v3                             0.008660   \n",
       "gemma-1.1-2b-it                                   0.006736   \n",
       "rag-tge_Mistral_v6                                0.018283   \n",
       "rag-tge_Mistral_v2-3360                           0.084337   \n",
       "zephyr-7b-beta                                    0.088494   \n",
       "qwen1_5-7b-chat-q8_0                              0.078327   \n",
       "c4ai-command-r-plus                               0.054568   \n",
       "Meta-Llama-3-70B-Instruct                         0.009623   \n",
       "qwen1_5-110b-chat                                 0.023286   \n",
       "rag-tge_Mistral_v2-4480                           0.070338   \n",
       "rag-tge_Llama-3-8B_v2                             0.135618   \n",
       "Mistral-7B-Instruct-v0.2                          0.050125   \n",
       "Mistral-7B-Instruct-v0.1                          0.000000   \n",
       "rag-tge_Llama-3-8B_v1                             0.098810   \n",
       "gpt-3.5-turbo-0125                                0.023671   \n",
       "rag-tge_Mistral.Q8                                0.040843   \n",
       "Phi-3-mini-4k-instruct                            0.064275   \n",
       "gpt-4-turbo                                       0.010585   \n",
       "qwen1_5-14b-chat-q8_0                             0.016358   \n",
       "qwen1_5-32b-chat-q8_0                             0.000000   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.037528   \n",
       "Meta-Llama-3-8B-Instruct                          0.018283   \n",
       "\n",
       "                           quality/answer_relevance  \n",
       "                                                std  \n",
       "llm                                                  \n",
       "gemma-1.1-7b-it                            0.043209  \n",
       "zephyr-orpo-141b-A35b-v0.1                 0.059428  \n",
       "rag-tge_Llama-3-8B_v3                      0.033242  \n",
       "gemma-1.1-2b-it                            0.019533  \n",
       "rag-tge_Mistral_v6                         0.040207  \n",
       "rag-tge_Mistral_v2-3360                    0.063220  \n",
       "zephyr-7b-beta                             0.041852  \n",
       "qwen1_5-7b-chat-q8_0                       0.034364  \n",
       "c4ai-command-r-plus                        0.046987  \n",
       "Meta-Llama-3-70B-Instruct                  0.027829  \n",
       "qwen1_5-110b-chat                          0.055224  \n",
       "rag-tge_Mistral_v2-4480                    0.055383  \n",
       "rag-tge_Llama-3-8B_v2                      0.066080  \n",
       "Mistral-7B-Instruct-v0.2                   0.028340  \n",
       "Mistral-7B-Instruct-v0.1                   0.027130  \n",
       "rag-tge_Llama-3-8B_v1                      0.071202  \n",
       "gpt-3.5-turbo-0125                         0.041098  \n",
       "rag-tge_Mistral.Q8                         0.040067  \n",
       "Phi-3-mini-4k-instruct                     0.037250  \n",
       "gpt-4-turbo                                0.033935  \n",
       "qwen1_5-14b-chat-q8_0                      0.038641  \n",
       "qwen1_5-32b-chat-q8_0                      0.026912  \n",
       "Mixtral-8x7B-Instruct-v0.1                 0.030875  \n",
       "Meta-Llama-3-8B-Instruct                   0.031690  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/answer_entail"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.043209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.049620</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.135618</td>\n",
       "      <td>0.066080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.059428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <td>0.082330</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.040207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.071202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.034364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.029156</td>\n",
       "      <td>0.045041</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.063220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.046987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall citations/ais_precision  \\\n",
       "                                            std                     std   \n",
       "llm                                                                       \n",
       "gemma-1.1-7b-it                        0.122999                0.082995   \n",
       "zephyr-7b-beta                         0.090558                0.068665   \n",
       "rag-tge_Llama-3-8B_v2                  0.120419                0.049620   \n",
       "gemma-1.1-2b-it                        0.005774                0.009623   \n",
       "zephyr-orpo-141b-A35b-v0.1             0.134222                0.101052   \n",
       "rag-tge_Mistral_v6                     0.082330                0.023575   \n",
       "rag-tge_Llama-3-8B_v1                  0.100349                0.030020   \n",
       "rag-tge_Mistral_v2-4480                0.134646                0.031338   \n",
       "Phi-3-mini-4k-instruct                 0.030503                0.069580   \n",
       "qwen1_5-7b-chat-q8_0                   0.063671                0.057158   \n",
       "rag-tge_Llama-3-8B_v3                  0.075100                0.029156   \n",
       "qwen1_5-110b-chat                      0.095486                0.026943   \n",
       "Mistral-7B-Instruct-v0.1               0.000000                0.000000   \n",
       "Mistral-7B-Instruct-v0.2               0.036560                0.038350   \n",
       "Meta-Llama-3-70B-Instruct              0.049556                0.017802   \n",
       "rag-tge_Mistral_v2-3360                0.146211                0.032981   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.061199                0.029692   \n",
       "gpt-3.5-turbo-0125                     0.072604                0.002887   \n",
       "gpt-4-turbo                            0.045401                0.005774   \n",
       "rag-tge_Mistral.Q8                     0.060520                0.021027   \n",
       "Meta-Llama-3-8B-Instruct               0.060547                0.022033   \n",
       "qwen1_5-14b-chat-q8_0                  0.042339                0.008660   \n",
       "qwen1_5-32b-chat-q8_0                  0.031856                0.002887   \n",
       "c4ai-command-r-plus                    0.060382                0.061399   \n",
       "\n",
       "                           correctness/answer_overlap  \\\n",
       "                                                  std   \n",
       "llm                                                     \n",
       "gemma-1.1-7b-it                              0.075822   \n",
       "zephyr-7b-beta                               0.028674   \n",
       "rag-tge_Llama-3-8B_v2                        0.015031   \n",
       "gemma-1.1-2b-it                              0.038105   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.060333   \n",
       "rag-tge_Mistral_v6                           0.031858   \n",
       "rag-tge_Llama-3-8B_v1                        0.013723   \n",
       "rag-tge_Mistral_v2-4480                      0.017918   \n",
       "Phi-3-mini-4k-instruct                       0.012317   \n",
       "qwen1_5-7b-chat-q8_0                         0.024118   \n",
       "rag-tge_Llama-3-8B_v3                        0.045041   \n",
       "qwen1_5-110b-chat                            0.020207   \n",
       "Mistral-7B-Instruct-v0.1                     0.014434   \n",
       "Mistral-7B-Instruct-v0.2                     0.014915   \n",
       "Meta-Llama-3-70B-Instruct                    0.020651   \n",
       "rag-tge_Mistral_v2-3360                      0.030777   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.001443   \n",
       "gpt-3.5-turbo-0125                           0.012990   \n",
       "gpt-4-turbo                                  0.007661   \n",
       "rag-tge_Mistral.Q8                           0.012892   \n",
       "Meta-Llama-3-8B-Instruct                     0.000000   \n",
       "qwen1_5-14b-chat-q8_0                        0.006598   \n",
       "qwen1_5-32b-chat-q8_0                        0.005774   \n",
       "c4ai-command-r-plus                          0.023094   \n",
       "\n",
       "                           correctness/answer_entail  \\\n",
       "                                                 std   \n",
       "llm                                                    \n",
       "gemma-1.1-7b-it                             0.075056   \n",
       "zephyr-7b-beta                              0.046188   \n",
       "rag-tge_Llama-3-8B_v2                       0.040415   \n",
       "gemma-1.1-2b-it                             0.040415   \n",
       "zephyr-orpo-141b-A35b-v0.1                  0.040415   \n",
       "rag-tge_Mistral_v6                          0.028868   \n",
       "rag-tge_Llama-3-8B_v1                       0.023094   \n",
       "rag-tge_Mistral_v2-4480                     0.023094   \n",
       "Phi-3-mini-4k-instruct                      0.023094   \n",
       "qwen1_5-7b-chat-q8_0                        0.023094   \n",
       "rag-tge_Llama-3-8B_v3                       0.023094   \n",
       "qwen1_5-110b-chat                           0.017321   \n",
       "Mistral-7B-Instruct-v0.1                    0.017321   \n",
       "Mistral-7B-Instruct-v0.2                    0.017321   \n",
       "Meta-Llama-3-70B-Instruct                   0.017321   \n",
       "rag-tge_Mistral_v2-3360                     0.011547   \n",
       "Mixtral-8x7B-Instruct-v0.1                  0.011547   \n",
       "gpt-3.5-turbo-0125                          0.011547   \n",
       "gpt-4-turbo                                 0.011547   \n",
       "rag-tge_Mistral.Q8                          0.005774   \n",
       "Meta-Llama-3-8B-Instruct                    0.005774   \n",
       "qwen1_5-14b-chat-q8_0                       0.005774   \n",
       "qwen1_5-32b-chat-q8_0                       0.005774   \n",
       "c4ai-command-r-plus                         0.000000   \n",
       "\n",
       "                           correctness/citations_recall  \\\n",
       "                                                    std   \n",
       "llm                                                       \n",
       "gemma-1.1-7b-it                                0.080829   \n",
       "zephyr-7b-beta                                 0.080056   \n",
       "rag-tge_Llama-3-8B_v2                          0.005774   \n",
       "gemma-1.1-2b-it                                0.005774   \n",
       "zephyr-orpo-141b-A35b-v0.1                     0.092376   \n",
       "rag-tge_Mistral_v6                             0.023094   \n",
       "rag-tge_Llama-3-8B_v1                          0.008660   \n",
       "rag-tge_Mistral_v2-4480                        0.025981   \n",
       "Phi-3-mini-4k-instruct                         0.051188   \n",
       "qwen1_5-7b-chat-q8_0                           0.074282   \n",
       "rag-tge_Llama-3-8B_v3                          0.025207   \n",
       "qwen1_5-110b-chat                              0.051962   \n",
       "Mistral-7B-Instruct-v0.1                       0.000000   \n",
       "Mistral-7B-Instruct-v0.2                       0.025981   \n",
       "Meta-Llama-3-70B-Instruct                      0.017321   \n",
       "rag-tge_Mistral_v2-3360                        0.025981   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.034641   \n",
       "gpt-3.5-turbo-0125                             0.023094   \n",
       "gpt-4-turbo                                    0.028868   \n",
       "rag-tge_Mistral.Q8                             0.023094   \n",
       "Meta-Llama-3-8B-Instruct                       0.023094   \n",
       "qwen1_5-14b-chat-q8_0                          0.030981   \n",
       "qwen1_5-32b-chat-q8_0                          0.008660   \n",
       "c4ai-command-r-plus                            0.043868   \n",
       "\n",
       "                           correctness/citations_precision  \\\n",
       "                                                       std   \n",
       "llm                                                          \n",
       "gemma-1.1-7b-it                                   0.101471   \n",
       "zephyr-7b-beta                                    0.088494   \n",
       "rag-tge_Llama-3-8B_v2                             0.135618   \n",
       "gemma-1.1-2b-it                                   0.006736   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.108477   \n",
       "rag-tge_Mistral_v6                                0.018283   \n",
       "rag-tge_Llama-3-8B_v1                             0.098810   \n",
       "rag-tge_Mistral_v2-4480                           0.070338   \n",
       "Phi-3-mini-4k-instruct                            0.064275   \n",
       "qwen1_5-7b-chat-q8_0                              0.078327   \n",
       "rag-tge_Llama-3-8B_v3                             0.008660   \n",
       "qwen1_5-110b-chat                                 0.023286   \n",
       "Mistral-7B-Instruct-v0.1                          0.000000   \n",
       "Mistral-7B-Instruct-v0.2                          0.050125   \n",
       "Meta-Llama-3-70B-Instruct                         0.009623   \n",
       "rag-tge_Mistral_v2-3360                           0.084337   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.037528   \n",
       "gpt-3.5-turbo-0125                                0.023671   \n",
       "gpt-4-turbo                                       0.010585   \n",
       "rag-tge_Mistral.Q8                                0.040843   \n",
       "Meta-Llama-3-8B-Instruct                          0.018283   \n",
       "qwen1_5-14b-chat-q8_0                             0.016358   \n",
       "qwen1_5-32b-chat-q8_0                             0.000000   \n",
       "c4ai-command-r-plus                               0.054568   \n",
       "\n",
       "                           quality/answer_relevance  \n",
       "                                                std  \n",
       "llm                                                  \n",
       "gemma-1.1-7b-it                            0.043209  \n",
       "zephyr-7b-beta                             0.041852  \n",
       "rag-tge_Llama-3-8B_v2                      0.066080  \n",
       "gemma-1.1-2b-it                            0.019533  \n",
       "zephyr-orpo-141b-A35b-v0.1                 0.059428  \n",
       "rag-tge_Mistral_v6                         0.040207  \n",
       "rag-tge_Llama-3-8B_v1                      0.071202  \n",
       "rag-tge_Mistral_v2-4480                    0.055383  \n",
       "Phi-3-mini-4k-instruct                     0.037250  \n",
       "qwen1_5-7b-chat-q8_0                       0.034364  \n",
       "rag-tge_Llama-3-8B_v3                      0.033242  \n",
       "qwen1_5-110b-chat                          0.055224  \n",
       "Mistral-7B-Instruct-v0.1                   0.027130  \n",
       "Mistral-7B-Instruct-v0.2                   0.028340  \n",
       "Meta-Llama-3-70B-Instruct                  0.027829  \n",
       "rag-tge_Mistral_v2-3360                    0.063220  \n",
       "Mixtral-8x7B-Instruct-v0.1                 0.030875  \n",
       "gpt-3.5-turbo-0125                         0.041098  \n",
       "gpt-4-turbo                                0.033935  \n",
       "rag-tge_Mistral.Q8                         0.040067  \n",
       "Meta-Llama-3-8B-Instruct                   0.031690  \n",
       "qwen1_5-14b-chat-q8_0                      0.038641  \n",
       "qwen1_5-32b-chat-q8_0                      0.026912  \n",
       "c4ai-command-r-plus                        0.046987  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/citations_recall"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.059428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.043209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.034364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.046987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.063220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.029156</td>\n",
       "      <td>0.045041</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <td>0.082330</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.040207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.071202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.049620</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.135618</td>\n",
       "      <td>0.066080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall citations/ais_precision  \\\n",
       "                                            std                     std   \n",
       "llm                                                                       \n",
       "zephyr-orpo-141b-A35b-v0.1             0.134222                0.101052   \n",
       "gemma-1.1-7b-it                        0.122999                0.082995   \n",
       "zephyr-7b-beta                         0.090558                0.068665   \n",
       "qwen1_5-7b-chat-q8_0                   0.063671                0.057158   \n",
       "qwen1_5-110b-chat                      0.095486                0.026943   \n",
       "Phi-3-mini-4k-instruct                 0.030503                0.069580   \n",
       "c4ai-command-r-plus                    0.060382                0.061399   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.061199                0.029692   \n",
       "qwen1_5-14b-chat-q8_0                  0.042339                0.008660   \n",
       "gpt-4-turbo                            0.045401                0.005774   \n",
       "Mistral-7B-Instruct-v0.2               0.036560                0.038350   \n",
       "rag-tge_Mistral_v2-4480                0.134646                0.031338   \n",
       "rag-tge_Mistral_v2-3360                0.146211                0.032981   \n",
       "rag-tge_Llama-3-8B_v3                  0.075100                0.029156   \n",
       "Meta-Llama-3-8B-Instruct               0.060547                0.022033   \n",
       "rag-tge_Mistral_v6                     0.082330                0.023575   \n",
       "gpt-3.5-turbo-0125                     0.072604                0.002887   \n",
       "rag-tge_Mistral.Q8                     0.060520                0.021027   \n",
       "Meta-Llama-3-70B-Instruct              0.049556                0.017802   \n",
       "rag-tge_Llama-3-8B_v1                  0.100349                0.030020   \n",
       "qwen1_5-32b-chat-q8_0                  0.031856                0.002887   \n",
       "rag-tge_Llama-3-8B_v2                  0.120419                0.049620   \n",
       "gemma-1.1-2b-it                        0.005774                0.009623   \n",
       "Mistral-7B-Instruct-v0.1               0.000000                0.000000   \n",
       "\n",
       "                           correctness/answer_overlap  \\\n",
       "                                                  std   \n",
       "llm                                                     \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.060333   \n",
       "gemma-1.1-7b-it                              0.075822   \n",
       "zephyr-7b-beta                               0.028674   \n",
       "qwen1_5-7b-chat-q8_0                         0.024118   \n",
       "qwen1_5-110b-chat                            0.020207   \n",
       "Phi-3-mini-4k-instruct                       0.012317   \n",
       "c4ai-command-r-plus                          0.023094   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.001443   \n",
       "qwen1_5-14b-chat-q8_0                        0.006598   \n",
       "gpt-4-turbo                                  0.007661   \n",
       "Mistral-7B-Instruct-v0.2                     0.014915   \n",
       "rag-tge_Mistral_v2-4480                      0.017918   \n",
       "rag-tge_Mistral_v2-3360                      0.030777   \n",
       "rag-tge_Llama-3-8B_v3                        0.045041   \n",
       "Meta-Llama-3-8B-Instruct                     0.000000   \n",
       "rag-tge_Mistral_v6                           0.031858   \n",
       "gpt-3.5-turbo-0125                           0.012990   \n",
       "rag-tge_Mistral.Q8                           0.012892   \n",
       "Meta-Llama-3-70B-Instruct                    0.020651   \n",
       "rag-tge_Llama-3-8B_v1                        0.013723   \n",
       "qwen1_5-32b-chat-q8_0                        0.005774   \n",
       "rag-tge_Llama-3-8B_v2                        0.015031   \n",
       "gemma-1.1-2b-it                              0.038105   \n",
       "Mistral-7B-Instruct-v0.1                     0.014434   \n",
       "\n",
       "                           correctness/answer_entail  \\\n",
       "                                                 std   \n",
       "llm                                                    \n",
       "zephyr-orpo-141b-A35b-v0.1                  0.040415   \n",
       "gemma-1.1-7b-it                             0.075056   \n",
       "zephyr-7b-beta                              0.046188   \n",
       "qwen1_5-7b-chat-q8_0                        0.023094   \n",
       "qwen1_5-110b-chat                           0.017321   \n",
       "Phi-3-mini-4k-instruct                      0.023094   \n",
       "c4ai-command-r-plus                         0.000000   \n",
       "Mixtral-8x7B-Instruct-v0.1                  0.011547   \n",
       "qwen1_5-14b-chat-q8_0                       0.005774   \n",
       "gpt-4-turbo                                 0.011547   \n",
       "Mistral-7B-Instruct-v0.2                    0.017321   \n",
       "rag-tge_Mistral_v2-4480                     0.023094   \n",
       "rag-tge_Mistral_v2-3360                     0.011547   \n",
       "rag-tge_Llama-3-8B_v3                       0.023094   \n",
       "Meta-Llama-3-8B-Instruct                    0.005774   \n",
       "rag-tge_Mistral_v6                          0.028868   \n",
       "gpt-3.5-turbo-0125                          0.011547   \n",
       "rag-tge_Mistral.Q8                          0.005774   \n",
       "Meta-Llama-3-70B-Instruct                   0.017321   \n",
       "rag-tge_Llama-3-8B_v1                       0.023094   \n",
       "qwen1_5-32b-chat-q8_0                       0.005774   \n",
       "rag-tge_Llama-3-8B_v2                       0.040415   \n",
       "gemma-1.1-2b-it                             0.040415   \n",
       "Mistral-7B-Instruct-v0.1                    0.017321   \n",
       "\n",
       "                           correctness/citations_recall  \\\n",
       "                                                    std   \n",
       "llm                                                       \n",
       "zephyr-orpo-141b-A35b-v0.1                     0.092376   \n",
       "gemma-1.1-7b-it                                0.080829   \n",
       "zephyr-7b-beta                                 0.080056   \n",
       "qwen1_5-7b-chat-q8_0                           0.074282   \n",
       "qwen1_5-110b-chat                              0.051962   \n",
       "Phi-3-mini-4k-instruct                         0.051188   \n",
       "c4ai-command-r-plus                            0.043868   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.034641   \n",
       "qwen1_5-14b-chat-q8_0                          0.030981   \n",
       "gpt-4-turbo                                    0.028868   \n",
       "Mistral-7B-Instruct-v0.2                       0.025981   \n",
       "rag-tge_Mistral_v2-4480                        0.025981   \n",
       "rag-tge_Mistral_v2-3360                        0.025981   \n",
       "rag-tge_Llama-3-8B_v3                          0.025207   \n",
       "Meta-Llama-3-8B-Instruct                       0.023094   \n",
       "rag-tge_Mistral_v6                             0.023094   \n",
       "gpt-3.5-turbo-0125                             0.023094   \n",
       "rag-tge_Mistral.Q8                             0.023094   \n",
       "Meta-Llama-3-70B-Instruct                      0.017321   \n",
       "rag-tge_Llama-3-8B_v1                          0.008660   \n",
       "qwen1_5-32b-chat-q8_0                          0.008660   \n",
       "rag-tge_Llama-3-8B_v2                          0.005774   \n",
       "gemma-1.1-2b-it                                0.005774   \n",
       "Mistral-7B-Instruct-v0.1                       0.000000   \n",
       "\n",
       "                           correctness/citations_precision  \\\n",
       "                                                       std   \n",
       "llm                                                          \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.108477   \n",
       "gemma-1.1-7b-it                                   0.101471   \n",
       "zephyr-7b-beta                                    0.088494   \n",
       "qwen1_5-7b-chat-q8_0                              0.078327   \n",
       "qwen1_5-110b-chat                                 0.023286   \n",
       "Phi-3-mini-4k-instruct                            0.064275   \n",
       "c4ai-command-r-plus                               0.054568   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.037528   \n",
       "qwen1_5-14b-chat-q8_0                             0.016358   \n",
       "gpt-4-turbo                                       0.010585   \n",
       "Mistral-7B-Instruct-v0.2                          0.050125   \n",
       "rag-tge_Mistral_v2-4480                           0.070338   \n",
       "rag-tge_Mistral_v2-3360                           0.084337   \n",
       "rag-tge_Llama-3-8B_v3                             0.008660   \n",
       "Meta-Llama-3-8B-Instruct                          0.018283   \n",
       "rag-tge_Mistral_v6                                0.018283   \n",
       "gpt-3.5-turbo-0125                                0.023671   \n",
       "rag-tge_Mistral.Q8                                0.040843   \n",
       "Meta-Llama-3-70B-Instruct                         0.009623   \n",
       "rag-tge_Llama-3-8B_v1                             0.098810   \n",
       "qwen1_5-32b-chat-q8_0                             0.000000   \n",
       "rag-tge_Llama-3-8B_v2                             0.135618   \n",
       "gemma-1.1-2b-it                                   0.006736   \n",
       "Mistral-7B-Instruct-v0.1                          0.000000   \n",
       "\n",
       "                           quality/answer_relevance  \n",
       "                                                std  \n",
       "llm                                                  \n",
       "zephyr-orpo-141b-A35b-v0.1                 0.059428  \n",
       "gemma-1.1-7b-it                            0.043209  \n",
       "zephyr-7b-beta                             0.041852  \n",
       "qwen1_5-7b-chat-q8_0                       0.034364  \n",
       "qwen1_5-110b-chat                          0.055224  \n",
       "Phi-3-mini-4k-instruct                     0.037250  \n",
       "c4ai-command-r-plus                        0.046987  \n",
       "Mixtral-8x7B-Instruct-v0.1                 0.030875  \n",
       "qwen1_5-14b-chat-q8_0                      0.038641  \n",
       "gpt-4-turbo                                0.033935  \n",
       "Mistral-7B-Instruct-v0.2                   0.028340  \n",
       "rag-tge_Mistral_v2-4480                    0.055383  \n",
       "rag-tge_Mistral_v2-3360                    0.063220  \n",
       "rag-tge_Llama-3-8B_v3                      0.033242  \n",
       "Meta-Llama-3-8B-Instruct                   0.031690  \n",
       "rag-tge_Mistral_v6                         0.040207  \n",
       "gpt-3.5-turbo-0125                         0.041098  \n",
       "rag-tge_Mistral.Q8                         0.040067  \n",
       "Meta-Llama-3-70B-Instruct                  0.027829  \n",
       "rag-tge_Llama-3-8B_v1                      0.071202  \n",
       "qwen1_5-32b-chat-q8_0                      0.026912  \n",
       "rag-tge_Llama-3-8B_v2                      0.066080  \n",
       "gemma-1.1-2b-it                            0.019533  \n",
       "Mistral-7B-Instruct-v0.1                   0.027130  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/citations_precision"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.049620</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.135618</td>\n",
       "      <td>0.066080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.059428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.043209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.071202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.063220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.034364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.046987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <td>0.082330</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.040207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.029156</td>\n",
       "      <td>0.045041</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall citations/ais_precision  \\\n",
       "                                            std                     std   \n",
       "llm                                                                       \n",
       "rag-tge_Llama-3-8B_v2                  0.120419                0.049620   \n",
       "zephyr-orpo-141b-A35b-v0.1             0.134222                0.101052   \n",
       "gemma-1.1-7b-it                        0.122999                0.082995   \n",
       "rag-tge_Llama-3-8B_v1                  0.100349                0.030020   \n",
       "zephyr-7b-beta                         0.090558                0.068665   \n",
       "rag-tge_Mistral_v2-3360                0.146211                0.032981   \n",
       "qwen1_5-7b-chat-q8_0                   0.063671                0.057158   \n",
       "rag-tge_Mistral_v2-4480                0.134646                0.031338   \n",
       "Phi-3-mini-4k-instruct                 0.030503                0.069580   \n",
       "c4ai-command-r-plus                    0.060382                0.061399   \n",
       "Mistral-7B-Instruct-v0.2               0.036560                0.038350   \n",
       "rag-tge_Mistral.Q8                     0.060520                0.021027   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.061199                0.029692   \n",
       "gpt-3.5-turbo-0125                     0.072604                0.002887   \n",
       "qwen1_5-110b-chat                      0.095486                0.026943   \n",
       "Meta-Llama-3-8B-Instruct               0.060547                0.022033   \n",
       "rag-tge_Mistral_v6                     0.082330                0.023575   \n",
       "qwen1_5-14b-chat-q8_0                  0.042339                0.008660   \n",
       "gpt-4-turbo                            0.045401                0.005774   \n",
       "Meta-Llama-3-70B-Instruct              0.049556                0.017802   \n",
       "rag-tge_Llama-3-8B_v3                  0.075100                0.029156   \n",
       "gemma-1.1-2b-it                        0.005774                0.009623   \n",
       "qwen1_5-32b-chat-q8_0                  0.031856                0.002887   \n",
       "Mistral-7B-Instruct-v0.1               0.000000                0.000000   \n",
       "\n",
       "                           correctness/answer_overlap  \\\n",
       "                                                  std   \n",
       "llm                                                     \n",
       "rag-tge_Llama-3-8B_v2                        0.015031   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.060333   \n",
       "gemma-1.1-7b-it                              0.075822   \n",
       "rag-tge_Llama-3-8B_v1                        0.013723   \n",
       "zephyr-7b-beta                               0.028674   \n",
       "rag-tge_Mistral_v2-3360                      0.030777   \n",
       "qwen1_5-7b-chat-q8_0                         0.024118   \n",
       "rag-tge_Mistral_v2-4480                      0.017918   \n",
       "Phi-3-mini-4k-instruct                       0.012317   \n",
       "c4ai-command-r-plus                          0.023094   \n",
       "Mistral-7B-Instruct-v0.2                     0.014915   \n",
       "rag-tge_Mistral.Q8                           0.012892   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.001443   \n",
       "gpt-3.5-turbo-0125                           0.012990   \n",
       "qwen1_5-110b-chat                            0.020207   \n",
       "Meta-Llama-3-8B-Instruct                     0.000000   \n",
       "rag-tge_Mistral_v6                           0.031858   \n",
       "qwen1_5-14b-chat-q8_0                        0.006598   \n",
       "gpt-4-turbo                                  0.007661   \n",
       "Meta-Llama-3-70B-Instruct                    0.020651   \n",
       "rag-tge_Llama-3-8B_v3                        0.045041   \n",
       "gemma-1.1-2b-it                              0.038105   \n",
       "qwen1_5-32b-chat-q8_0                        0.005774   \n",
       "Mistral-7B-Instruct-v0.1                     0.014434   \n",
       "\n",
       "                           correctness/answer_entail  \\\n",
       "                                                 std   \n",
       "llm                                                    \n",
       "rag-tge_Llama-3-8B_v2                       0.040415   \n",
       "zephyr-orpo-141b-A35b-v0.1                  0.040415   \n",
       "gemma-1.1-7b-it                             0.075056   \n",
       "rag-tge_Llama-3-8B_v1                       0.023094   \n",
       "zephyr-7b-beta                              0.046188   \n",
       "rag-tge_Mistral_v2-3360                     0.011547   \n",
       "qwen1_5-7b-chat-q8_0                        0.023094   \n",
       "rag-tge_Mistral_v2-4480                     0.023094   \n",
       "Phi-3-mini-4k-instruct                      0.023094   \n",
       "c4ai-command-r-plus                         0.000000   \n",
       "Mistral-7B-Instruct-v0.2                    0.017321   \n",
       "rag-tge_Mistral.Q8                          0.005774   \n",
       "Mixtral-8x7B-Instruct-v0.1                  0.011547   \n",
       "gpt-3.5-turbo-0125                          0.011547   \n",
       "qwen1_5-110b-chat                           0.017321   \n",
       "Meta-Llama-3-8B-Instruct                    0.005774   \n",
       "rag-tge_Mistral_v6                          0.028868   \n",
       "qwen1_5-14b-chat-q8_0                       0.005774   \n",
       "gpt-4-turbo                                 0.011547   \n",
       "Meta-Llama-3-70B-Instruct                   0.017321   \n",
       "rag-tge_Llama-3-8B_v3                       0.023094   \n",
       "gemma-1.1-2b-it                             0.040415   \n",
       "qwen1_5-32b-chat-q8_0                       0.005774   \n",
       "Mistral-7B-Instruct-v0.1                    0.017321   \n",
       "\n",
       "                           correctness/citations_recall  \\\n",
       "                                                    std   \n",
       "llm                                                       \n",
       "rag-tge_Llama-3-8B_v2                          0.005774   \n",
       "zephyr-orpo-141b-A35b-v0.1                     0.092376   \n",
       "gemma-1.1-7b-it                                0.080829   \n",
       "rag-tge_Llama-3-8B_v1                          0.008660   \n",
       "zephyr-7b-beta                                 0.080056   \n",
       "rag-tge_Mistral_v2-3360                        0.025981   \n",
       "qwen1_5-7b-chat-q8_0                           0.074282   \n",
       "rag-tge_Mistral_v2-4480                        0.025981   \n",
       "Phi-3-mini-4k-instruct                         0.051188   \n",
       "c4ai-command-r-plus                            0.043868   \n",
       "Mistral-7B-Instruct-v0.2                       0.025981   \n",
       "rag-tge_Mistral.Q8                             0.023094   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.034641   \n",
       "gpt-3.5-turbo-0125                             0.023094   \n",
       "qwen1_5-110b-chat                              0.051962   \n",
       "Meta-Llama-3-8B-Instruct                       0.023094   \n",
       "rag-tge_Mistral_v6                             0.023094   \n",
       "qwen1_5-14b-chat-q8_0                          0.030981   \n",
       "gpt-4-turbo                                    0.028868   \n",
       "Meta-Llama-3-70B-Instruct                      0.017321   \n",
       "rag-tge_Llama-3-8B_v3                          0.025207   \n",
       "gemma-1.1-2b-it                                0.005774   \n",
       "qwen1_5-32b-chat-q8_0                          0.008660   \n",
       "Mistral-7B-Instruct-v0.1                       0.000000   \n",
       "\n",
       "                           correctness/citations_precision  \\\n",
       "                                                       std   \n",
       "llm                                                          \n",
       "rag-tge_Llama-3-8B_v2                             0.135618   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.108477   \n",
       "gemma-1.1-7b-it                                   0.101471   \n",
       "rag-tge_Llama-3-8B_v1                             0.098810   \n",
       "zephyr-7b-beta                                    0.088494   \n",
       "rag-tge_Mistral_v2-3360                           0.084337   \n",
       "qwen1_5-7b-chat-q8_0                              0.078327   \n",
       "rag-tge_Mistral_v2-4480                           0.070338   \n",
       "Phi-3-mini-4k-instruct                            0.064275   \n",
       "c4ai-command-r-plus                               0.054568   \n",
       "Mistral-7B-Instruct-v0.2                          0.050125   \n",
       "rag-tge_Mistral.Q8                                0.040843   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.037528   \n",
       "gpt-3.5-turbo-0125                                0.023671   \n",
       "qwen1_5-110b-chat                                 0.023286   \n",
       "Meta-Llama-3-8B-Instruct                          0.018283   \n",
       "rag-tge_Mistral_v6                                0.018283   \n",
       "qwen1_5-14b-chat-q8_0                             0.016358   \n",
       "gpt-4-turbo                                       0.010585   \n",
       "Meta-Llama-3-70B-Instruct                         0.009623   \n",
       "rag-tge_Llama-3-8B_v3                             0.008660   \n",
       "gemma-1.1-2b-it                                   0.006736   \n",
       "qwen1_5-32b-chat-q8_0                             0.000000   \n",
       "Mistral-7B-Instruct-v0.1                          0.000000   \n",
       "\n",
       "                           quality/answer_relevance  \n",
       "                                                std  \n",
       "llm                                                  \n",
       "rag-tge_Llama-3-8B_v2                      0.066080  \n",
       "zephyr-orpo-141b-A35b-v0.1                 0.059428  \n",
       "gemma-1.1-7b-it                            0.043209  \n",
       "rag-tge_Llama-3-8B_v1                      0.071202  \n",
       "zephyr-7b-beta                             0.041852  \n",
       "rag-tge_Mistral_v2-3360                    0.063220  \n",
       "qwen1_5-7b-chat-q8_0                       0.034364  \n",
       "rag-tge_Mistral_v2-4480                    0.055383  \n",
       "Phi-3-mini-4k-instruct                     0.037250  \n",
       "c4ai-command-r-plus                        0.046987  \n",
       "Mistral-7B-Instruct-v0.2                   0.028340  \n",
       "rag-tge_Mistral.Q8                         0.040067  \n",
       "Mixtral-8x7B-Instruct-v0.1                 0.030875  \n",
       "gpt-3.5-turbo-0125                         0.041098  \n",
       "qwen1_5-110b-chat                          0.055224  \n",
       "Meta-Llama-3-8B-Instruct                   0.031690  \n",
       "rag-tge_Mistral_v6                         0.040207  \n",
       "qwen1_5-14b-chat-q8_0                      0.038641  \n",
       "gpt-4-turbo                                0.033935  \n",
       "Meta-Llama-3-70B-Instruct                  0.027829  \n",
       "rag-tge_Llama-3-8B_v3                      0.033242  \n",
       "gemma-1.1-2b-it                            0.019533  \n",
       "qwen1_5-32b-chat-q8_0                      0.026912  \n",
       "Mistral-7B-Instruct-v0.1                   0.027130  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: quality/answer_relevance"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.071202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v2</th>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.049620</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.135618</td>\n",
       "      <td>0.066080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.063220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.059428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.046987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.043209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v6</th>\n",
       "      <td>0.082330</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.040207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.034364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v3</th>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.029156</td>\n",
       "      <td>0.045041</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.033242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall citations/ais_precision  \\\n",
       "                                            std                     std   \n",
       "llm                                                                       \n",
       "rag-tge_Llama-3-8B_v1                  0.100349                0.030020   \n",
       "rag-tge_Llama-3-8B_v2                  0.120419                0.049620   \n",
       "rag-tge_Mistral_v2-3360                0.146211                0.032981   \n",
       "zephyr-orpo-141b-A35b-v0.1             0.134222                0.101052   \n",
       "rag-tge_Mistral_v2-4480                0.134646                0.031338   \n",
       "qwen1_5-110b-chat                      0.095486                0.026943   \n",
       "c4ai-command-r-plus                    0.060382                0.061399   \n",
       "gemma-1.1-7b-it                        0.122999                0.082995   \n",
       "zephyr-7b-beta                         0.090558                0.068665   \n",
       "gpt-3.5-turbo-0125                     0.072604                0.002887   \n",
       "rag-tge_Mistral_v6                     0.082330                0.023575   \n",
       "rag-tge_Mistral.Q8                     0.060520                0.021027   \n",
       "qwen1_5-14b-chat-q8_0                  0.042339                0.008660   \n",
       "Phi-3-mini-4k-instruct                 0.030503                0.069580   \n",
       "qwen1_5-7b-chat-q8_0                   0.063671                0.057158   \n",
       "gpt-4-turbo                            0.045401                0.005774   \n",
       "rag-tge_Llama-3-8B_v3                  0.075100                0.029156   \n",
       "Meta-Llama-3-8B-Instruct               0.060547                0.022033   \n",
       "Mixtral-8x7B-Instruct-v0.1             0.061199                0.029692   \n",
       "Mistral-7B-Instruct-v0.2               0.036560                0.038350   \n",
       "Meta-Llama-3-70B-Instruct              0.049556                0.017802   \n",
       "Mistral-7B-Instruct-v0.1               0.000000                0.000000   \n",
       "qwen1_5-32b-chat-q8_0                  0.031856                0.002887   \n",
       "gemma-1.1-2b-it                        0.005774                0.009623   \n",
       "\n",
       "                           correctness/answer_overlap  \\\n",
       "                                                  std   \n",
       "llm                                                     \n",
       "rag-tge_Llama-3-8B_v1                        0.013723   \n",
       "rag-tge_Llama-3-8B_v2                        0.015031   \n",
       "rag-tge_Mistral_v2-3360                      0.030777   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.060333   \n",
       "rag-tge_Mistral_v2-4480                      0.017918   \n",
       "qwen1_5-110b-chat                            0.020207   \n",
       "c4ai-command-r-plus                          0.023094   \n",
       "gemma-1.1-7b-it                              0.075822   \n",
       "zephyr-7b-beta                               0.028674   \n",
       "gpt-3.5-turbo-0125                           0.012990   \n",
       "rag-tge_Mistral_v6                           0.031858   \n",
       "rag-tge_Mistral.Q8                           0.012892   \n",
       "qwen1_5-14b-chat-q8_0                        0.006598   \n",
       "Phi-3-mini-4k-instruct                       0.012317   \n",
       "qwen1_5-7b-chat-q8_0                         0.024118   \n",
       "gpt-4-turbo                                  0.007661   \n",
       "rag-tge_Llama-3-8B_v3                        0.045041   \n",
       "Meta-Llama-3-8B-Instruct                     0.000000   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.001443   \n",
       "Mistral-7B-Instruct-v0.2                     0.014915   \n",
       "Meta-Llama-3-70B-Instruct                    0.020651   \n",
       "Mistral-7B-Instruct-v0.1                     0.014434   \n",
       "qwen1_5-32b-chat-q8_0                        0.005774   \n",
       "gemma-1.1-2b-it                              0.038105   \n",
       "\n",
       "                           correctness/answer_entail  \\\n",
       "                                                 std   \n",
       "llm                                                    \n",
       "rag-tge_Llama-3-8B_v1                       0.023094   \n",
       "rag-tge_Llama-3-8B_v2                       0.040415   \n",
       "rag-tge_Mistral_v2-3360                     0.011547   \n",
       "zephyr-orpo-141b-A35b-v0.1                  0.040415   \n",
       "rag-tge_Mistral_v2-4480                     0.023094   \n",
       "qwen1_5-110b-chat                           0.017321   \n",
       "c4ai-command-r-plus                         0.000000   \n",
       "gemma-1.1-7b-it                             0.075056   \n",
       "zephyr-7b-beta                              0.046188   \n",
       "gpt-3.5-turbo-0125                          0.011547   \n",
       "rag-tge_Mistral_v6                          0.028868   \n",
       "rag-tge_Mistral.Q8                          0.005774   \n",
       "qwen1_5-14b-chat-q8_0                       0.005774   \n",
       "Phi-3-mini-4k-instruct                      0.023094   \n",
       "qwen1_5-7b-chat-q8_0                        0.023094   \n",
       "gpt-4-turbo                                 0.011547   \n",
       "rag-tge_Llama-3-8B_v3                       0.023094   \n",
       "Meta-Llama-3-8B-Instruct                    0.005774   \n",
       "Mixtral-8x7B-Instruct-v0.1                  0.011547   \n",
       "Mistral-7B-Instruct-v0.2                    0.017321   \n",
       "Meta-Llama-3-70B-Instruct                   0.017321   \n",
       "Mistral-7B-Instruct-v0.1                    0.017321   \n",
       "qwen1_5-32b-chat-q8_0                       0.005774   \n",
       "gemma-1.1-2b-it                             0.040415   \n",
       "\n",
       "                           correctness/citations_recall  \\\n",
       "                                                    std   \n",
       "llm                                                       \n",
       "rag-tge_Llama-3-8B_v1                          0.008660   \n",
       "rag-tge_Llama-3-8B_v2                          0.005774   \n",
       "rag-tge_Mistral_v2-3360                        0.025981   \n",
       "zephyr-orpo-141b-A35b-v0.1                     0.092376   \n",
       "rag-tge_Mistral_v2-4480                        0.025981   \n",
       "qwen1_5-110b-chat                              0.051962   \n",
       "c4ai-command-r-plus                            0.043868   \n",
       "gemma-1.1-7b-it                                0.080829   \n",
       "zephyr-7b-beta                                 0.080056   \n",
       "gpt-3.5-turbo-0125                             0.023094   \n",
       "rag-tge_Mistral_v6                             0.023094   \n",
       "rag-tge_Mistral.Q8                             0.023094   \n",
       "qwen1_5-14b-chat-q8_0                          0.030981   \n",
       "Phi-3-mini-4k-instruct                         0.051188   \n",
       "qwen1_5-7b-chat-q8_0                           0.074282   \n",
       "gpt-4-turbo                                    0.028868   \n",
       "rag-tge_Llama-3-8B_v3                          0.025207   \n",
       "Meta-Llama-3-8B-Instruct                       0.023094   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.034641   \n",
       "Mistral-7B-Instruct-v0.2                       0.025981   \n",
       "Meta-Llama-3-70B-Instruct                      0.017321   \n",
       "Mistral-7B-Instruct-v0.1                       0.000000   \n",
       "qwen1_5-32b-chat-q8_0                          0.008660   \n",
       "gemma-1.1-2b-it                                0.005774   \n",
       "\n",
       "                           correctness/citations_precision  \\\n",
       "                                                       std   \n",
       "llm                                                          \n",
       "rag-tge_Llama-3-8B_v1                             0.098810   \n",
       "rag-tge_Llama-3-8B_v2                             0.135618   \n",
       "rag-tge_Mistral_v2-3360                           0.084337   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.108477   \n",
       "rag-tge_Mistral_v2-4480                           0.070338   \n",
       "qwen1_5-110b-chat                                 0.023286   \n",
       "c4ai-command-r-plus                               0.054568   \n",
       "gemma-1.1-7b-it                                   0.101471   \n",
       "zephyr-7b-beta                                    0.088494   \n",
       "gpt-3.5-turbo-0125                                0.023671   \n",
       "rag-tge_Mistral_v6                                0.018283   \n",
       "rag-tge_Mistral.Q8                                0.040843   \n",
       "qwen1_5-14b-chat-q8_0                             0.016358   \n",
       "Phi-3-mini-4k-instruct                            0.064275   \n",
       "qwen1_5-7b-chat-q8_0                              0.078327   \n",
       "gpt-4-turbo                                       0.010585   \n",
       "rag-tge_Llama-3-8B_v3                             0.008660   \n",
       "Meta-Llama-3-8B-Instruct                          0.018283   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.037528   \n",
       "Mistral-7B-Instruct-v0.2                          0.050125   \n",
       "Meta-Llama-3-70B-Instruct                         0.009623   \n",
       "Mistral-7B-Instruct-v0.1                          0.000000   \n",
       "qwen1_5-32b-chat-q8_0                             0.000000   \n",
       "gemma-1.1-2b-it                                   0.006736   \n",
       "\n",
       "                           quality/answer_relevance  \n",
       "                                                std  \n",
       "llm                                                  \n",
       "rag-tge_Llama-3-8B_v1                      0.071202  \n",
       "rag-tge_Llama-3-8B_v2                      0.066080  \n",
       "rag-tge_Mistral_v2-3360                    0.063220  \n",
       "zephyr-orpo-141b-A35b-v0.1                 0.059428  \n",
       "rag-tge_Mistral_v2-4480                    0.055383  \n",
       "qwen1_5-110b-chat                          0.055224  \n",
       "c4ai-command-r-plus                        0.046987  \n",
       "gemma-1.1-7b-it                            0.043209  \n",
       "zephyr-7b-beta                             0.041852  \n",
       "gpt-3.5-turbo-0125                         0.041098  \n",
       "rag-tge_Mistral_v6                         0.040207  \n",
       "rag-tge_Mistral.Q8                         0.040067  \n",
       "qwen1_5-14b-chat-q8_0                      0.038641  \n",
       "Phi-3-mini-4k-instruct                     0.037250  \n",
       "qwen1_5-7b-chat-q8_0                       0.034364  \n",
       "gpt-4-turbo                                0.033935  \n",
       "rag-tge_Llama-3-8B_v3                      0.033242  \n",
       "Meta-Llama-3-8B-Instruct                   0.031690  \n",
       "Mixtral-8x7B-Instruct-v0.1                 0.030875  \n",
       "Mistral-7B-Instruct-v0.2                   0.028340  \n",
       "Meta-Llama-3-70B-Instruct                  0.027829  \n",
       "Mistral-7B-Instruct-v0.1                   0.027130  \n",
       "qwen1_5-32b-chat-q8_0                      0.026912  \n",
       "gemma-1.1-2b-it                            0.019533  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_results = show_cleaned_results(eval_display)\n",
    "for agg in [AGG_FUNC, \"std\"]:\n",
    "    display(Markdown(f\"# {agg}\"))\n",
    "    for sort_by in [\n",
    "        (\"citations/ais_recall\", agg),\n",
    "        (\"citations/ais_precision\", agg),\n",
    "        (\"correctness/answer_overlap\", agg),\n",
    "        (\"correctness/answer_entail\", agg),\n",
    "        (\"correctness/citations_recall\", agg),\n",
    "        (\"correctness/citations_precision\", agg),\n",
    "        (\"quality/answer_relevance\", agg),\n",
    "    ]:\n",
    "        display(Markdown(f\"### sorted by: {sort_by[0]}\"))\n",
    "        results = clean_results.sort_values(by=sort_by, ascending=False)\n",
    "        results = results[[col for col in results.columns if col[1] == agg]]\n",
    "        display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Training results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_sentences</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_total_citations</th>\n",
       "      <th>citations/n_correct_citations</th>\n",
       "      <th>...</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "      <th>n_questions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>ellm</th>\n",
       "      <th>sim</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.768950</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.967017</td>\n",
       "      <td>0.010844</td>\n",
       "      <td>1.510799</td>\n",
       "      <td>0.063348</td>\n",
       "      <td>2.054890</td>\n",
       "      <td>0.085451</td>\n",
       "      <td>1.953894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.900795</td>\n",
       "      <td>0.010757</td>\n",
       "      <td>0.823467</td>\n",
       "      <td>0.015654</td>\n",
       "      <td>0.920578</td>\n",
       "      <td>0.011854</td>\n",
       "      <td>0.764136</td>\n",
       "      <td>0.024321</td>\n",
       "      <td>17872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.734613</td>\n",
       "      <td>0.063516</td>\n",
       "      <td>0.956884</td>\n",
       "      <td>0.027845</td>\n",
       "      <td>2.307743</td>\n",
       "      <td>0.209854</td>\n",
       "      <td>2.775428</td>\n",
       "      <td>0.274398</td>\n",
       "      <td>2.557775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017245</td>\n",
       "      <td>0.899073</td>\n",
       "      <td>0.020221</td>\n",
       "      <td>0.861862</td>\n",
       "      <td>0.037924</td>\n",
       "      <td>0.881502</td>\n",
       "      <td>0.037920</td>\n",
       "      <td>0.765638</td>\n",
       "      <td>0.034703</td>\n",
       "      <td>7659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1.Q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.684853</td>\n",
       "      <td>0.070232</td>\n",
       "      <td>0.930524</td>\n",
       "      <td>0.034851</td>\n",
       "      <td>2.912667</td>\n",
       "      <td>0.273580</td>\n",
       "      <td>3.392500</td>\n",
       "      <td>0.383894</td>\n",
       "      <td>3.078000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018198</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.019919</td>\n",
       "      <td>0.878833</td>\n",
       "      <td>0.036453</td>\n",
       "      <td>0.835680</td>\n",
       "      <td>0.046054</td>\n",
       "      <td>0.757222</td>\n",
       "      <td>0.036725</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.117130</td>\n",
       "      <td>0.987744</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>2.174000</td>\n",
       "      <td>0.256917</td>\n",
       "      <td>1.989000</td>\n",
       "      <td>0.213576</td>\n",
       "      <td>1.902000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022317</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>0.053828</td>\n",
       "      <td>0.939481</td>\n",
       "      <td>0.036772</td>\n",
       "      <td>0.764311</td>\n",
       "      <td>0.043379</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.582407</td>\n",
       "      <td>0.031801</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.006415</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.083395</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.044905</td>\n",
       "      <td>1.388889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.022453</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.738220</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.563212</td>\n",
       "      <td>0.127016</td>\n",
       "      <td>0.882383</td>\n",
       "      <td>0.101713</td>\n",
       "      <td>2.376147</td>\n",
       "      <td>0.372804</td>\n",
       "      <td>5.887287</td>\n",
       "      <td>1.252030</td>\n",
       "      <td>4.269987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036494</td>\n",
       "      <td>0.878113</td>\n",
       "      <td>0.034536</td>\n",
       "      <td>0.821756</td>\n",
       "      <td>0.097210</td>\n",
       "      <td>0.663595</td>\n",
       "      <td>0.105757</td>\n",
       "      <td>0.743845</td>\n",
       "      <td>0.063733</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              prompt_id  \\\n",
       "                                                                                                                          \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "\n",
       "                                                                                                              citations/ais_recall  \\\n",
       "                                                                                                                               max   \n",
       "llm                             temperature nli                     ellm                     sim                                     \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.768950   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.734613   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.684853   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.669000   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.582407   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.563212   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.031242   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.063516   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.070232   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.117130   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.031801   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.127016   \n",
       "\n",
       "                                                                                                              citations/ais_precision  \\\n",
       "                                                                                                                                  max   \n",
       "llm                             temperature nli                     ellm                     sim                                        \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.967017   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.956884   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.930524   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.987744   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.994444   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.882383   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.010844   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.027845   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034851   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.030177   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.006415   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.101713   \n",
       "\n",
       "                                                                                                              citations/n_sentences  \\\n",
       "                                                                                                                                max   \n",
       "llm                             temperature nli                     ellm                     sim                                      \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.510799   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.307743   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.912667   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.174000   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.666667   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.376147   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.063348   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.209854   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.273580   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.256917   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.083395   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.372804   \n",
       "\n",
       "                                                                                                              citations/n_total_citations  \\\n",
       "                                                                                                                                      max   \n",
       "llm                             temperature nli                     ellm                     sim                                            \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.054890   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.775428   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    3.392500   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.989000   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.400000   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    5.887287   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.085451   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.274398   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.383894   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.213576   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.044905   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.252030   \n",
       "\n",
       "                                                                                                              citations/n_correct_citations  \\\n",
       "                                                                                                                                        max   \n",
       "llm                             temperature nli                     ellm                     sim                                              \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.953894   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.557775   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      3.078000   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.902000   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.388889   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      4.269987   \n",
       "\n",
       "                                                                                                               ...  \\\n",
       "                                                                                                               ...   \n",
       "llm                             temperature nli                     ellm                     sim               ...   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "\n",
       "                                                                                                              correctness/answer_overlap  \\\n",
       "                                                                                                                                     std   \n",
       "llm                             temperature nli                     ellm                     sim                                           \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.010100   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.017245   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.018198   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.022317   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.010200   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.036494   \n",
       "\n",
       "                                                                                                              correctness/answer_entail  \\\n",
       "                                                                                                                                    max   \n",
       "llm                             temperature nli                     ellm                     sim                                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.900795   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.899073   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.894000   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.898000   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.844444   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.878113   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.010757   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.020221   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.019919   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.025403   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034536   \n",
       "\n",
       "                                                                                                              correctness/citations_recall  \\\n",
       "                                                                                                                                       max   \n",
       "llm                             temperature nli                     ellm                     sim                                             \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.823467   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.861862   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.878833   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.782500   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.650000   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.821756   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.015654   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.037924   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.036453   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.053828   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.022453   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.097210   \n",
       "\n",
       "                                                                                                              correctness/citations_precision  \\\n",
       "                                                                                                                                          max   \n",
       "llm                             temperature nli                     ellm                     sim                                                \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.920578   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.881502   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.835680   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.939481   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.955556   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.663595   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.011854   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.037920   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.046054   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.036772   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.003208   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.105757   \n",
       "\n",
       "                                                                                                              quality/answer_relevance  \\\n",
       "                                                                                                                                   max   \n",
       "llm                             temperature nli                     ellm                     sim                                         \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.764136   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.765638   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.757222   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.764311   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.738220   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.743845   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.024321   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034703   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.036725   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.043379   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017761   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.063733   \n",
       "\n",
       "                                                                                                              n_questions  \n",
       "                                                                                                                           \n",
       "llm                             temperature nli                     ellm                     sim                           \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2       17872  \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2        7659  \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2        6000  \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2        1000  \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          90  \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         763  \n",
       "\n",
       "[6 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Training results\"))\n",
    "train_display = remove_index(train_results, \"prompt_id\")\n",
    "train_display"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
