{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tdolega/miniconda/envs/p311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from common.consts import RESULTS_DIR, EVAL_SIZE\n",
    "from common.utils import filename_to_obj, remove_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [01:26<00:00,  2.22s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_idx</th>\n",
       "      <th>question_id</th>\n",
       "      <th>llm</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>ellm</th>\n",
       "      <th>sim</th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>citations/supported</th>\n",
       "      <th>citations/citations</th>\n",
       "      <th>citations/correct_citations</th>\n",
       "      <th>citations/out_of_range</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "      <th>quality/new_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "      <td>[[], [], [3], [4]]</td>\n",
       "      <td>[[], [], [True], [True]]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.649022</td>\n",
       "      <td>Which of P.K. Subban's brothers was drafted fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.875</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[[], [], [3], [4], [6], [], [], [], [], [4, 5]...</td>\n",
       "      <td>[[], [], [True], [True], [True], [], [], [], [...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.757470</td>\n",
       "      <td>Who are the two professional hockey players, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[[], [], [4], [6], [], []]</td>\n",
       "      <td>[[], [], [True], [True], [], []]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.770844</td>\n",
       "      <td>Who are the two professional hockey players, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5a761900554299109176e648</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[[1]]</td>\n",
       "      <td>[[True]]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.450042</td>\n",
       "      <td>What is the name of the intelligence firm that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5a761900554299109176e648</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[[0, 1], [0, 1]]</td>\n",
       "      <td>[[True, True], [True, True]]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.772082</td>\n",
       "      <td>What is the name of the lobbying group founded...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_idx               question_id                       llm prompt_id  \\\n",
       "0             0  5abab42e55429955dce3eed2  Mistral-7B-Instruct-v0.2         1   \n",
       "1             0  5abab42e55429955dce3eed2  Mistral-7B-Instruct-v0.2         1   \n",
       "2             0  5abab42e55429955dce3eed2  Mistral-7B-Instruct-v0.2         1   \n",
       "3             1  5a761900554299109176e648  Mistral-7B-Instruct-v0.2         1   \n",
       "4             1  5a761900554299109176e648  Mistral-7B-Instruct-v0.2         1   \n",
       "\n",
       "  temperature                      nli                      ellm  \\\n",
       "0         0.8  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "1         0.8  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "2         0.8  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "3         0.8  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "4         0.8  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "\n",
       "                sim  citations/ais_recall  citations/ais_precision  ...  \\\n",
       "0  all-MiniLM-L6-v2              0.250000                    1.000  ...   \n",
       "1  all-MiniLM-L6-v2              0.083333                    0.875  ...   \n",
       "2  all-MiniLM-L6-v2              0.000000                    1.000  ...   \n",
       "3  all-MiniLM-L6-v2              1.000000                    1.000  ...   \n",
       "4  all-MiniLM-L6-v2              1.000000                    1.000  ...   \n",
       "\n",
       "                    citations/supported  \\\n",
       "0                          [0, 0, 0, 1]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "2                    [0, 0, 0, 0, 0, 0]   \n",
       "3                                   [1]   \n",
       "4                                [1, 1]   \n",
       "\n",
       "                                 citations/citations  \\\n",
       "0                                 [[], [], [3], [4]]   \n",
       "1  [[], [], [3], [4], [6], [], [], [], [], [4, 5]...   \n",
       "2                         [[], [], [4], [6], [], []]   \n",
       "3                                              [[1]]   \n",
       "4                                   [[0, 1], [0, 1]]   \n",
       "\n",
       "                         citations/correct_citations  \\\n",
       "0                           [[], [], [True], [True]]   \n",
       "1  [[], [], [True], [True], [True], [], [], [], [...   \n",
       "2                   [[], [], [True], [True], [], []]   \n",
       "3                                           [[True]]   \n",
       "4                       [[True, True], [True, True]]   \n",
       "\n",
       "                 citations/out_of_range  correctness/answer_overlap  \\\n",
       "0                          [0, 0, 0, 0]                         1.0   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                         1.0   \n",
       "2                    [0, 0, 0, 0, 0, 0]                         0.5   \n",
       "3                                   [0]                         1.0   \n",
       "4                                [0, 0]                         1.0   \n",
       "\n",
       "  correctness/answer_entail correctness/citations_recall  \\\n",
       "0                       1.0                          1.0   \n",
       "1                       0.0                          1.0   \n",
       "2                       0.0                          0.5   \n",
       "3                       1.0                          0.5   \n",
       "4                       1.0                          1.0   \n",
       "\n",
       "  correctness/citations_precision quality/answer_relevance  \\\n",
       "0                             1.0                 0.649022   \n",
       "1                             0.5                 0.757470   \n",
       "2                             0.5                 0.770844   \n",
       "3                             1.0                 0.450042   \n",
       "4                             1.0                 0.772082   \n",
       "\n",
       "                                quality/new_question  \n",
       "0  Which of P.K. Subban's brothers was drafted fi...  \n",
       "1  Who are the two professional hockey players, b...  \n",
       "2  Who are the two professional hockey players, b...  \n",
       "3  What is the name of the intelligence firm that...  \n",
       "4  What is the name of the lobbying group founded...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def results_as_pandas(filename):\n",
    "    path = os.path.join(RESULTS_DIR, filename)\n",
    "    with open(path, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "    data = [json.loads(d) for d in data]\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    if len(data) == 0:\n",
    "        print(f\"empty file: {filename}\")\n",
    "        return data\n",
    "\n",
    "    params = filename_to_obj(filename)\n",
    "    for k, v in params.items():\n",
    "        data[k] = v\n",
    "\n",
    "    data = data.explode(\"evaluations\")\n",
    "    data = data.rename_axis(\"question_idx\").reset_index()\n",
    "\n",
    "    data = pd.concat([data, data[\"evaluations\"].apply(pd.Series)], axis=1)\n",
    "    evaluation_keys = data[\"evaluations\"].apply(pd.Series).columns\n",
    "    for col in evaluation_keys:\n",
    "        data = pd.concat([data, data[col].apply(pd.Series).add_prefix(f\"{col}/\")], axis=1)\n",
    "        data = data.drop(columns=col)\n",
    "    data = data.drop(columns=[\"evaluations\"])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "files = os.listdir(RESULTS_DIR)\n",
    "params_names = list(filename_to_obj(files[0]).keys())\n",
    "all_results = pd.concat([results_as_pandas(f) for f in tqdm(files)])\n",
    "all_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns: ['citations/supported', 'citations/sentences', 'citations/out_of_range', 'quality/new_question', 'citations/citations', 'citations/correct_citations']\n"
     ]
    }
   ],
   "source": [
    "all_obj_cols = all_results.select_dtypes(include=[\"object\"]).columns\n",
    "drop_obj_cols = list(set(all_obj_cols) - set(params_names))\n",
    "drop_obj_cols.remove(\"question_id\")\n",
    "print(f\"Dropping columns: {drop_obj_cols}\")\n",
    "all_num_results = all_results.drop(columns=drop_obj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_split = all_num_results[all_num_results[\"question_idx\"] < EVAL_SIZE]\n",
    "train_split = all_num_results[all_num_results[\"question_idx\"] >= EVAL_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(split):\n",
    "    split = split.drop(columns=[\"question_idx\"])\n",
    "    results_with_std_for_each_question = split.groupby([*params_names, \"question_id\"]).agg([\"mean\", \"std\"])\n",
    "    results_for_each_model = results_with_std_for_each_question.groupby(params_names)\n",
    "    results = results_for_each_model.mean()\n",
    "    results[\"n_questions\"] = results_for_each_model.size()\n",
    "    return results\n",
    "\n",
    "\n",
    "eval_results = aggregate(eval_split)\n",
    "train_results = aggregate(train_split)\n",
    "\n",
    "if eval_results[\"n_questions\"].nunique() != 1:\n",
    "    print(\"Warning: not all rows in evaluation have the same number of examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Prompts comparison"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.871517</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.872812</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.721619</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.501540</td>\n",
       "      <td>0.066146</td>\n",
       "      <td>0.862167</td>\n",
       "      <td>0.034978</td>\n",
       "      <td>0.855380</td>\n",
       "      <td>0.027905</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.043301</td>\n",
       "      <td>0.670627</td>\n",
       "      <td>0.046655</td>\n",
       "      <td>0.704898</td>\n",
       "      <td>0.030174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.580222</td>\n",
       "      <td>0.045033</td>\n",
       "      <td>0.890076</td>\n",
       "      <td>0.024787</td>\n",
       "      <td>0.855936</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.042370</td>\n",
       "      <td>0.658884</td>\n",
       "      <td>0.027177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   citations/ais_recall            \\\n",
       "                                                   mean       std   \n",
       "llm                      prompt_id                                  \n",
       "Mistral-7B-Instruct-v0.2 1                     0.575644  0.036560   \n",
       "                         2                     0.501540  0.066146   \n",
       "                         3                     0.580222  0.045033   \n",
       "\n",
       "                                   citations/ais_precision            \\\n",
       "                                                      mean       std   \n",
       "llm                      prompt_id                                     \n",
       "Mistral-7B-Instruct-v0.2 1                        0.871517  0.038350   \n",
       "                         2                        0.862167  0.034978   \n",
       "                         3                        0.890076  0.024787   \n",
       "\n",
       "                                   correctness/answer_overlap            \\\n",
       "                                                         mean       std   \n",
       "llm                      prompt_id                                        \n",
       "Mistral-7B-Instruct-v0.2 1                           0.872812  0.014915   \n",
       "                         2                           0.855380  0.027905   \n",
       "                         3                           0.855936  0.017321   \n",
       "\n",
       "                                   correctness/answer_entail            \\\n",
       "                                                        mean       std   \n",
       "llm                      prompt_id                                       \n",
       "Mistral-7B-Instruct-v0.2 1                          0.886667  0.017321   \n",
       "                         2                          0.860000  0.023094   \n",
       "                         3                          0.863333  0.011547   \n",
       "\n",
       "                                   correctness/citations_recall            \\\n",
       "                                                           mean       std   \n",
       "llm                      prompt_id                                          \n",
       "Mistral-7B-Instruct-v0.2 1                             0.751667  0.025981   \n",
       "                         2                             0.770000  0.043301   \n",
       "                         3                             0.665000  0.034641   \n",
       "\n",
       "                                   correctness/citations_precision            \\\n",
       "                                                              mean       std   \n",
       "llm                      prompt_id                                             \n",
       "Mistral-7B-Instruct-v0.2 1                                0.721619  0.050125   \n",
       "                         2                                0.670627  0.046655   \n",
       "                         3                                0.658333  0.042370   \n",
       "\n",
       "                                   quality/answer_relevance            \n",
       "                                                       mean       std  \n",
       "llm                      prompt_id                                     \n",
       "Mistral-7B-Instruct-v0.2 1                         0.720431  0.028340  \n",
       "                         2                         0.704898  0.030174  \n",
       "                         3                         0.658884  0.027177  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Prompts comparison\"))\n",
    "parameter_results = eval_results[eval_results.index.get_level_values(\"llm\") == \"Mistral-7B-Instruct-v0.2\"]\n",
    "\n",
    "\n",
    "def show_cleaned_results(short_eval_display, keep_index_name=None):\n",
    "    short_eval_display = short_eval_display.copy()\n",
    "    for index_name in [\"temperature\", \"nli\", \"ellm\", \"sim\", \"prompt_id\"]:\n",
    "        if index_name == keep_index_name:\n",
    "            continue\n",
    "        short_eval_display = remove_index(short_eval_display, index_name)\n",
    "    important_columns = [\"citations/ais_recall\", \"citations/ais_precision\", \"correctness/answer_overlap\", \"correctness/answer_entail\", \"correctness/citations_recall\", \"correctness/citations_precision\", \"quality/answer_relevance\"]\n",
    "    short_eval_display = short_eval_display[important_columns]\n",
    "    return short_eval_display\n",
    "\n",
    "\n",
    "show_cleaned_results(parameter_results[parameter_results.index.get_level_values(\"temperature\") == \"0.1\"], keep_index_name=\"prompt_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Temperature comparison"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>temperature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>0.01</th>\n",
       "      <td>0.574825</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>0.889365</td>\n",
       "      <td>0.016922</td>\n",
       "      <td>0.858923</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.744357</td>\n",
       "      <td>0.023419</td>\n",
       "      <td>0.734959</td>\n",
       "      <td>0.015812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.871517</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.872812</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.721619</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.544493</td>\n",
       "      <td>0.081991</td>\n",
       "      <td>0.877352</td>\n",
       "      <td>0.050804</td>\n",
       "      <td>0.864735</td>\n",
       "      <td>0.029793</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.741825</td>\n",
       "      <td>0.050897</td>\n",
       "      <td>0.725103</td>\n",
       "      <td>0.033120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.566712</td>\n",
       "      <td>0.084729</td>\n",
       "      <td>0.863762</td>\n",
       "      <td>0.066155</td>\n",
       "      <td>0.872534</td>\n",
       "      <td>0.045707</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.059848</td>\n",
       "      <td>0.749746</td>\n",
       "      <td>0.067481</td>\n",
       "      <td>0.723474</td>\n",
       "      <td>0.047856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.580572</td>\n",
       "      <td>0.150051</td>\n",
       "      <td>0.877947</td>\n",
       "      <td>0.108934</td>\n",
       "      <td>0.872336</td>\n",
       "      <td>0.044607</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.096603</td>\n",
       "      <td>0.738476</td>\n",
       "      <td>0.099659</td>\n",
       "      <td>0.721409</td>\n",
       "      <td>0.049850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.569651</td>\n",
       "      <td>0.144597</td>\n",
       "      <td>0.881010</td>\n",
       "      <td>0.085049</td>\n",
       "      <td>0.852962</td>\n",
       "      <td>0.073768</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>0.082169</td>\n",
       "      <td>0.737151</td>\n",
       "      <td>0.114113</td>\n",
       "      <td>0.707704</td>\n",
       "      <td>0.059824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.519373</td>\n",
       "      <td>0.168079</td>\n",
       "      <td>0.856773</td>\n",
       "      <td>0.110804</td>\n",
       "      <td>0.845013</td>\n",
       "      <td>0.049038</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.121810</td>\n",
       "      <td>0.738574</td>\n",
       "      <td>0.125848</td>\n",
       "      <td>0.715341</td>\n",
       "      <td>0.064925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.555853</td>\n",
       "      <td>0.182757</td>\n",
       "      <td>0.858316</td>\n",
       "      <td>0.115458</td>\n",
       "      <td>0.871201</td>\n",
       "      <td>0.047054</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.118923</td>\n",
       "      <td>0.736230</td>\n",
       "      <td>0.132095</td>\n",
       "      <td>0.727172</td>\n",
       "      <td>0.058840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.505895</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.842402</td>\n",
       "      <td>0.131938</td>\n",
       "      <td>0.867148</td>\n",
       "      <td>0.062564</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.086603</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.119697</td>\n",
       "      <td>0.719730</td>\n",
       "      <td>0.123992</td>\n",
       "      <td>0.725166</td>\n",
       "      <td>0.070362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.572745</td>\n",
       "      <td>0.204617</td>\n",
       "      <td>0.876745</td>\n",
       "      <td>0.127270</td>\n",
       "      <td>0.829410</td>\n",
       "      <td>0.074434</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.149130</td>\n",
       "      <td>0.731516</td>\n",
       "      <td>0.152158</td>\n",
       "      <td>0.695873</td>\n",
       "      <td>0.073964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.550218</td>\n",
       "      <td>0.202885</td>\n",
       "      <td>0.858579</td>\n",
       "      <td>0.139181</td>\n",
       "      <td>0.824547</td>\n",
       "      <td>0.066776</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.063509</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.144130</td>\n",
       "      <td>0.707476</td>\n",
       "      <td>0.164076</td>\n",
       "      <td>0.686019</td>\n",
       "      <td>0.081091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>0.524532</td>\n",
       "      <td>0.221513</td>\n",
       "      <td>0.856628</td>\n",
       "      <td>0.156983</td>\n",
       "      <td>0.838289</td>\n",
       "      <td>0.074745</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.069282</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.178205</td>\n",
       "      <td>0.711397</td>\n",
       "      <td>0.160805</td>\n",
       "      <td>0.696656</td>\n",
       "      <td>0.077673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.463269</td>\n",
       "      <td>0.259358</td>\n",
       "      <td>0.785161</td>\n",
       "      <td>0.220605</td>\n",
       "      <td>0.809466</td>\n",
       "      <td>0.089997</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.223412</td>\n",
       "      <td>0.658788</td>\n",
       "      <td>0.225945</td>\n",
       "      <td>0.695753</td>\n",
       "      <td>0.089034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5</th>\n",
       "      <td>0.266854</td>\n",
       "      <td>0.262768</td>\n",
       "      <td>0.712875</td>\n",
       "      <td>0.240513</td>\n",
       "      <td>0.724706</td>\n",
       "      <td>0.186147</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.161658</td>\n",
       "      <td>0.668333</td>\n",
       "      <td>0.283620</td>\n",
       "      <td>0.549794</td>\n",
       "      <td>0.258627</td>\n",
       "      <td>0.705244</td>\n",
       "      <td>0.097187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     citations/ais_recall            \\\n",
       "                                                     mean       std   \n",
       "llm                      temperature                                  \n",
       "Mistral-7B-Instruct-v0.2 0.01                    0.574825  0.027143   \n",
       "                         0.1                     0.575644  0.036560   \n",
       "                         0.2                     0.544493  0.081991   \n",
       "                         0.3                     0.566712  0.084729   \n",
       "                         0.4                     0.580572  0.150051   \n",
       "                         0.5                     0.569651  0.144597   \n",
       "                         0.6                     0.519373  0.168079   \n",
       "                         0.7                     0.555853  0.182757   \n",
       "                         0.8                     0.505895  0.195393   \n",
       "                         0.9                     0.572745  0.204617   \n",
       "                         1.0                     0.550218  0.202885   \n",
       "                         1.5                     0.524532  0.221513   \n",
       "                         2.0                     0.463269  0.259358   \n",
       "                         2.5                     0.266854  0.262768   \n",
       "\n",
       "                                     citations/ais_precision            \\\n",
       "                                                        mean       std   \n",
       "llm                      temperature                                     \n",
       "Mistral-7B-Instruct-v0.2 0.01                       0.889365  0.016922   \n",
       "                         0.1                        0.871517  0.038350   \n",
       "                         0.2                        0.877352  0.050804   \n",
       "                         0.3                        0.863762  0.066155   \n",
       "                         0.4                        0.877947  0.108934   \n",
       "                         0.5                        0.881010  0.085049   \n",
       "                         0.6                        0.856773  0.110804   \n",
       "                         0.7                        0.858316  0.115458   \n",
       "                         0.8                        0.842402  0.131938   \n",
       "                         0.9                        0.876745  0.127270   \n",
       "                         1.0                        0.858579  0.139181   \n",
       "                         1.5                        0.856628  0.156983   \n",
       "                         2.0                        0.785161  0.220605   \n",
       "                         2.5                        0.712875  0.240513   \n",
       "\n",
       "                                     correctness/answer_overlap            \\\n",
       "                                                           mean       std   \n",
       "llm                      temperature                                        \n",
       "Mistral-7B-Instruct-v0.2 0.01                          0.858923  0.012990   \n",
       "                         0.1                           0.872812  0.014915   \n",
       "                         0.2                           0.864735  0.029793   \n",
       "                         0.3                           0.872534  0.045707   \n",
       "                         0.4                           0.872336  0.044607   \n",
       "                         0.5                           0.852962  0.073768   \n",
       "                         0.6                           0.845013  0.049038   \n",
       "                         0.7                           0.871201  0.047054   \n",
       "                         0.8                           0.867148  0.062564   \n",
       "                         0.9                           0.829410  0.074434   \n",
       "                         1.0                           0.824547  0.066776   \n",
       "                         1.5                           0.838289  0.074745   \n",
       "                         2.0                           0.809466  0.089997   \n",
       "                         2.5                           0.724706  0.186147   \n",
       "\n",
       "                                     correctness/answer_entail            \\\n",
       "                                                          mean       std   \n",
       "llm                      temperature                                       \n",
       "Mistral-7B-Instruct-v0.2 0.01                         0.883333  0.017321   \n",
       "                         0.1                          0.886667  0.017321   \n",
       "                         0.2                          0.886667  0.005774   \n",
       "                         0.3                          0.883333  0.023094   \n",
       "                         0.4                          0.886667  0.028868   \n",
       "                         0.5                          0.880000  0.034641   \n",
       "                         0.6                          0.870000  0.040415   \n",
       "                         0.7                          0.873333  0.028868   \n",
       "                         0.8                          0.860000  0.086603   \n",
       "                         0.9                          0.856667  0.057735   \n",
       "                         1.0                          0.836667  0.063509   \n",
       "                         1.5                          0.853333  0.069282   \n",
       "                         2.0                          0.830000  0.075056   \n",
       "                         2.5                          0.750000  0.161658   \n",
       "\n",
       "                                     correctness/citations_recall            \\\n",
       "                                                             mean       std   \n",
       "llm                      temperature                                          \n",
       "Mistral-7B-Instruct-v0.2 0.01                            0.758333  0.014434   \n",
       "                         0.1                             0.751667  0.025981   \n",
       "                         0.2                             0.770000  0.051962   \n",
       "                         0.3                             0.776667  0.059848   \n",
       "                         0.4                             0.775000  0.096603   \n",
       "                         0.5                             0.761667  0.082169   \n",
       "                         0.6                             0.758333  0.121810   \n",
       "                         0.7                             0.770000  0.118923   \n",
       "                         0.8                             0.751667  0.119697   \n",
       "                         0.9                             0.751667  0.149130   \n",
       "                         1.0                             0.706667  0.144130   \n",
       "                         1.5                             0.753333  0.178205   \n",
       "                         2.0                             0.770000  0.223412   \n",
       "                         2.5                             0.668333  0.283620   \n",
       "\n",
       "                                     correctness/citations_precision  \\\n",
       "                                                                mean   \n",
       "llm                      temperature                                   \n",
       "Mistral-7B-Instruct-v0.2 0.01                               0.744357   \n",
       "                         0.1                                0.721619   \n",
       "                         0.2                                0.741825   \n",
       "                         0.3                                0.749746   \n",
       "                         0.4                                0.738476   \n",
       "                         0.5                                0.737151   \n",
       "                         0.6                                0.738574   \n",
       "                         0.7                                0.736230   \n",
       "                         0.8                                0.719730   \n",
       "                         0.9                                0.731516   \n",
       "                         1.0                                0.707476   \n",
       "                         1.5                                0.711397   \n",
       "                         2.0                                0.658788   \n",
       "                         2.5                                0.549794   \n",
       "\n",
       "                                               quality/answer_relevance  \\\n",
       "                                           std                     mean   \n",
       "llm                      temperature                                      \n",
       "Mistral-7B-Instruct-v0.2 0.01         0.023419                 0.734959   \n",
       "                         0.1          0.050125                 0.720431   \n",
       "                         0.2          0.050897                 0.725103   \n",
       "                         0.3          0.067481                 0.723474   \n",
       "                         0.4          0.099659                 0.721409   \n",
       "                         0.5          0.114113                 0.707704   \n",
       "                         0.6          0.125848                 0.715341   \n",
       "                         0.7          0.132095                 0.727172   \n",
       "                         0.8          0.123992                 0.725166   \n",
       "                         0.9          0.152158                 0.695873   \n",
       "                         1.0          0.164076                 0.686019   \n",
       "                         1.5          0.160805                 0.696656   \n",
       "                         2.0          0.225945                 0.695753   \n",
       "                         2.5          0.258627                 0.705244   \n",
       "\n",
       "                                                \n",
       "                                           std  \n",
       "llm                      temperature            \n",
       "Mistral-7B-Instruct-v0.2 0.01         0.015812  \n",
       "                         0.1          0.028340  \n",
       "                         0.2          0.033120  \n",
       "                         0.3          0.047856  \n",
       "                         0.4          0.049850  \n",
       "                         0.5          0.059824  \n",
       "                         0.6          0.064925  \n",
       "                         0.7          0.058840  \n",
       "                         0.8          0.070362  \n",
       "                         0.9          0.073964  \n",
       "                         1.0          0.081091  \n",
       "                         1.5          0.077673  \n",
       "                         2.0          0.089034  \n",
       "                         2.5          0.097187  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Temperature comparison\"))\n",
    "show_cleaned_results(parameter_results[parameter_results.index.get_level_values(\"prompt_id\") == \"1\"], keep_index_name=\"temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Evaluation results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_sentences</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_total_citations</th>\n",
       "      <th>citations/n_correct_citations</th>\n",
       "      <th>...</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "      <th>n_questions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>ellm</th>\n",
       "      <th>sim</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.640377</td>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.953748</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>8.153333</td>\n",
       "      <td>1.170721</td>\n",
       "      <td>8.490000</td>\n",
       "      <td>1.338763</td>\n",
       "      <td>8.020000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.988333</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.735427</td>\n",
       "      <td>0.071202</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.733170</td>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.954283</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>4.746667</td>\n",
       "      <td>1.208135</td>\n",
       "      <td>5.483333</td>\n",
       "      <td>1.148101</td>\n",
       "      <td>5.220000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.876556</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.729280</td>\n",
       "      <td>0.055383</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.682667</td>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.957922</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>5.566667</td>\n",
       "      <td>1.424317</td>\n",
       "      <td>6.223333</td>\n",
       "      <td>1.360671</td>\n",
       "      <td>5.960000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.842111</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.725706</td>\n",
       "      <td>0.063220</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.812135</td>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.957667</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>2.246667</td>\n",
       "      <td>0.261624</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>0.306084</td>\n",
       "      <td>2.796667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907413</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.742347</td>\n",
       "      <td>0.040067</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.737556</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>0.214022</td>\n",
       "      <td>2.143333</td>\n",
       "      <td>0.207846</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>0.041098</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.928603</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.148564</td>\n",
       "      <td>2.290000</td>\n",
       "      <td>0.205801</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.726039</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>1.593333</td>\n",
       "      <td>0.170111</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>0.090331</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.938778</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.747313</td>\n",
       "      <td>0.033935</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>1.463333</td>\n",
       "      <td>0.063509</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>0.069282</td>\n",
       "      <td>1.796667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.752517</td>\n",
       "      <td>0.027829</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.417516</td>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.796321</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>0.366975</td>\n",
       "      <td>4.930000</td>\n",
       "      <td>1.293896</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.545670</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.696486</td>\n",
       "      <td>0.059428</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.492702</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.951210</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>2.186667</td>\n",
       "      <td>0.194752</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>0.180710</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.720451</td>\n",
       "      <td>0.031690</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.871517</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>2.573333</td>\n",
       "      <td>0.212475</td>\n",
       "      <td>3.016667</td>\n",
       "      <td>0.372709</td>\n",
       "      <td>2.676667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.721619</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.028340</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.528167</td>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>1.976667</td>\n",
       "      <td>0.222073</td>\n",
       "      <td>1.673333</td>\n",
       "      <td>0.127017</td>\n",
       "      <td>1.623333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.929889</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.737396</td>\n",
       "      <td>0.055224</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>1.393333</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>0.086603</td>\n",
       "      <td>1.516667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.719488</td>\n",
       "      <td>0.038641</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.069282</td>\n",
       "      <td>1.396667</td>\n",
       "      <td>0.027321</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710307</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.406690</td>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.910524</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.395182</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>0.653154</td>\n",
       "      <td>2.343333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.727884</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.715053</td>\n",
       "      <td>0.041852</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.409167</td>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>2.093333</td>\n",
       "      <td>0.102376</td>\n",
       "      <td>1.756667</td>\n",
       "      <td>0.274993</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578333</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.644302</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.635162</td>\n",
       "      <td>0.046987</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.233444</td>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>0.227846</td>\n",
       "      <td>1.303333</td>\n",
       "      <td>0.217846</td>\n",
       "      <td>1.263333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.800444</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.767839</td>\n",
       "      <td>0.034364</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_TinyLlama.Q32</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.405833</td>\n",
       "      <td>0.121770</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>0.039015</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>0.206299</td>\n",
       "      <td>1.836667</td>\n",
       "      <td>0.250346</td>\n",
       "      <td>1.663333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049460</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.608111</td>\n",
       "      <td>0.068060</td>\n",
       "      <td>0.614176</td>\n",
       "      <td>0.045262</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.367889</td>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>1.316667</td>\n",
       "      <td>0.161244</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>0.150111</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.471667</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.660222</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.738827</td>\n",
       "      <td>0.043209</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.252796</td>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>2.654658</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>0.296180</td>\n",
       "      <td>1.490000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.457889</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.663574</td>\n",
       "      <td>0.037250</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinyllama-1.1b-chat-v1.0.Q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.041361</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>2.340000</td>\n",
       "      <td>0.333174</td>\n",
       "      <td>0.363333</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028318</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.564932</td>\n",
       "      <td>0.044756</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.046111</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>1.443333</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.708830</td>\n",
       "      <td>0.019533</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.396667</td>\n",
       "      <td>0.135995</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737850</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                            prompt_id  \\\n",
       "                                                                                                                        \n",
       "llm                           temperature nli                     ellm                     sim                          \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "\n",
       "                                                                                                            citations/ais_recall  \\\n",
       "                                                                                                                            mean   \n",
       "llm                           temperature nli                     ellm                     sim                                     \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.640377   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.733170   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.682667   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.812135   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.737556   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.653500   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.733013   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.691944   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.417516   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.492702   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.575644   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.528167   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.633333   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.512222   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.406690   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.409167   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.233444   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.405833   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.367889   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.252796   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.041361   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.006667   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.005000   \n",
       "\n",
       "                                                                                                                       \\\n",
       "                                                                                                                  std   \n",
       "llm                           temperature nli                     ellm                     sim                          \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.100349   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.134646   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.146211   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.060520   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.072604   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.061199   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.045401   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.049556   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.134222   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.060547   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.036560   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.095486   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.042339   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.031856   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.090558   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.060382   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.063671   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.121770   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.122999   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.030503   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.010585   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                            citations/ais_precision  \\\n",
       "                                                                                                                               mean   \n",
       "llm                           temperature nli                     ellm                     sim                                        \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.953748   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.954283   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.957922   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.957667   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.995833   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.928603   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.985000   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.955556   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.796321   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.951210   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.871517   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.976111   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.975000   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.993333   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.910524   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.714694   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.862000   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.749778   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.766667   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.578455   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.125000   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.046111   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.010000   \n",
       "\n",
       "                                                                                                                       \\\n",
       "                                                                                                                  std   \n",
       "llm                           temperature nli                     ellm                     sim                          \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.030020   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.031338   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.032981   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.021027   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.002887   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.029692   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017802   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.101052   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.022033   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.038350   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.026943   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.008660   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.002887   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.068665   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.061399   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.057158   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.039015   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.082995   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.069580   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.031754   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.009623   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                            citations/n_sentences  \\\n",
       "                                                                                                                             mean   \n",
       "llm                           temperature nli                     ellm                     sim                                      \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              8.153333   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              4.746667   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              5.566667   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.246667   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.020000   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.100000   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.593333   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.463333   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.990000   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.186667   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.573333   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.976667   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.393333   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.600000   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              3.280000   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.093333   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.420000   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.720000   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.316667   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              8.400000   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.340000   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.443333   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.396667   \n",
       "\n",
       "                                                                                                                       \\\n",
       "                                                                                                                  std   \n",
       "llm                           temperature nli                     ellm                     sim                          \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.170721   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.208135   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.424317   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.261624   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.214022   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.148564   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.170111   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.063509   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.366975   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.194752   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.212475   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.222073   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.075056   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.069282   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.395182   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.102376   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.227846   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.206299   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.161244   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  2.654658   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.333174   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040415   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.135995   \n",
       "\n",
       "                                                                                                            citations/n_total_citations  \\\n",
       "                                                                                                                                   mean   \n",
       "llm                           temperature nli                     ellm                     sim                                            \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    8.490000   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    5.483333   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    6.223333   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.950000   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.143333   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.290000   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.790000   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.880000   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    4.930000   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.040000   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    3.016667   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.673333   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.583333   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.396667   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.570000   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.756667   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.303333   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.836667   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.360000   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.633333   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    0.363333   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    0.113333   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    0.030000   \n",
       "\n",
       "                                                                                                                       \\\n",
       "                                                                                                                  std   \n",
       "llm                           temperature nli                     ellm                     sim                          \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.338763   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.148101   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.360671   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.306084   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.207846   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.205801   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.090331   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.069282   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.293896   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.180710   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.372709   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.127017   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.086603   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.027321   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.653154   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.274993   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.217846   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.250346   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.150111   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.296180   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.075056   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034641   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                            citations/n_correct_citations  \\\n",
       "                                                                                                                                     mean   \n",
       "llm                           temperature nli                     ellm                     sim                                              \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      8.020000   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      5.220000   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      5.960000   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.796667   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.130000   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.120000   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.760000   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.796667   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      3.570000   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.910000   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.676667   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.623333   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.516667   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.380000   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.343333   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.650000   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.263333   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.663333   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.170000   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.490000   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.370000   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.076667   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      0.030000   \n",
       "\n",
       "                                                                                                             ...  \\\n",
       "                                                                                                             ...   \n",
       "llm                           temperature nli                     ellm                     sim               ...   \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "\n",
       "                                                                                                            correctness/answer_overlap  \\\n",
       "                                                                                                                                   std   \n",
       "llm                           temperature nli                     ellm                     sim                                           \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.013723   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.017918   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.030777   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.012892   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.012990   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.001443   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.007661   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.020651   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.060333   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.000000   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.014915   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.020207   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.006598   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.005774   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.028674   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.023094   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.024118   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.049460   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.075822   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.012317   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.028318   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.038105   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.014434   \n",
       "\n",
       "                                                                                                            correctness/answer_entail  \\\n",
       "                                                                                                                                 mean   \n",
       "llm                           temperature nli                     ellm                     sim                                          \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.923333   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.896667   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.910000   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.866667   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.910000   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.896667   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.900000   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.873333   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.860000   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.903333   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.886667   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.893333   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.863333   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.896667   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.866667   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.880000   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.840000   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.693333   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.726667   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.780000   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.616667   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.670000   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.826667   \n",
       "\n",
       "                                                                                                                       \\\n",
       "                                                                                                                  std   \n",
       "llm                           temperature nli                     ellm                     sim                          \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.011547   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.011547   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.011547   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.011547   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040415   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.046188   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.046188   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.075056   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.057735   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040415   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "\n",
       "                                                                                                            correctness/citations_recall  \\\n",
       "                                                                                                                                    mean   \n",
       "llm                           temperature nli                     ellm                     sim                                             \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.988333   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.971667   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.968333   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.915000   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.853333   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.825000   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.795000   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.785000   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.775000   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.753333   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.751667   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.735000   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.660000   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.655000   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.626667   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.578333   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.548333   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.525000   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.471667   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.451667   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.051667   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.033333   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.010000   \n",
       "\n",
       "                                                                                                                       \\\n",
       "                                                                                                                  std   \n",
       "llm                           temperature nli                     ellm                     sim                          \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.008660   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.025981   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.025981   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034641   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.028868   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017321   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.092376   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023094   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.025981   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.051962   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.030981   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.008660   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.080056   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.043868   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.074282   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.051962   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.080829   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.051188   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.002887   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.005774   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                            correctness/citations_precision  \\\n",
       "                                                                                                                                       mean   \n",
       "llm                           temperature nli                     ellm                     sim                                                \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.775833   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.876556   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.842111   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.907413   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.941667   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.875556   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.938778   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.907556   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.545670   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.907556   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.721619   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.929889   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.920000   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.961667   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.727884   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.644302   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.800444   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.608111   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.660222   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.457889   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.036111   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.042778   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.006667   \n",
       "\n",
       "                                                                                                                       \\\n",
       "                                                                                                                  std   \n",
       "llm                           temperature nli                     ellm                     sim                          \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.098810   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.070338   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.084337   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040843   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023671   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.037528   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.010585   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.009623   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.108477   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.018283   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.050125   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.023286   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.016358   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.088494   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.054568   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.078327   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.068060   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.101471   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.064275   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.006736   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.006736   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "\n",
       "                                                                                                            quality/answer_relevance  \\\n",
       "                                                                                                                                mean   \n",
       "llm                           temperature nli                     ellm                     sim                                         \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.735427   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.729280   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.725706   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.742347   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.751901   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.726039   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.747313   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.752517   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.696486   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.720451   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.720431   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.737396   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.719488   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.710307   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.715053   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.635162   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.767839   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.614176   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.738827   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.663574   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.564932   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.708830   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.737850   \n",
       "\n",
       "                                                                                                                       \\\n",
       "                                                                                                                  std   \n",
       "llm                           temperature nli                     ellm                     sim                          \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.071202   \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.055383   \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.063220   \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.040067   \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.041098   \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.030875   \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.033935   \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.027829   \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.059428   \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.031690   \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.028340   \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.055224   \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.038641   \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.026912   \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.041852   \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.046987   \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034364   \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.045262   \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.043209   \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.037250   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.044756   \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.019533   \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.027130   \n",
       "\n",
       "                                                                                                            n_questions  \n",
       "                                                                                                                         \n",
       "llm                           temperature nli                     ellm                     sim                           \n",
       "rag-tge_Llama-3-8B_v1         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "rag-tge_Mistral_v2-4480       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "rag-tge_Mistral_v2-3360       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "rag-tge_Mistral.Q8            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "gpt-3.5-turbo-0125            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Mixtral-8x7B-Instruct-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "gpt-4-turbo                   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Meta-Llama-3-70B-Instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "zephyr-orpo-141b-A35b-v0.1    0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Meta-Llama-3-8B-Instruct      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Mistral-7B-Instruct-v0.2      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "qwen1_5-110b-chat             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "qwen1_5-14b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "qwen1_5-32b-chat-q8_0         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "zephyr-7b-beta                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "c4ai-command-r-plus           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "qwen1_5-7b-chat-q8_0          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "rag-tge_TinyLlama.Q32         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "gemma-1.1-7b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Phi-3-mini-4k-instruct        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "gemma-1.1-2b-it               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "Mistral-7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         100  \n",
       "\n",
       "[23 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Evaluation results\"))\n",
    "eval_display = eval_results[eval_results.index.get_level_values(\"prompt_id\") == \"1\"]\n",
    "eval_display = eval_display[eval_display.index.get_level_values(\"temperature\") == \"0.1\"]\n",
    "eval_display = eval_display[eval_display.index.get_level_values(\"llm\") != \"Mixtral-8x7B-Instruct-v0.1.Q8_0\"]  # use this model only for training data, because we already have same model without quantization\n",
    "eval_display = remove_index(eval_display, \"prompt_id\")\n",
    "eval_display = eval_display.sort_values(by=(\"correctness/citations_recall\", \"mean\"), ascending=False)\n",
    "eval_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### sorted by: citations/ais_recall"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.812135</td>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.957667</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.860838</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907413</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.742347</td>\n",
       "      <td>0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.737556</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.733170</td>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.954283</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.915308</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.876556</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.729280</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.877302</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.938778</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.747313</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.865923</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.752517</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.682667</td>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.957922</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.936128</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.842111</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.725706</td>\n",
       "      <td>0.063220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.928603</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.909923</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.726039</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.640377</td>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.953748</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.988333</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.735427</td>\n",
       "      <td>0.071202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.719488</td>\n",
       "      <td>0.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.871517</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.872812</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.721619</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.528167</td>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.867315</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.929889</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.737396</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.873725</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710307</td>\n",
       "      <td>0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.492702</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.951210</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.720451</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.417516</td>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.796321</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.807244</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.545670</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.696486</td>\n",
       "      <td>0.059428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.409167</td>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.735956</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578333</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.644302</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.635162</td>\n",
       "      <td>0.046987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.406690</td>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.910524</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.853718</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.727884</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.715053</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_TinyLlama.Q32</th>\n",
       "      <td>0.405833</td>\n",
       "      <td>0.121770</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>0.039015</td>\n",
       "      <td>0.677537</td>\n",
       "      <td>0.049460</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.608111</td>\n",
       "      <td>0.068060</td>\n",
       "      <td>0.614176</td>\n",
       "      <td>0.045262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.367889</td>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.722513</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.471667</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.660222</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.738827</td>\n",
       "      <td>0.043209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.252796</td>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.711068</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.457889</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.663574</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.233444</td>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.864821</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.800444</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.767839</td>\n",
       "      <td>0.034364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinyllama-1.1b-chat-v1.0.Q8_0</th>\n",
       "      <td>0.041361</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>0.566297</td>\n",
       "      <td>0.028318</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.564932</td>\n",
       "      <td>0.044756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.046111</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.630654</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.708830</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790410</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737850</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              citations/ais_recall            \\\n",
       "                                              mean       std   \n",
       "llm                                                            \n",
       "rag-tge_Mistral.Q8                        0.812135  0.060520   \n",
       "gpt-3.5-turbo-0125                        0.737556  0.072604   \n",
       "rag-tge_Mistral_v2-4480                   0.733170  0.134646   \n",
       "gpt-4-turbo                               0.733013  0.045401   \n",
       "Meta-Llama-3-70B-Instruct                 0.691944  0.049556   \n",
       "rag-tge_Mistral_v2-3360                   0.682667  0.146211   \n",
       "Mixtral-8x7B-Instruct-v0.1                0.653500  0.061199   \n",
       "rag-tge_Llama-3-8B_v1                     0.640377  0.100349   \n",
       "qwen1_5-14b-chat-q8_0                     0.633333  0.042339   \n",
       "Mistral-7B-Instruct-v0.2                  0.575644  0.036560   \n",
       "qwen1_5-110b-chat                         0.528167  0.095486   \n",
       "qwen1_5-32b-chat-q8_0                     0.512222  0.031856   \n",
       "Meta-Llama-3-8B-Instruct                  0.492702  0.060547   \n",
       "zephyr-orpo-141b-A35b-v0.1                0.417516  0.134222   \n",
       "c4ai-command-r-plus                       0.409167  0.060382   \n",
       "zephyr-7b-beta                            0.406690  0.090558   \n",
       "rag-tge_TinyLlama.Q32                     0.405833  0.121770   \n",
       "gemma-1.1-7b-it                           0.367889  0.122999   \n",
       "Phi-3-mini-4k-instruct                    0.252796  0.030503   \n",
       "qwen1_5-7b-chat-q8_0                      0.233444  0.063671   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0             0.041361  0.010585   \n",
       "gemma-1.1-2b-it                           0.006667  0.005774   \n",
       "Mistral-7B-Instruct-v0.1                  0.005000  0.000000   \n",
       "\n",
       "                              citations/ais_precision            \\\n",
       "                                                 mean       std   \n",
       "llm                                                               \n",
       "rag-tge_Mistral.Q8                           0.957667  0.021027   \n",
       "gpt-3.5-turbo-0125                           0.995833  0.002887   \n",
       "rag-tge_Mistral_v2-4480                      0.954283  0.031338   \n",
       "gpt-4-turbo                                  0.985000  0.005774   \n",
       "Meta-Llama-3-70B-Instruct                    0.955556  0.017802   \n",
       "rag-tge_Mistral_v2-3360                      0.957922  0.032981   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.928603  0.029692   \n",
       "rag-tge_Llama-3-8B_v1                        0.953748  0.030020   \n",
       "qwen1_5-14b-chat-q8_0                        0.975000  0.008660   \n",
       "Mistral-7B-Instruct-v0.2                     0.871517  0.038350   \n",
       "qwen1_5-110b-chat                            0.976111  0.026943   \n",
       "qwen1_5-32b-chat-q8_0                        0.993333  0.002887   \n",
       "Meta-Llama-3-8B-Instruct                     0.951210  0.022033   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.796321  0.101052   \n",
       "c4ai-command-r-plus                          0.714694  0.061399   \n",
       "zephyr-7b-beta                               0.910524  0.068665   \n",
       "rag-tge_TinyLlama.Q32                        0.749778  0.039015   \n",
       "gemma-1.1-7b-it                              0.766667  0.082995   \n",
       "Phi-3-mini-4k-instruct                       0.578455  0.069580   \n",
       "qwen1_5-7b-chat-q8_0                         0.862000  0.057158   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                0.125000  0.031754   \n",
       "gemma-1.1-2b-it                              0.046111  0.009623   \n",
       "Mistral-7B-Instruct-v0.1                     0.010000  0.000000   \n",
       "\n",
       "                              correctness/answer_overlap            \\\n",
       "                                                    mean       std   \n",
       "llm                                                                  \n",
       "rag-tge_Mistral.Q8                              0.860838  0.012892   \n",
       "gpt-3.5-turbo-0125                              0.884244  0.012990   \n",
       "rag-tge_Mistral_v2-4480                         0.915308  0.017918   \n",
       "gpt-4-turbo                                     0.877302  0.007661   \n",
       "Meta-Llama-3-70B-Instruct                       0.865923  0.020651   \n",
       "rag-tge_Mistral_v2-3360                         0.936128  0.030777   \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.909923  0.001443   \n",
       "rag-tge_Llama-3-8B_v1                           0.944436  0.013723   \n",
       "qwen1_5-14b-chat-q8_0                           0.876344  0.006598   \n",
       "Mistral-7B-Instruct-v0.2                        0.872812  0.014915   \n",
       "qwen1_5-110b-chat                               0.867315  0.020207   \n",
       "qwen1_5-32b-chat-q8_0                           0.873725  0.005774   \n",
       "Meta-Llama-3-8B-Instruct                        0.917846  0.000000   \n",
       "zephyr-orpo-141b-A35b-v0.1                      0.807244  0.060333   \n",
       "c4ai-command-r-plus                             0.735956  0.023094   \n",
       "zephyr-7b-beta                                  0.853718  0.028674   \n",
       "rag-tge_TinyLlama.Q32                           0.677537  0.049460   \n",
       "gemma-1.1-7b-it                                 0.722513  0.075822   \n",
       "Phi-3-mini-4k-instruct                          0.711068  0.012317   \n",
       "qwen1_5-7b-chat-q8_0                            0.864821  0.024118   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                   0.566297  0.028318   \n",
       "gemma-1.1-2b-it                                 0.630654  0.038105   \n",
       "Mistral-7B-Instruct-v0.1                        0.790410  0.014434   \n",
       "\n",
       "                              correctness/answer_entail            \\\n",
       "                                                   mean       std   \n",
       "llm                                                                 \n",
       "rag-tge_Mistral.Q8                             0.866667  0.005774   \n",
       "gpt-3.5-turbo-0125                             0.910000  0.011547   \n",
       "rag-tge_Mistral_v2-4480                        0.896667  0.023094   \n",
       "gpt-4-turbo                                    0.900000  0.011547   \n",
       "Meta-Llama-3-70B-Instruct                      0.873333  0.017321   \n",
       "rag-tge_Mistral_v2-3360                        0.910000  0.011547   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.896667  0.011547   \n",
       "rag-tge_Llama-3-8B_v1                          0.923333  0.023094   \n",
       "qwen1_5-14b-chat-q8_0                          0.863333  0.005774   \n",
       "Mistral-7B-Instruct-v0.2                       0.886667  0.017321   \n",
       "qwen1_5-110b-chat                              0.893333  0.017321   \n",
       "qwen1_5-32b-chat-q8_0                          0.896667  0.005774   \n",
       "Meta-Llama-3-8B-Instruct                       0.903333  0.005774   \n",
       "zephyr-orpo-141b-A35b-v0.1                     0.860000  0.040415   \n",
       "c4ai-command-r-plus                            0.880000  0.000000   \n",
       "zephyr-7b-beta                                 0.866667  0.046188   \n",
       "rag-tge_TinyLlama.Q32                          0.693333  0.046188   \n",
       "gemma-1.1-7b-it                                0.726667  0.075056   \n",
       "Phi-3-mini-4k-instruct                         0.780000  0.023094   \n",
       "qwen1_5-7b-chat-q8_0                           0.840000  0.023094   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                  0.616667  0.057735   \n",
       "gemma-1.1-2b-it                                0.670000  0.040415   \n",
       "Mistral-7B-Instruct-v0.1                       0.826667  0.017321   \n",
       "\n",
       "                              correctness/citations_recall            \\\n",
       "                                                      mean       std   \n",
       "llm                                                                    \n",
       "rag-tge_Mistral.Q8                                0.915000  0.023094   \n",
       "gpt-3.5-turbo-0125                                0.853333  0.023094   \n",
       "rag-tge_Mistral_v2-4480                           0.971667  0.025981   \n",
       "gpt-4-turbo                                       0.795000  0.028868   \n",
       "Meta-Llama-3-70B-Instruct                         0.785000  0.017321   \n",
       "rag-tge_Mistral_v2-3360                           0.968333  0.025981   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.825000  0.034641   \n",
       "rag-tge_Llama-3-8B_v1                             0.988333  0.008660   \n",
       "qwen1_5-14b-chat-q8_0                             0.660000  0.030981   \n",
       "Mistral-7B-Instruct-v0.2                          0.751667  0.025981   \n",
       "qwen1_5-110b-chat                                 0.735000  0.051962   \n",
       "qwen1_5-32b-chat-q8_0                             0.655000  0.008660   \n",
       "Meta-Llama-3-8B-Instruct                          0.753333  0.023094   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.775000  0.092376   \n",
       "c4ai-command-r-plus                               0.578333  0.043868   \n",
       "zephyr-7b-beta                                    0.626667  0.080056   \n",
       "rag-tge_TinyLlama.Q32                             0.525000  0.051962   \n",
       "gemma-1.1-7b-it                                   0.471667  0.080829   \n",
       "Phi-3-mini-4k-instruct                            0.451667  0.051188   \n",
       "qwen1_5-7b-chat-q8_0                              0.548333  0.074282   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                     0.051667  0.002887   \n",
       "gemma-1.1-2b-it                                   0.033333  0.005774   \n",
       "Mistral-7B-Instruct-v0.1                          0.010000  0.000000   \n",
       "\n",
       "                              correctness/citations_precision            \\\n",
       "                                                         mean       std   \n",
       "llm                                                                       \n",
       "rag-tge_Mistral.Q8                                   0.907413  0.040843   \n",
       "gpt-3.5-turbo-0125                                   0.941667  0.023671   \n",
       "rag-tge_Mistral_v2-4480                              0.876556  0.070338   \n",
       "gpt-4-turbo                                          0.938778  0.010585   \n",
       "Meta-Llama-3-70B-Instruct                            0.907556  0.009623   \n",
       "rag-tge_Mistral_v2-3360                              0.842111  0.084337   \n",
       "Mixtral-8x7B-Instruct-v0.1                           0.875556  0.037528   \n",
       "rag-tge_Llama-3-8B_v1                                0.775833  0.098810   \n",
       "qwen1_5-14b-chat-q8_0                                0.920000  0.016358   \n",
       "Mistral-7B-Instruct-v0.2                             0.721619  0.050125   \n",
       "qwen1_5-110b-chat                                    0.929889  0.023286   \n",
       "qwen1_5-32b-chat-q8_0                                0.961667  0.000000   \n",
       "Meta-Llama-3-8B-Instruct                             0.907556  0.018283   \n",
       "zephyr-orpo-141b-A35b-v0.1                           0.545670  0.108477   \n",
       "c4ai-command-r-plus                                  0.644302  0.054568   \n",
       "zephyr-7b-beta                                       0.727884  0.088494   \n",
       "rag-tge_TinyLlama.Q32                                0.608111  0.068060   \n",
       "gemma-1.1-7b-it                                      0.660222  0.101471   \n",
       "Phi-3-mini-4k-instruct                               0.457889  0.064275   \n",
       "qwen1_5-7b-chat-q8_0                                 0.800444  0.078327   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                        0.036111  0.006736   \n",
       "gemma-1.1-2b-it                                      0.042778  0.006736   \n",
       "Mistral-7B-Instruct-v0.1                             0.006667  0.000000   \n",
       "\n",
       "                              quality/answer_relevance            \n",
       "                                                  mean       std  \n",
       "llm                                                               \n",
       "rag-tge_Mistral.Q8                            0.742347  0.040067  \n",
       "gpt-3.5-turbo-0125                            0.751901  0.041098  \n",
       "rag-tge_Mistral_v2-4480                       0.729280  0.055383  \n",
       "gpt-4-turbo                                   0.747313  0.033935  \n",
       "Meta-Llama-3-70B-Instruct                     0.752517  0.027829  \n",
       "rag-tge_Mistral_v2-3360                       0.725706  0.063220  \n",
       "Mixtral-8x7B-Instruct-v0.1                    0.726039  0.030875  \n",
       "rag-tge_Llama-3-8B_v1                         0.735427  0.071202  \n",
       "qwen1_5-14b-chat-q8_0                         0.719488  0.038641  \n",
       "Mistral-7B-Instruct-v0.2                      0.720431  0.028340  \n",
       "qwen1_5-110b-chat                             0.737396  0.055224  \n",
       "qwen1_5-32b-chat-q8_0                         0.710307  0.026912  \n",
       "Meta-Llama-3-8B-Instruct                      0.720451  0.031690  \n",
       "zephyr-orpo-141b-A35b-v0.1                    0.696486  0.059428  \n",
       "c4ai-command-r-plus                           0.635162  0.046987  \n",
       "zephyr-7b-beta                                0.715053  0.041852  \n",
       "rag-tge_TinyLlama.Q32                         0.614176  0.045262  \n",
       "gemma-1.1-7b-it                               0.738827  0.043209  \n",
       "Phi-3-mini-4k-instruct                        0.663574  0.037250  \n",
       "qwen1_5-7b-chat-q8_0                          0.767839  0.034364  \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                 0.564932  0.044756  \n",
       "gemma-1.1-2b-it                               0.708830  0.019533  \n",
       "Mistral-7B-Instruct-v0.1                      0.737850  0.027130  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: citations/ais_precision"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.737556</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.873725</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710307</td>\n",
       "      <td>0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.877302</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.938778</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.747313</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.528167</td>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.867315</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.929889</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.737396</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.719488</td>\n",
       "      <td>0.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.682667</td>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.957922</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.936128</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.842111</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.725706</td>\n",
       "      <td>0.063220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.812135</td>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.957667</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.860838</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907413</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.742347</td>\n",
       "      <td>0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.865923</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.752517</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.733170</td>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.954283</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.915308</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.876556</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.729280</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.640377</td>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.953748</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.988333</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.735427</td>\n",
       "      <td>0.071202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.492702</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.951210</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.720451</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.928603</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.909923</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.726039</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.406690</td>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.910524</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.853718</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.727884</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.715053</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.871517</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.872812</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.721619</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.233444</td>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.864821</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.800444</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.767839</td>\n",
       "      <td>0.034364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.417516</td>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.796321</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.807244</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.545670</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.696486</td>\n",
       "      <td>0.059428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.367889</td>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.722513</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.471667</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.660222</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.738827</td>\n",
       "      <td>0.043209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_TinyLlama.Q32</th>\n",
       "      <td>0.405833</td>\n",
       "      <td>0.121770</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>0.039015</td>\n",
       "      <td>0.677537</td>\n",
       "      <td>0.049460</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.608111</td>\n",
       "      <td>0.068060</td>\n",
       "      <td>0.614176</td>\n",
       "      <td>0.045262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.409167</td>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.735956</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578333</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.644302</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.635162</td>\n",
       "      <td>0.046987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.252796</td>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.711068</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.457889</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.663574</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinyllama-1.1b-chat-v1.0.Q8_0</th>\n",
       "      <td>0.041361</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>0.566297</td>\n",
       "      <td>0.028318</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.564932</td>\n",
       "      <td>0.044756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.046111</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.630654</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.708830</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790410</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737850</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              citations/ais_recall            \\\n",
       "                                              mean       std   \n",
       "llm                                                            \n",
       "gpt-3.5-turbo-0125                        0.737556  0.072604   \n",
       "qwen1_5-32b-chat-q8_0                     0.512222  0.031856   \n",
       "gpt-4-turbo                               0.733013  0.045401   \n",
       "qwen1_5-110b-chat                         0.528167  0.095486   \n",
       "qwen1_5-14b-chat-q8_0                     0.633333  0.042339   \n",
       "rag-tge_Mistral_v2-3360                   0.682667  0.146211   \n",
       "rag-tge_Mistral.Q8                        0.812135  0.060520   \n",
       "Meta-Llama-3-70B-Instruct                 0.691944  0.049556   \n",
       "rag-tge_Mistral_v2-4480                   0.733170  0.134646   \n",
       "rag-tge_Llama-3-8B_v1                     0.640377  0.100349   \n",
       "Meta-Llama-3-8B-Instruct                  0.492702  0.060547   \n",
       "Mixtral-8x7B-Instruct-v0.1                0.653500  0.061199   \n",
       "zephyr-7b-beta                            0.406690  0.090558   \n",
       "Mistral-7B-Instruct-v0.2                  0.575644  0.036560   \n",
       "qwen1_5-7b-chat-q8_0                      0.233444  0.063671   \n",
       "zephyr-orpo-141b-A35b-v0.1                0.417516  0.134222   \n",
       "gemma-1.1-7b-it                           0.367889  0.122999   \n",
       "rag-tge_TinyLlama.Q32                     0.405833  0.121770   \n",
       "c4ai-command-r-plus                       0.409167  0.060382   \n",
       "Phi-3-mini-4k-instruct                    0.252796  0.030503   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0             0.041361  0.010585   \n",
       "gemma-1.1-2b-it                           0.006667  0.005774   \n",
       "Mistral-7B-Instruct-v0.1                  0.005000  0.000000   \n",
       "\n",
       "                              citations/ais_precision            \\\n",
       "                                                 mean       std   \n",
       "llm                                                               \n",
       "gpt-3.5-turbo-0125                           0.995833  0.002887   \n",
       "qwen1_5-32b-chat-q8_0                        0.993333  0.002887   \n",
       "gpt-4-turbo                                  0.985000  0.005774   \n",
       "qwen1_5-110b-chat                            0.976111  0.026943   \n",
       "qwen1_5-14b-chat-q8_0                        0.975000  0.008660   \n",
       "rag-tge_Mistral_v2-3360                      0.957922  0.032981   \n",
       "rag-tge_Mistral.Q8                           0.957667  0.021027   \n",
       "Meta-Llama-3-70B-Instruct                    0.955556  0.017802   \n",
       "rag-tge_Mistral_v2-4480                      0.954283  0.031338   \n",
       "rag-tge_Llama-3-8B_v1                        0.953748  0.030020   \n",
       "Meta-Llama-3-8B-Instruct                     0.951210  0.022033   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.928603  0.029692   \n",
       "zephyr-7b-beta                               0.910524  0.068665   \n",
       "Mistral-7B-Instruct-v0.2                     0.871517  0.038350   \n",
       "qwen1_5-7b-chat-q8_0                         0.862000  0.057158   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.796321  0.101052   \n",
       "gemma-1.1-7b-it                              0.766667  0.082995   \n",
       "rag-tge_TinyLlama.Q32                        0.749778  0.039015   \n",
       "c4ai-command-r-plus                          0.714694  0.061399   \n",
       "Phi-3-mini-4k-instruct                       0.578455  0.069580   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                0.125000  0.031754   \n",
       "gemma-1.1-2b-it                              0.046111  0.009623   \n",
       "Mistral-7B-Instruct-v0.1                     0.010000  0.000000   \n",
       "\n",
       "                              correctness/answer_overlap            \\\n",
       "                                                    mean       std   \n",
       "llm                                                                  \n",
       "gpt-3.5-turbo-0125                              0.884244  0.012990   \n",
       "qwen1_5-32b-chat-q8_0                           0.873725  0.005774   \n",
       "gpt-4-turbo                                     0.877302  0.007661   \n",
       "qwen1_5-110b-chat                               0.867315  0.020207   \n",
       "qwen1_5-14b-chat-q8_0                           0.876344  0.006598   \n",
       "rag-tge_Mistral_v2-3360                         0.936128  0.030777   \n",
       "rag-tge_Mistral.Q8                              0.860838  0.012892   \n",
       "Meta-Llama-3-70B-Instruct                       0.865923  0.020651   \n",
       "rag-tge_Mistral_v2-4480                         0.915308  0.017918   \n",
       "rag-tge_Llama-3-8B_v1                           0.944436  0.013723   \n",
       "Meta-Llama-3-8B-Instruct                        0.917846  0.000000   \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.909923  0.001443   \n",
       "zephyr-7b-beta                                  0.853718  0.028674   \n",
       "Mistral-7B-Instruct-v0.2                        0.872812  0.014915   \n",
       "qwen1_5-7b-chat-q8_0                            0.864821  0.024118   \n",
       "zephyr-orpo-141b-A35b-v0.1                      0.807244  0.060333   \n",
       "gemma-1.1-7b-it                                 0.722513  0.075822   \n",
       "rag-tge_TinyLlama.Q32                           0.677537  0.049460   \n",
       "c4ai-command-r-plus                             0.735956  0.023094   \n",
       "Phi-3-mini-4k-instruct                          0.711068  0.012317   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                   0.566297  0.028318   \n",
       "gemma-1.1-2b-it                                 0.630654  0.038105   \n",
       "Mistral-7B-Instruct-v0.1                        0.790410  0.014434   \n",
       "\n",
       "                              correctness/answer_entail            \\\n",
       "                                                   mean       std   \n",
       "llm                                                                 \n",
       "gpt-3.5-turbo-0125                             0.910000  0.011547   \n",
       "qwen1_5-32b-chat-q8_0                          0.896667  0.005774   \n",
       "gpt-4-turbo                                    0.900000  0.011547   \n",
       "qwen1_5-110b-chat                              0.893333  0.017321   \n",
       "qwen1_5-14b-chat-q8_0                          0.863333  0.005774   \n",
       "rag-tge_Mistral_v2-3360                        0.910000  0.011547   \n",
       "rag-tge_Mistral.Q8                             0.866667  0.005774   \n",
       "Meta-Llama-3-70B-Instruct                      0.873333  0.017321   \n",
       "rag-tge_Mistral_v2-4480                        0.896667  0.023094   \n",
       "rag-tge_Llama-3-8B_v1                          0.923333  0.023094   \n",
       "Meta-Llama-3-8B-Instruct                       0.903333  0.005774   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.896667  0.011547   \n",
       "zephyr-7b-beta                                 0.866667  0.046188   \n",
       "Mistral-7B-Instruct-v0.2                       0.886667  0.017321   \n",
       "qwen1_5-7b-chat-q8_0                           0.840000  0.023094   \n",
       "zephyr-orpo-141b-A35b-v0.1                     0.860000  0.040415   \n",
       "gemma-1.1-7b-it                                0.726667  0.075056   \n",
       "rag-tge_TinyLlama.Q32                          0.693333  0.046188   \n",
       "c4ai-command-r-plus                            0.880000  0.000000   \n",
       "Phi-3-mini-4k-instruct                         0.780000  0.023094   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                  0.616667  0.057735   \n",
       "gemma-1.1-2b-it                                0.670000  0.040415   \n",
       "Mistral-7B-Instruct-v0.1                       0.826667  0.017321   \n",
       "\n",
       "                              correctness/citations_recall            \\\n",
       "                                                      mean       std   \n",
       "llm                                                                    \n",
       "gpt-3.5-turbo-0125                                0.853333  0.023094   \n",
       "qwen1_5-32b-chat-q8_0                             0.655000  0.008660   \n",
       "gpt-4-turbo                                       0.795000  0.028868   \n",
       "qwen1_5-110b-chat                                 0.735000  0.051962   \n",
       "qwen1_5-14b-chat-q8_0                             0.660000  0.030981   \n",
       "rag-tge_Mistral_v2-3360                           0.968333  0.025981   \n",
       "rag-tge_Mistral.Q8                                0.915000  0.023094   \n",
       "Meta-Llama-3-70B-Instruct                         0.785000  0.017321   \n",
       "rag-tge_Mistral_v2-4480                           0.971667  0.025981   \n",
       "rag-tge_Llama-3-8B_v1                             0.988333  0.008660   \n",
       "Meta-Llama-3-8B-Instruct                          0.753333  0.023094   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.825000  0.034641   \n",
       "zephyr-7b-beta                                    0.626667  0.080056   \n",
       "Mistral-7B-Instruct-v0.2                          0.751667  0.025981   \n",
       "qwen1_5-7b-chat-q8_0                              0.548333  0.074282   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.775000  0.092376   \n",
       "gemma-1.1-7b-it                                   0.471667  0.080829   \n",
       "rag-tge_TinyLlama.Q32                             0.525000  0.051962   \n",
       "c4ai-command-r-plus                               0.578333  0.043868   \n",
       "Phi-3-mini-4k-instruct                            0.451667  0.051188   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                     0.051667  0.002887   \n",
       "gemma-1.1-2b-it                                   0.033333  0.005774   \n",
       "Mistral-7B-Instruct-v0.1                          0.010000  0.000000   \n",
       "\n",
       "                              correctness/citations_precision            \\\n",
       "                                                         mean       std   \n",
       "llm                                                                       \n",
       "gpt-3.5-turbo-0125                                   0.941667  0.023671   \n",
       "qwen1_5-32b-chat-q8_0                                0.961667  0.000000   \n",
       "gpt-4-turbo                                          0.938778  0.010585   \n",
       "qwen1_5-110b-chat                                    0.929889  0.023286   \n",
       "qwen1_5-14b-chat-q8_0                                0.920000  0.016358   \n",
       "rag-tge_Mistral_v2-3360                              0.842111  0.084337   \n",
       "rag-tge_Mistral.Q8                                   0.907413  0.040843   \n",
       "Meta-Llama-3-70B-Instruct                            0.907556  0.009623   \n",
       "rag-tge_Mistral_v2-4480                              0.876556  0.070338   \n",
       "rag-tge_Llama-3-8B_v1                                0.775833  0.098810   \n",
       "Meta-Llama-3-8B-Instruct                             0.907556  0.018283   \n",
       "Mixtral-8x7B-Instruct-v0.1                           0.875556  0.037528   \n",
       "zephyr-7b-beta                                       0.727884  0.088494   \n",
       "Mistral-7B-Instruct-v0.2                             0.721619  0.050125   \n",
       "qwen1_5-7b-chat-q8_0                                 0.800444  0.078327   \n",
       "zephyr-orpo-141b-A35b-v0.1                           0.545670  0.108477   \n",
       "gemma-1.1-7b-it                                      0.660222  0.101471   \n",
       "rag-tge_TinyLlama.Q32                                0.608111  0.068060   \n",
       "c4ai-command-r-plus                                  0.644302  0.054568   \n",
       "Phi-3-mini-4k-instruct                               0.457889  0.064275   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                        0.036111  0.006736   \n",
       "gemma-1.1-2b-it                                      0.042778  0.006736   \n",
       "Mistral-7B-Instruct-v0.1                             0.006667  0.000000   \n",
       "\n",
       "                              quality/answer_relevance            \n",
       "                                                  mean       std  \n",
       "llm                                                               \n",
       "gpt-3.5-turbo-0125                            0.751901  0.041098  \n",
       "qwen1_5-32b-chat-q8_0                         0.710307  0.026912  \n",
       "gpt-4-turbo                                   0.747313  0.033935  \n",
       "qwen1_5-110b-chat                             0.737396  0.055224  \n",
       "qwen1_5-14b-chat-q8_0                         0.719488  0.038641  \n",
       "rag-tge_Mistral_v2-3360                       0.725706  0.063220  \n",
       "rag-tge_Mistral.Q8                            0.742347  0.040067  \n",
       "Meta-Llama-3-70B-Instruct                     0.752517  0.027829  \n",
       "rag-tge_Mistral_v2-4480                       0.729280  0.055383  \n",
       "rag-tge_Llama-3-8B_v1                         0.735427  0.071202  \n",
       "Meta-Llama-3-8B-Instruct                      0.720451  0.031690  \n",
       "Mixtral-8x7B-Instruct-v0.1                    0.726039  0.030875  \n",
       "zephyr-7b-beta                                0.715053  0.041852  \n",
       "Mistral-7B-Instruct-v0.2                      0.720431  0.028340  \n",
       "qwen1_5-7b-chat-q8_0                          0.767839  0.034364  \n",
       "zephyr-orpo-141b-A35b-v0.1                    0.696486  0.059428  \n",
       "gemma-1.1-7b-it                               0.738827  0.043209  \n",
       "rag-tge_TinyLlama.Q32                         0.614176  0.045262  \n",
       "c4ai-command-r-plus                           0.635162  0.046987  \n",
       "Phi-3-mini-4k-instruct                        0.663574  0.037250  \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                 0.564932  0.044756  \n",
       "gemma-1.1-2b-it                               0.708830  0.019533  \n",
       "Mistral-7B-Instruct-v0.1                      0.737850  0.027130  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/answer_overlap"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.640377</td>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.953748</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.988333</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.735427</td>\n",
       "      <td>0.071202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.682667</td>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.957922</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.936128</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.842111</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.725706</td>\n",
       "      <td>0.063220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.492702</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.951210</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.720451</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.733170</td>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.954283</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.915308</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.876556</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.729280</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.928603</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.909923</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.726039</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.737556</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.877302</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.938778</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.747313</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.719488</td>\n",
       "      <td>0.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.873725</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710307</td>\n",
       "      <td>0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.871517</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.872812</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.721619</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.528167</td>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.867315</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.929889</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.737396</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.865923</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.752517</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.233444</td>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.864821</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.800444</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.767839</td>\n",
       "      <td>0.034364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.812135</td>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.957667</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.860838</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907413</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.742347</td>\n",
       "      <td>0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.406690</td>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.910524</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.853718</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.727884</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.715053</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.417516</td>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.796321</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.807244</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.545670</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.696486</td>\n",
       "      <td>0.059428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790410</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737850</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.409167</td>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.735956</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578333</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.644302</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.635162</td>\n",
       "      <td>0.046987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.367889</td>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.722513</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.471667</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.660222</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.738827</td>\n",
       "      <td>0.043209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.252796</td>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.711068</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.457889</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.663574</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_TinyLlama.Q32</th>\n",
       "      <td>0.405833</td>\n",
       "      <td>0.121770</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>0.039015</td>\n",
       "      <td>0.677537</td>\n",
       "      <td>0.049460</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.608111</td>\n",
       "      <td>0.068060</td>\n",
       "      <td>0.614176</td>\n",
       "      <td>0.045262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.046111</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.630654</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.708830</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinyllama-1.1b-chat-v1.0.Q8_0</th>\n",
       "      <td>0.041361</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>0.566297</td>\n",
       "      <td>0.028318</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.564932</td>\n",
       "      <td>0.044756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              citations/ais_recall            \\\n",
       "                                              mean       std   \n",
       "llm                                                            \n",
       "rag-tge_Llama-3-8B_v1                     0.640377  0.100349   \n",
       "rag-tge_Mistral_v2-3360                   0.682667  0.146211   \n",
       "Meta-Llama-3-8B-Instruct                  0.492702  0.060547   \n",
       "rag-tge_Mistral_v2-4480                   0.733170  0.134646   \n",
       "Mixtral-8x7B-Instruct-v0.1                0.653500  0.061199   \n",
       "gpt-3.5-turbo-0125                        0.737556  0.072604   \n",
       "gpt-4-turbo                               0.733013  0.045401   \n",
       "qwen1_5-14b-chat-q8_0                     0.633333  0.042339   \n",
       "qwen1_5-32b-chat-q8_0                     0.512222  0.031856   \n",
       "Mistral-7B-Instruct-v0.2                  0.575644  0.036560   \n",
       "qwen1_5-110b-chat                         0.528167  0.095486   \n",
       "Meta-Llama-3-70B-Instruct                 0.691944  0.049556   \n",
       "qwen1_5-7b-chat-q8_0                      0.233444  0.063671   \n",
       "rag-tge_Mistral.Q8                        0.812135  0.060520   \n",
       "zephyr-7b-beta                            0.406690  0.090558   \n",
       "zephyr-orpo-141b-A35b-v0.1                0.417516  0.134222   \n",
       "Mistral-7B-Instruct-v0.1                  0.005000  0.000000   \n",
       "c4ai-command-r-plus                       0.409167  0.060382   \n",
       "gemma-1.1-7b-it                           0.367889  0.122999   \n",
       "Phi-3-mini-4k-instruct                    0.252796  0.030503   \n",
       "rag-tge_TinyLlama.Q32                     0.405833  0.121770   \n",
       "gemma-1.1-2b-it                           0.006667  0.005774   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0             0.041361  0.010585   \n",
       "\n",
       "                              citations/ais_precision            \\\n",
       "                                                 mean       std   \n",
       "llm                                                               \n",
       "rag-tge_Llama-3-8B_v1                        0.953748  0.030020   \n",
       "rag-tge_Mistral_v2-3360                      0.957922  0.032981   \n",
       "Meta-Llama-3-8B-Instruct                     0.951210  0.022033   \n",
       "rag-tge_Mistral_v2-4480                      0.954283  0.031338   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.928603  0.029692   \n",
       "gpt-3.5-turbo-0125                           0.995833  0.002887   \n",
       "gpt-4-turbo                                  0.985000  0.005774   \n",
       "qwen1_5-14b-chat-q8_0                        0.975000  0.008660   \n",
       "qwen1_5-32b-chat-q8_0                        0.993333  0.002887   \n",
       "Mistral-7B-Instruct-v0.2                     0.871517  0.038350   \n",
       "qwen1_5-110b-chat                            0.976111  0.026943   \n",
       "Meta-Llama-3-70B-Instruct                    0.955556  0.017802   \n",
       "qwen1_5-7b-chat-q8_0                         0.862000  0.057158   \n",
       "rag-tge_Mistral.Q8                           0.957667  0.021027   \n",
       "zephyr-7b-beta                               0.910524  0.068665   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.796321  0.101052   \n",
       "Mistral-7B-Instruct-v0.1                     0.010000  0.000000   \n",
       "c4ai-command-r-plus                          0.714694  0.061399   \n",
       "gemma-1.1-7b-it                              0.766667  0.082995   \n",
       "Phi-3-mini-4k-instruct                       0.578455  0.069580   \n",
       "rag-tge_TinyLlama.Q32                        0.749778  0.039015   \n",
       "gemma-1.1-2b-it                              0.046111  0.009623   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                0.125000  0.031754   \n",
       "\n",
       "                              correctness/answer_overlap            \\\n",
       "                                                    mean       std   \n",
       "llm                                                                  \n",
       "rag-tge_Llama-3-8B_v1                           0.944436  0.013723   \n",
       "rag-tge_Mistral_v2-3360                         0.936128  0.030777   \n",
       "Meta-Llama-3-8B-Instruct                        0.917846  0.000000   \n",
       "rag-tge_Mistral_v2-4480                         0.915308  0.017918   \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.909923  0.001443   \n",
       "gpt-3.5-turbo-0125                              0.884244  0.012990   \n",
       "gpt-4-turbo                                     0.877302  0.007661   \n",
       "qwen1_5-14b-chat-q8_0                           0.876344  0.006598   \n",
       "qwen1_5-32b-chat-q8_0                           0.873725  0.005774   \n",
       "Mistral-7B-Instruct-v0.2                        0.872812  0.014915   \n",
       "qwen1_5-110b-chat                               0.867315  0.020207   \n",
       "Meta-Llama-3-70B-Instruct                       0.865923  0.020651   \n",
       "qwen1_5-7b-chat-q8_0                            0.864821  0.024118   \n",
       "rag-tge_Mistral.Q8                              0.860838  0.012892   \n",
       "zephyr-7b-beta                                  0.853718  0.028674   \n",
       "zephyr-orpo-141b-A35b-v0.1                      0.807244  0.060333   \n",
       "Mistral-7B-Instruct-v0.1                        0.790410  0.014434   \n",
       "c4ai-command-r-plus                             0.735956  0.023094   \n",
       "gemma-1.1-7b-it                                 0.722513  0.075822   \n",
       "Phi-3-mini-4k-instruct                          0.711068  0.012317   \n",
       "rag-tge_TinyLlama.Q32                           0.677537  0.049460   \n",
       "gemma-1.1-2b-it                                 0.630654  0.038105   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                   0.566297  0.028318   \n",
       "\n",
       "                              correctness/answer_entail            \\\n",
       "                                                   mean       std   \n",
       "llm                                                                 \n",
       "rag-tge_Llama-3-8B_v1                          0.923333  0.023094   \n",
       "rag-tge_Mistral_v2-3360                        0.910000  0.011547   \n",
       "Meta-Llama-3-8B-Instruct                       0.903333  0.005774   \n",
       "rag-tge_Mistral_v2-4480                        0.896667  0.023094   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.896667  0.011547   \n",
       "gpt-3.5-turbo-0125                             0.910000  0.011547   \n",
       "gpt-4-turbo                                    0.900000  0.011547   \n",
       "qwen1_5-14b-chat-q8_0                          0.863333  0.005774   \n",
       "qwen1_5-32b-chat-q8_0                          0.896667  0.005774   \n",
       "Mistral-7B-Instruct-v0.2                       0.886667  0.017321   \n",
       "qwen1_5-110b-chat                              0.893333  0.017321   \n",
       "Meta-Llama-3-70B-Instruct                      0.873333  0.017321   \n",
       "qwen1_5-7b-chat-q8_0                           0.840000  0.023094   \n",
       "rag-tge_Mistral.Q8                             0.866667  0.005774   \n",
       "zephyr-7b-beta                                 0.866667  0.046188   \n",
       "zephyr-orpo-141b-A35b-v0.1                     0.860000  0.040415   \n",
       "Mistral-7B-Instruct-v0.1                       0.826667  0.017321   \n",
       "c4ai-command-r-plus                            0.880000  0.000000   \n",
       "gemma-1.1-7b-it                                0.726667  0.075056   \n",
       "Phi-3-mini-4k-instruct                         0.780000  0.023094   \n",
       "rag-tge_TinyLlama.Q32                          0.693333  0.046188   \n",
       "gemma-1.1-2b-it                                0.670000  0.040415   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                  0.616667  0.057735   \n",
       "\n",
       "                              correctness/citations_recall            \\\n",
       "                                                      mean       std   \n",
       "llm                                                                    \n",
       "rag-tge_Llama-3-8B_v1                             0.988333  0.008660   \n",
       "rag-tge_Mistral_v2-3360                           0.968333  0.025981   \n",
       "Meta-Llama-3-8B-Instruct                          0.753333  0.023094   \n",
       "rag-tge_Mistral_v2-4480                           0.971667  0.025981   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.825000  0.034641   \n",
       "gpt-3.5-turbo-0125                                0.853333  0.023094   \n",
       "gpt-4-turbo                                       0.795000  0.028868   \n",
       "qwen1_5-14b-chat-q8_0                             0.660000  0.030981   \n",
       "qwen1_5-32b-chat-q8_0                             0.655000  0.008660   \n",
       "Mistral-7B-Instruct-v0.2                          0.751667  0.025981   \n",
       "qwen1_5-110b-chat                                 0.735000  0.051962   \n",
       "Meta-Llama-3-70B-Instruct                         0.785000  0.017321   \n",
       "qwen1_5-7b-chat-q8_0                              0.548333  0.074282   \n",
       "rag-tge_Mistral.Q8                                0.915000  0.023094   \n",
       "zephyr-7b-beta                                    0.626667  0.080056   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.775000  0.092376   \n",
       "Mistral-7B-Instruct-v0.1                          0.010000  0.000000   \n",
       "c4ai-command-r-plus                               0.578333  0.043868   \n",
       "gemma-1.1-7b-it                                   0.471667  0.080829   \n",
       "Phi-3-mini-4k-instruct                            0.451667  0.051188   \n",
       "rag-tge_TinyLlama.Q32                             0.525000  0.051962   \n",
       "gemma-1.1-2b-it                                   0.033333  0.005774   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                     0.051667  0.002887   \n",
       "\n",
       "                              correctness/citations_precision            \\\n",
       "                                                         mean       std   \n",
       "llm                                                                       \n",
       "rag-tge_Llama-3-8B_v1                                0.775833  0.098810   \n",
       "rag-tge_Mistral_v2-3360                              0.842111  0.084337   \n",
       "Meta-Llama-3-8B-Instruct                             0.907556  0.018283   \n",
       "rag-tge_Mistral_v2-4480                              0.876556  0.070338   \n",
       "Mixtral-8x7B-Instruct-v0.1                           0.875556  0.037528   \n",
       "gpt-3.5-turbo-0125                                   0.941667  0.023671   \n",
       "gpt-4-turbo                                          0.938778  0.010585   \n",
       "qwen1_5-14b-chat-q8_0                                0.920000  0.016358   \n",
       "qwen1_5-32b-chat-q8_0                                0.961667  0.000000   \n",
       "Mistral-7B-Instruct-v0.2                             0.721619  0.050125   \n",
       "qwen1_5-110b-chat                                    0.929889  0.023286   \n",
       "Meta-Llama-3-70B-Instruct                            0.907556  0.009623   \n",
       "qwen1_5-7b-chat-q8_0                                 0.800444  0.078327   \n",
       "rag-tge_Mistral.Q8                                   0.907413  0.040843   \n",
       "zephyr-7b-beta                                       0.727884  0.088494   \n",
       "zephyr-orpo-141b-A35b-v0.1                           0.545670  0.108477   \n",
       "Mistral-7B-Instruct-v0.1                             0.006667  0.000000   \n",
       "c4ai-command-r-plus                                  0.644302  0.054568   \n",
       "gemma-1.1-7b-it                                      0.660222  0.101471   \n",
       "Phi-3-mini-4k-instruct                               0.457889  0.064275   \n",
       "rag-tge_TinyLlama.Q32                                0.608111  0.068060   \n",
       "gemma-1.1-2b-it                                      0.042778  0.006736   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                        0.036111  0.006736   \n",
       "\n",
       "                              quality/answer_relevance            \n",
       "                                                  mean       std  \n",
       "llm                                                               \n",
       "rag-tge_Llama-3-8B_v1                         0.735427  0.071202  \n",
       "rag-tge_Mistral_v2-3360                       0.725706  0.063220  \n",
       "Meta-Llama-3-8B-Instruct                      0.720451  0.031690  \n",
       "rag-tge_Mistral_v2-4480                       0.729280  0.055383  \n",
       "Mixtral-8x7B-Instruct-v0.1                    0.726039  0.030875  \n",
       "gpt-3.5-turbo-0125                            0.751901  0.041098  \n",
       "gpt-4-turbo                                   0.747313  0.033935  \n",
       "qwen1_5-14b-chat-q8_0                         0.719488  0.038641  \n",
       "qwen1_5-32b-chat-q8_0                         0.710307  0.026912  \n",
       "Mistral-7B-Instruct-v0.2                      0.720431  0.028340  \n",
       "qwen1_5-110b-chat                             0.737396  0.055224  \n",
       "Meta-Llama-3-70B-Instruct                     0.752517  0.027829  \n",
       "qwen1_5-7b-chat-q8_0                          0.767839  0.034364  \n",
       "rag-tge_Mistral.Q8                            0.742347  0.040067  \n",
       "zephyr-7b-beta                                0.715053  0.041852  \n",
       "zephyr-orpo-141b-A35b-v0.1                    0.696486  0.059428  \n",
       "Mistral-7B-Instruct-v0.1                      0.737850  0.027130  \n",
       "c4ai-command-r-plus                           0.635162  0.046987  \n",
       "gemma-1.1-7b-it                               0.738827  0.043209  \n",
       "Phi-3-mini-4k-instruct                        0.663574  0.037250  \n",
       "rag-tge_TinyLlama.Q32                         0.614176  0.045262  \n",
       "gemma-1.1-2b-it                               0.708830  0.019533  \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                 0.564932  0.044756  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/answer_entail"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.640377</td>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.953748</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.988333</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.735427</td>\n",
       "      <td>0.071202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.682667</td>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.957922</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.936128</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.842111</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.725706</td>\n",
       "      <td>0.063220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.737556</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.492702</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.951210</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.720451</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.877302</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.938778</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.747313</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.928603</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.909923</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.726039</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.733170</td>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.954283</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.915308</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.876556</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.729280</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.873725</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710307</td>\n",
       "      <td>0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.528167</td>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.867315</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.929889</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.737396</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.871517</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.872812</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.721619</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.409167</td>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.735956</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578333</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.644302</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.635162</td>\n",
       "      <td>0.046987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.865923</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.752517</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.812135</td>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.957667</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.860838</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907413</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.742347</td>\n",
       "      <td>0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.406690</td>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.910524</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.853718</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.727884</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.715053</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.719488</td>\n",
       "      <td>0.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.417516</td>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.796321</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.807244</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.545670</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.696486</td>\n",
       "      <td>0.059428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.233444</td>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.864821</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.800444</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.767839</td>\n",
       "      <td>0.034364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790410</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737850</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.252796</td>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.711068</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.457889</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.663574</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.367889</td>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.722513</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.471667</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.660222</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.738827</td>\n",
       "      <td>0.043209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_TinyLlama.Q32</th>\n",
       "      <td>0.405833</td>\n",
       "      <td>0.121770</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>0.039015</td>\n",
       "      <td>0.677537</td>\n",
       "      <td>0.049460</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.608111</td>\n",
       "      <td>0.068060</td>\n",
       "      <td>0.614176</td>\n",
       "      <td>0.045262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.046111</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.630654</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.708830</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinyllama-1.1b-chat-v1.0.Q8_0</th>\n",
       "      <td>0.041361</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>0.566297</td>\n",
       "      <td>0.028318</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.564932</td>\n",
       "      <td>0.044756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              citations/ais_recall            \\\n",
       "                                              mean       std   \n",
       "llm                                                            \n",
       "rag-tge_Llama-3-8B_v1                     0.640377  0.100349   \n",
       "rag-tge_Mistral_v2-3360                   0.682667  0.146211   \n",
       "gpt-3.5-turbo-0125                        0.737556  0.072604   \n",
       "Meta-Llama-3-8B-Instruct                  0.492702  0.060547   \n",
       "gpt-4-turbo                               0.733013  0.045401   \n",
       "Mixtral-8x7B-Instruct-v0.1                0.653500  0.061199   \n",
       "rag-tge_Mistral_v2-4480                   0.733170  0.134646   \n",
       "qwen1_5-32b-chat-q8_0                     0.512222  0.031856   \n",
       "qwen1_5-110b-chat                         0.528167  0.095486   \n",
       "Mistral-7B-Instruct-v0.2                  0.575644  0.036560   \n",
       "c4ai-command-r-plus                       0.409167  0.060382   \n",
       "Meta-Llama-3-70B-Instruct                 0.691944  0.049556   \n",
       "rag-tge_Mistral.Q8                        0.812135  0.060520   \n",
       "zephyr-7b-beta                            0.406690  0.090558   \n",
       "qwen1_5-14b-chat-q8_0                     0.633333  0.042339   \n",
       "zephyr-orpo-141b-A35b-v0.1                0.417516  0.134222   \n",
       "qwen1_5-7b-chat-q8_0                      0.233444  0.063671   \n",
       "Mistral-7B-Instruct-v0.1                  0.005000  0.000000   \n",
       "Phi-3-mini-4k-instruct                    0.252796  0.030503   \n",
       "gemma-1.1-7b-it                           0.367889  0.122999   \n",
       "rag-tge_TinyLlama.Q32                     0.405833  0.121770   \n",
       "gemma-1.1-2b-it                           0.006667  0.005774   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0             0.041361  0.010585   \n",
       "\n",
       "                              citations/ais_precision            \\\n",
       "                                                 mean       std   \n",
       "llm                                                               \n",
       "rag-tge_Llama-3-8B_v1                        0.953748  0.030020   \n",
       "rag-tge_Mistral_v2-3360                      0.957922  0.032981   \n",
       "gpt-3.5-turbo-0125                           0.995833  0.002887   \n",
       "Meta-Llama-3-8B-Instruct                     0.951210  0.022033   \n",
       "gpt-4-turbo                                  0.985000  0.005774   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.928603  0.029692   \n",
       "rag-tge_Mistral_v2-4480                      0.954283  0.031338   \n",
       "qwen1_5-32b-chat-q8_0                        0.993333  0.002887   \n",
       "qwen1_5-110b-chat                            0.976111  0.026943   \n",
       "Mistral-7B-Instruct-v0.2                     0.871517  0.038350   \n",
       "c4ai-command-r-plus                          0.714694  0.061399   \n",
       "Meta-Llama-3-70B-Instruct                    0.955556  0.017802   \n",
       "rag-tge_Mistral.Q8                           0.957667  0.021027   \n",
       "zephyr-7b-beta                               0.910524  0.068665   \n",
       "qwen1_5-14b-chat-q8_0                        0.975000  0.008660   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.796321  0.101052   \n",
       "qwen1_5-7b-chat-q8_0                         0.862000  0.057158   \n",
       "Mistral-7B-Instruct-v0.1                     0.010000  0.000000   \n",
       "Phi-3-mini-4k-instruct                       0.578455  0.069580   \n",
       "gemma-1.1-7b-it                              0.766667  0.082995   \n",
       "rag-tge_TinyLlama.Q32                        0.749778  0.039015   \n",
       "gemma-1.1-2b-it                              0.046111  0.009623   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                0.125000  0.031754   \n",
       "\n",
       "                              correctness/answer_overlap            \\\n",
       "                                                    mean       std   \n",
       "llm                                                                  \n",
       "rag-tge_Llama-3-8B_v1                           0.944436  0.013723   \n",
       "rag-tge_Mistral_v2-3360                         0.936128  0.030777   \n",
       "gpt-3.5-turbo-0125                              0.884244  0.012990   \n",
       "Meta-Llama-3-8B-Instruct                        0.917846  0.000000   \n",
       "gpt-4-turbo                                     0.877302  0.007661   \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.909923  0.001443   \n",
       "rag-tge_Mistral_v2-4480                         0.915308  0.017918   \n",
       "qwen1_5-32b-chat-q8_0                           0.873725  0.005774   \n",
       "qwen1_5-110b-chat                               0.867315  0.020207   \n",
       "Mistral-7B-Instruct-v0.2                        0.872812  0.014915   \n",
       "c4ai-command-r-plus                             0.735956  0.023094   \n",
       "Meta-Llama-3-70B-Instruct                       0.865923  0.020651   \n",
       "rag-tge_Mistral.Q8                              0.860838  0.012892   \n",
       "zephyr-7b-beta                                  0.853718  0.028674   \n",
       "qwen1_5-14b-chat-q8_0                           0.876344  0.006598   \n",
       "zephyr-orpo-141b-A35b-v0.1                      0.807244  0.060333   \n",
       "qwen1_5-7b-chat-q8_0                            0.864821  0.024118   \n",
       "Mistral-7B-Instruct-v0.1                        0.790410  0.014434   \n",
       "Phi-3-mini-4k-instruct                          0.711068  0.012317   \n",
       "gemma-1.1-7b-it                                 0.722513  0.075822   \n",
       "rag-tge_TinyLlama.Q32                           0.677537  0.049460   \n",
       "gemma-1.1-2b-it                                 0.630654  0.038105   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                   0.566297  0.028318   \n",
       "\n",
       "                              correctness/answer_entail            \\\n",
       "                                                   mean       std   \n",
       "llm                                                                 \n",
       "rag-tge_Llama-3-8B_v1                          0.923333  0.023094   \n",
       "rag-tge_Mistral_v2-3360                        0.910000  0.011547   \n",
       "gpt-3.5-turbo-0125                             0.910000  0.011547   \n",
       "Meta-Llama-3-8B-Instruct                       0.903333  0.005774   \n",
       "gpt-4-turbo                                    0.900000  0.011547   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.896667  0.011547   \n",
       "rag-tge_Mistral_v2-4480                        0.896667  0.023094   \n",
       "qwen1_5-32b-chat-q8_0                          0.896667  0.005774   \n",
       "qwen1_5-110b-chat                              0.893333  0.017321   \n",
       "Mistral-7B-Instruct-v0.2                       0.886667  0.017321   \n",
       "c4ai-command-r-plus                            0.880000  0.000000   \n",
       "Meta-Llama-3-70B-Instruct                      0.873333  0.017321   \n",
       "rag-tge_Mistral.Q8                             0.866667  0.005774   \n",
       "zephyr-7b-beta                                 0.866667  0.046188   \n",
       "qwen1_5-14b-chat-q8_0                          0.863333  0.005774   \n",
       "zephyr-orpo-141b-A35b-v0.1                     0.860000  0.040415   \n",
       "qwen1_5-7b-chat-q8_0                           0.840000  0.023094   \n",
       "Mistral-7B-Instruct-v0.1                       0.826667  0.017321   \n",
       "Phi-3-mini-4k-instruct                         0.780000  0.023094   \n",
       "gemma-1.1-7b-it                                0.726667  0.075056   \n",
       "rag-tge_TinyLlama.Q32                          0.693333  0.046188   \n",
       "gemma-1.1-2b-it                                0.670000  0.040415   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                  0.616667  0.057735   \n",
       "\n",
       "                              correctness/citations_recall            \\\n",
       "                                                      mean       std   \n",
       "llm                                                                    \n",
       "rag-tge_Llama-3-8B_v1                             0.988333  0.008660   \n",
       "rag-tge_Mistral_v2-3360                           0.968333  0.025981   \n",
       "gpt-3.5-turbo-0125                                0.853333  0.023094   \n",
       "Meta-Llama-3-8B-Instruct                          0.753333  0.023094   \n",
       "gpt-4-turbo                                       0.795000  0.028868   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.825000  0.034641   \n",
       "rag-tge_Mistral_v2-4480                           0.971667  0.025981   \n",
       "qwen1_5-32b-chat-q8_0                             0.655000  0.008660   \n",
       "qwen1_5-110b-chat                                 0.735000  0.051962   \n",
       "Mistral-7B-Instruct-v0.2                          0.751667  0.025981   \n",
       "c4ai-command-r-plus                               0.578333  0.043868   \n",
       "Meta-Llama-3-70B-Instruct                         0.785000  0.017321   \n",
       "rag-tge_Mistral.Q8                                0.915000  0.023094   \n",
       "zephyr-7b-beta                                    0.626667  0.080056   \n",
       "qwen1_5-14b-chat-q8_0                             0.660000  0.030981   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.775000  0.092376   \n",
       "qwen1_5-7b-chat-q8_0                              0.548333  0.074282   \n",
       "Mistral-7B-Instruct-v0.1                          0.010000  0.000000   \n",
       "Phi-3-mini-4k-instruct                            0.451667  0.051188   \n",
       "gemma-1.1-7b-it                                   0.471667  0.080829   \n",
       "rag-tge_TinyLlama.Q32                             0.525000  0.051962   \n",
       "gemma-1.1-2b-it                                   0.033333  0.005774   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                     0.051667  0.002887   \n",
       "\n",
       "                              correctness/citations_precision            \\\n",
       "                                                         mean       std   \n",
       "llm                                                                       \n",
       "rag-tge_Llama-3-8B_v1                                0.775833  0.098810   \n",
       "rag-tge_Mistral_v2-3360                              0.842111  0.084337   \n",
       "gpt-3.5-turbo-0125                                   0.941667  0.023671   \n",
       "Meta-Llama-3-8B-Instruct                             0.907556  0.018283   \n",
       "gpt-4-turbo                                          0.938778  0.010585   \n",
       "Mixtral-8x7B-Instruct-v0.1                           0.875556  0.037528   \n",
       "rag-tge_Mistral_v2-4480                              0.876556  0.070338   \n",
       "qwen1_5-32b-chat-q8_0                                0.961667  0.000000   \n",
       "qwen1_5-110b-chat                                    0.929889  0.023286   \n",
       "Mistral-7B-Instruct-v0.2                             0.721619  0.050125   \n",
       "c4ai-command-r-plus                                  0.644302  0.054568   \n",
       "Meta-Llama-3-70B-Instruct                            0.907556  0.009623   \n",
       "rag-tge_Mistral.Q8                                   0.907413  0.040843   \n",
       "zephyr-7b-beta                                       0.727884  0.088494   \n",
       "qwen1_5-14b-chat-q8_0                                0.920000  0.016358   \n",
       "zephyr-orpo-141b-A35b-v0.1                           0.545670  0.108477   \n",
       "qwen1_5-7b-chat-q8_0                                 0.800444  0.078327   \n",
       "Mistral-7B-Instruct-v0.1                             0.006667  0.000000   \n",
       "Phi-3-mini-4k-instruct                               0.457889  0.064275   \n",
       "gemma-1.1-7b-it                                      0.660222  0.101471   \n",
       "rag-tge_TinyLlama.Q32                                0.608111  0.068060   \n",
       "gemma-1.1-2b-it                                      0.042778  0.006736   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                        0.036111  0.006736   \n",
       "\n",
       "                              quality/answer_relevance            \n",
       "                                                  mean       std  \n",
       "llm                                                               \n",
       "rag-tge_Llama-3-8B_v1                         0.735427  0.071202  \n",
       "rag-tge_Mistral_v2-3360                       0.725706  0.063220  \n",
       "gpt-3.5-turbo-0125                            0.751901  0.041098  \n",
       "Meta-Llama-3-8B-Instruct                      0.720451  0.031690  \n",
       "gpt-4-turbo                                   0.747313  0.033935  \n",
       "Mixtral-8x7B-Instruct-v0.1                    0.726039  0.030875  \n",
       "rag-tge_Mistral_v2-4480                       0.729280  0.055383  \n",
       "qwen1_5-32b-chat-q8_0                         0.710307  0.026912  \n",
       "qwen1_5-110b-chat                             0.737396  0.055224  \n",
       "Mistral-7B-Instruct-v0.2                      0.720431  0.028340  \n",
       "c4ai-command-r-plus                           0.635162  0.046987  \n",
       "Meta-Llama-3-70B-Instruct                     0.752517  0.027829  \n",
       "rag-tge_Mistral.Q8                            0.742347  0.040067  \n",
       "zephyr-7b-beta                                0.715053  0.041852  \n",
       "qwen1_5-14b-chat-q8_0                         0.719488  0.038641  \n",
       "zephyr-orpo-141b-A35b-v0.1                    0.696486  0.059428  \n",
       "qwen1_5-7b-chat-q8_0                          0.767839  0.034364  \n",
       "Mistral-7B-Instruct-v0.1                      0.737850  0.027130  \n",
       "Phi-3-mini-4k-instruct                        0.663574  0.037250  \n",
       "gemma-1.1-7b-it                               0.738827  0.043209  \n",
       "rag-tge_TinyLlama.Q32                         0.614176  0.045262  \n",
       "gemma-1.1-2b-it                               0.708830  0.019533  \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                 0.564932  0.044756  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/citations_recall"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.640377</td>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.953748</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.988333</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.735427</td>\n",
       "      <td>0.071202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.733170</td>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.954283</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.915308</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.876556</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.729280</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.682667</td>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.957922</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.936128</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.842111</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.725706</td>\n",
       "      <td>0.063220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.812135</td>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.957667</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.860838</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907413</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.742347</td>\n",
       "      <td>0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.737556</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.928603</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.909923</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.726039</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.877302</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.938778</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.747313</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.865923</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.752517</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.417516</td>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.796321</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.807244</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.545670</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.696486</td>\n",
       "      <td>0.059428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.492702</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.951210</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.720451</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.871517</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.872812</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.721619</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.528167</td>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.867315</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.929889</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.737396</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.719488</td>\n",
       "      <td>0.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.873725</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710307</td>\n",
       "      <td>0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.406690</td>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.910524</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.853718</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.727884</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.715053</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.409167</td>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.735956</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578333</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.644302</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.635162</td>\n",
       "      <td>0.046987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.233444</td>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.864821</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.800444</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.767839</td>\n",
       "      <td>0.034364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_TinyLlama.Q32</th>\n",
       "      <td>0.405833</td>\n",
       "      <td>0.121770</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>0.039015</td>\n",
       "      <td>0.677537</td>\n",
       "      <td>0.049460</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.608111</td>\n",
       "      <td>0.068060</td>\n",
       "      <td>0.614176</td>\n",
       "      <td>0.045262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.367889</td>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.722513</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.471667</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.660222</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.738827</td>\n",
       "      <td>0.043209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.252796</td>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.711068</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.457889</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.663574</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinyllama-1.1b-chat-v1.0.Q8_0</th>\n",
       "      <td>0.041361</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>0.566297</td>\n",
       "      <td>0.028318</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.564932</td>\n",
       "      <td>0.044756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.046111</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.630654</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.708830</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790410</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737850</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              citations/ais_recall            \\\n",
       "                                              mean       std   \n",
       "llm                                                            \n",
       "rag-tge_Llama-3-8B_v1                     0.640377  0.100349   \n",
       "rag-tge_Mistral_v2-4480                   0.733170  0.134646   \n",
       "rag-tge_Mistral_v2-3360                   0.682667  0.146211   \n",
       "rag-tge_Mistral.Q8                        0.812135  0.060520   \n",
       "gpt-3.5-turbo-0125                        0.737556  0.072604   \n",
       "Mixtral-8x7B-Instruct-v0.1                0.653500  0.061199   \n",
       "gpt-4-turbo                               0.733013  0.045401   \n",
       "Meta-Llama-3-70B-Instruct                 0.691944  0.049556   \n",
       "zephyr-orpo-141b-A35b-v0.1                0.417516  0.134222   \n",
       "Meta-Llama-3-8B-Instruct                  0.492702  0.060547   \n",
       "Mistral-7B-Instruct-v0.2                  0.575644  0.036560   \n",
       "qwen1_5-110b-chat                         0.528167  0.095486   \n",
       "qwen1_5-14b-chat-q8_0                     0.633333  0.042339   \n",
       "qwen1_5-32b-chat-q8_0                     0.512222  0.031856   \n",
       "zephyr-7b-beta                            0.406690  0.090558   \n",
       "c4ai-command-r-plus                       0.409167  0.060382   \n",
       "qwen1_5-7b-chat-q8_0                      0.233444  0.063671   \n",
       "rag-tge_TinyLlama.Q32                     0.405833  0.121770   \n",
       "gemma-1.1-7b-it                           0.367889  0.122999   \n",
       "Phi-3-mini-4k-instruct                    0.252796  0.030503   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0             0.041361  0.010585   \n",
       "gemma-1.1-2b-it                           0.006667  0.005774   \n",
       "Mistral-7B-Instruct-v0.1                  0.005000  0.000000   \n",
       "\n",
       "                              citations/ais_precision            \\\n",
       "                                                 mean       std   \n",
       "llm                                                               \n",
       "rag-tge_Llama-3-8B_v1                        0.953748  0.030020   \n",
       "rag-tge_Mistral_v2-4480                      0.954283  0.031338   \n",
       "rag-tge_Mistral_v2-3360                      0.957922  0.032981   \n",
       "rag-tge_Mistral.Q8                           0.957667  0.021027   \n",
       "gpt-3.5-turbo-0125                           0.995833  0.002887   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.928603  0.029692   \n",
       "gpt-4-turbo                                  0.985000  0.005774   \n",
       "Meta-Llama-3-70B-Instruct                    0.955556  0.017802   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.796321  0.101052   \n",
       "Meta-Llama-3-8B-Instruct                     0.951210  0.022033   \n",
       "Mistral-7B-Instruct-v0.2                     0.871517  0.038350   \n",
       "qwen1_5-110b-chat                            0.976111  0.026943   \n",
       "qwen1_5-14b-chat-q8_0                        0.975000  0.008660   \n",
       "qwen1_5-32b-chat-q8_0                        0.993333  0.002887   \n",
       "zephyr-7b-beta                               0.910524  0.068665   \n",
       "c4ai-command-r-plus                          0.714694  0.061399   \n",
       "qwen1_5-7b-chat-q8_0                         0.862000  0.057158   \n",
       "rag-tge_TinyLlama.Q32                        0.749778  0.039015   \n",
       "gemma-1.1-7b-it                              0.766667  0.082995   \n",
       "Phi-3-mini-4k-instruct                       0.578455  0.069580   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                0.125000  0.031754   \n",
       "gemma-1.1-2b-it                              0.046111  0.009623   \n",
       "Mistral-7B-Instruct-v0.1                     0.010000  0.000000   \n",
       "\n",
       "                              correctness/answer_overlap            \\\n",
       "                                                    mean       std   \n",
       "llm                                                                  \n",
       "rag-tge_Llama-3-8B_v1                           0.944436  0.013723   \n",
       "rag-tge_Mistral_v2-4480                         0.915308  0.017918   \n",
       "rag-tge_Mistral_v2-3360                         0.936128  0.030777   \n",
       "rag-tge_Mistral.Q8                              0.860838  0.012892   \n",
       "gpt-3.5-turbo-0125                              0.884244  0.012990   \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.909923  0.001443   \n",
       "gpt-4-turbo                                     0.877302  0.007661   \n",
       "Meta-Llama-3-70B-Instruct                       0.865923  0.020651   \n",
       "zephyr-orpo-141b-A35b-v0.1                      0.807244  0.060333   \n",
       "Meta-Llama-3-8B-Instruct                        0.917846  0.000000   \n",
       "Mistral-7B-Instruct-v0.2                        0.872812  0.014915   \n",
       "qwen1_5-110b-chat                               0.867315  0.020207   \n",
       "qwen1_5-14b-chat-q8_0                           0.876344  0.006598   \n",
       "qwen1_5-32b-chat-q8_0                           0.873725  0.005774   \n",
       "zephyr-7b-beta                                  0.853718  0.028674   \n",
       "c4ai-command-r-plus                             0.735956  0.023094   \n",
       "qwen1_5-7b-chat-q8_0                            0.864821  0.024118   \n",
       "rag-tge_TinyLlama.Q32                           0.677537  0.049460   \n",
       "gemma-1.1-7b-it                                 0.722513  0.075822   \n",
       "Phi-3-mini-4k-instruct                          0.711068  0.012317   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                   0.566297  0.028318   \n",
       "gemma-1.1-2b-it                                 0.630654  0.038105   \n",
       "Mistral-7B-Instruct-v0.1                        0.790410  0.014434   \n",
       "\n",
       "                              correctness/answer_entail            \\\n",
       "                                                   mean       std   \n",
       "llm                                                                 \n",
       "rag-tge_Llama-3-8B_v1                          0.923333  0.023094   \n",
       "rag-tge_Mistral_v2-4480                        0.896667  0.023094   \n",
       "rag-tge_Mistral_v2-3360                        0.910000  0.011547   \n",
       "rag-tge_Mistral.Q8                             0.866667  0.005774   \n",
       "gpt-3.5-turbo-0125                             0.910000  0.011547   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.896667  0.011547   \n",
       "gpt-4-turbo                                    0.900000  0.011547   \n",
       "Meta-Llama-3-70B-Instruct                      0.873333  0.017321   \n",
       "zephyr-orpo-141b-A35b-v0.1                     0.860000  0.040415   \n",
       "Meta-Llama-3-8B-Instruct                       0.903333  0.005774   \n",
       "Mistral-7B-Instruct-v0.2                       0.886667  0.017321   \n",
       "qwen1_5-110b-chat                              0.893333  0.017321   \n",
       "qwen1_5-14b-chat-q8_0                          0.863333  0.005774   \n",
       "qwen1_5-32b-chat-q8_0                          0.896667  0.005774   \n",
       "zephyr-7b-beta                                 0.866667  0.046188   \n",
       "c4ai-command-r-plus                            0.880000  0.000000   \n",
       "qwen1_5-7b-chat-q8_0                           0.840000  0.023094   \n",
       "rag-tge_TinyLlama.Q32                          0.693333  0.046188   \n",
       "gemma-1.1-7b-it                                0.726667  0.075056   \n",
       "Phi-3-mini-4k-instruct                         0.780000  0.023094   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                  0.616667  0.057735   \n",
       "gemma-1.1-2b-it                                0.670000  0.040415   \n",
       "Mistral-7B-Instruct-v0.1                       0.826667  0.017321   \n",
       "\n",
       "                              correctness/citations_recall            \\\n",
       "                                                      mean       std   \n",
       "llm                                                                    \n",
       "rag-tge_Llama-3-8B_v1                             0.988333  0.008660   \n",
       "rag-tge_Mistral_v2-4480                           0.971667  0.025981   \n",
       "rag-tge_Mistral_v2-3360                           0.968333  0.025981   \n",
       "rag-tge_Mistral.Q8                                0.915000  0.023094   \n",
       "gpt-3.5-turbo-0125                                0.853333  0.023094   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.825000  0.034641   \n",
       "gpt-4-turbo                                       0.795000  0.028868   \n",
       "Meta-Llama-3-70B-Instruct                         0.785000  0.017321   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.775000  0.092376   \n",
       "Meta-Llama-3-8B-Instruct                          0.753333  0.023094   \n",
       "Mistral-7B-Instruct-v0.2                          0.751667  0.025981   \n",
       "qwen1_5-110b-chat                                 0.735000  0.051962   \n",
       "qwen1_5-14b-chat-q8_0                             0.660000  0.030981   \n",
       "qwen1_5-32b-chat-q8_0                             0.655000  0.008660   \n",
       "zephyr-7b-beta                                    0.626667  0.080056   \n",
       "c4ai-command-r-plus                               0.578333  0.043868   \n",
       "qwen1_5-7b-chat-q8_0                              0.548333  0.074282   \n",
       "rag-tge_TinyLlama.Q32                             0.525000  0.051962   \n",
       "gemma-1.1-7b-it                                   0.471667  0.080829   \n",
       "Phi-3-mini-4k-instruct                            0.451667  0.051188   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                     0.051667  0.002887   \n",
       "gemma-1.1-2b-it                                   0.033333  0.005774   \n",
       "Mistral-7B-Instruct-v0.1                          0.010000  0.000000   \n",
       "\n",
       "                              correctness/citations_precision            \\\n",
       "                                                         mean       std   \n",
       "llm                                                                       \n",
       "rag-tge_Llama-3-8B_v1                                0.775833  0.098810   \n",
       "rag-tge_Mistral_v2-4480                              0.876556  0.070338   \n",
       "rag-tge_Mistral_v2-3360                              0.842111  0.084337   \n",
       "rag-tge_Mistral.Q8                                   0.907413  0.040843   \n",
       "gpt-3.5-turbo-0125                                   0.941667  0.023671   \n",
       "Mixtral-8x7B-Instruct-v0.1                           0.875556  0.037528   \n",
       "gpt-4-turbo                                          0.938778  0.010585   \n",
       "Meta-Llama-3-70B-Instruct                            0.907556  0.009623   \n",
       "zephyr-orpo-141b-A35b-v0.1                           0.545670  0.108477   \n",
       "Meta-Llama-3-8B-Instruct                             0.907556  0.018283   \n",
       "Mistral-7B-Instruct-v0.2                             0.721619  0.050125   \n",
       "qwen1_5-110b-chat                                    0.929889  0.023286   \n",
       "qwen1_5-14b-chat-q8_0                                0.920000  0.016358   \n",
       "qwen1_5-32b-chat-q8_0                                0.961667  0.000000   \n",
       "zephyr-7b-beta                                       0.727884  0.088494   \n",
       "c4ai-command-r-plus                                  0.644302  0.054568   \n",
       "qwen1_5-7b-chat-q8_0                                 0.800444  0.078327   \n",
       "rag-tge_TinyLlama.Q32                                0.608111  0.068060   \n",
       "gemma-1.1-7b-it                                      0.660222  0.101471   \n",
       "Phi-3-mini-4k-instruct                               0.457889  0.064275   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                        0.036111  0.006736   \n",
       "gemma-1.1-2b-it                                      0.042778  0.006736   \n",
       "Mistral-7B-Instruct-v0.1                             0.006667  0.000000   \n",
       "\n",
       "                              quality/answer_relevance            \n",
       "                                                  mean       std  \n",
       "llm                                                               \n",
       "rag-tge_Llama-3-8B_v1                         0.735427  0.071202  \n",
       "rag-tge_Mistral_v2-4480                       0.729280  0.055383  \n",
       "rag-tge_Mistral_v2-3360                       0.725706  0.063220  \n",
       "rag-tge_Mistral.Q8                            0.742347  0.040067  \n",
       "gpt-3.5-turbo-0125                            0.751901  0.041098  \n",
       "Mixtral-8x7B-Instruct-v0.1                    0.726039  0.030875  \n",
       "gpt-4-turbo                                   0.747313  0.033935  \n",
       "Meta-Llama-3-70B-Instruct                     0.752517  0.027829  \n",
       "zephyr-orpo-141b-A35b-v0.1                    0.696486  0.059428  \n",
       "Meta-Llama-3-8B-Instruct                      0.720451  0.031690  \n",
       "Mistral-7B-Instruct-v0.2                      0.720431  0.028340  \n",
       "qwen1_5-110b-chat                             0.737396  0.055224  \n",
       "qwen1_5-14b-chat-q8_0                         0.719488  0.038641  \n",
       "qwen1_5-32b-chat-q8_0                         0.710307  0.026912  \n",
       "zephyr-7b-beta                                0.715053  0.041852  \n",
       "c4ai-command-r-plus                           0.635162  0.046987  \n",
       "qwen1_5-7b-chat-q8_0                          0.767839  0.034364  \n",
       "rag-tge_TinyLlama.Q32                         0.614176  0.045262  \n",
       "gemma-1.1-7b-it                               0.738827  0.043209  \n",
       "Phi-3-mini-4k-instruct                        0.663574  0.037250  \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                 0.564932  0.044756  \n",
       "gemma-1.1-2b-it                               0.708830  0.019533  \n",
       "Mistral-7B-Instruct-v0.1                      0.737850  0.027130  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/citations_precision"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.873725</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710307</td>\n",
       "      <td>0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.737556</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.877302</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.938778</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.747313</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.528167</td>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.867315</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.929889</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.737396</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.719488</td>\n",
       "      <td>0.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.865923</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.752517</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.492702</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.951210</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.720451</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.812135</td>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.957667</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.860838</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907413</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.742347</td>\n",
       "      <td>0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.733170</td>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.954283</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.915308</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.876556</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.729280</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.928603</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.909923</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.726039</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.682667</td>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.957922</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.936128</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.842111</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.725706</td>\n",
       "      <td>0.063220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.233444</td>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.864821</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.800444</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.767839</td>\n",
       "      <td>0.034364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.640377</td>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.953748</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.988333</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.735427</td>\n",
       "      <td>0.071202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.406690</td>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.910524</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.853718</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.727884</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.715053</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.871517</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.872812</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.721619</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.367889</td>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.722513</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.471667</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.660222</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.738827</td>\n",
       "      <td>0.043209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.409167</td>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.735956</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578333</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.644302</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.635162</td>\n",
       "      <td>0.046987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_TinyLlama.Q32</th>\n",
       "      <td>0.405833</td>\n",
       "      <td>0.121770</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>0.039015</td>\n",
       "      <td>0.677537</td>\n",
       "      <td>0.049460</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.608111</td>\n",
       "      <td>0.068060</td>\n",
       "      <td>0.614176</td>\n",
       "      <td>0.045262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.417516</td>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.796321</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.807244</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.545670</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.696486</td>\n",
       "      <td>0.059428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.252796</td>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.711068</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.457889</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.663574</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.046111</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.630654</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.708830</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinyllama-1.1b-chat-v1.0.Q8_0</th>\n",
       "      <td>0.041361</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>0.566297</td>\n",
       "      <td>0.028318</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.564932</td>\n",
       "      <td>0.044756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790410</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737850</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              citations/ais_recall            \\\n",
       "                                              mean       std   \n",
       "llm                                                            \n",
       "qwen1_5-32b-chat-q8_0                     0.512222  0.031856   \n",
       "gpt-3.5-turbo-0125                        0.737556  0.072604   \n",
       "gpt-4-turbo                               0.733013  0.045401   \n",
       "qwen1_5-110b-chat                         0.528167  0.095486   \n",
       "qwen1_5-14b-chat-q8_0                     0.633333  0.042339   \n",
       "Meta-Llama-3-70B-Instruct                 0.691944  0.049556   \n",
       "Meta-Llama-3-8B-Instruct                  0.492702  0.060547   \n",
       "rag-tge_Mistral.Q8                        0.812135  0.060520   \n",
       "rag-tge_Mistral_v2-4480                   0.733170  0.134646   \n",
       "Mixtral-8x7B-Instruct-v0.1                0.653500  0.061199   \n",
       "rag-tge_Mistral_v2-3360                   0.682667  0.146211   \n",
       "qwen1_5-7b-chat-q8_0                      0.233444  0.063671   \n",
       "rag-tge_Llama-3-8B_v1                     0.640377  0.100349   \n",
       "zephyr-7b-beta                            0.406690  0.090558   \n",
       "Mistral-7B-Instruct-v0.2                  0.575644  0.036560   \n",
       "gemma-1.1-7b-it                           0.367889  0.122999   \n",
       "c4ai-command-r-plus                       0.409167  0.060382   \n",
       "rag-tge_TinyLlama.Q32                     0.405833  0.121770   \n",
       "zephyr-orpo-141b-A35b-v0.1                0.417516  0.134222   \n",
       "Phi-3-mini-4k-instruct                    0.252796  0.030503   \n",
       "gemma-1.1-2b-it                           0.006667  0.005774   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0             0.041361  0.010585   \n",
       "Mistral-7B-Instruct-v0.1                  0.005000  0.000000   \n",
       "\n",
       "                              citations/ais_precision            \\\n",
       "                                                 mean       std   \n",
       "llm                                                               \n",
       "qwen1_5-32b-chat-q8_0                        0.993333  0.002887   \n",
       "gpt-3.5-turbo-0125                           0.995833  0.002887   \n",
       "gpt-4-turbo                                  0.985000  0.005774   \n",
       "qwen1_5-110b-chat                            0.976111  0.026943   \n",
       "qwen1_5-14b-chat-q8_0                        0.975000  0.008660   \n",
       "Meta-Llama-3-70B-Instruct                    0.955556  0.017802   \n",
       "Meta-Llama-3-8B-Instruct                     0.951210  0.022033   \n",
       "rag-tge_Mistral.Q8                           0.957667  0.021027   \n",
       "rag-tge_Mistral_v2-4480                      0.954283  0.031338   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.928603  0.029692   \n",
       "rag-tge_Mistral_v2-3360                      0.957922  0.032981   \n",
       "qwen1_5-7b-chat-q8_0                         0.862000  0.057158   \n",
       "rag-tge_Llama-3-8B_v1                        0.953748  0.030020   \n",
       "zephyr-7b-beta                               0.910524  0.068665   \n",
       "Mistral-7B-Instruct-v0.2                     0.871517  0.038350   \n",
       "gemma-1.1-7b-it                              0.766667  0.082995   \n",
       "c4ai-command-r-plus                          0.714694  0.061399   \n",
       "rag-tge_TinyLlama.Q32                        0.749778  0.039015   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.796321  0.101052   \n",
       "Phi-3-mini-4k-instruct                       0.578455  0.069580   \n",
       "gemma-1.1-2b-it                              0.046111  0.009623   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                0.125000  0.031754   \n",
       "Mistral-7B-Instruct-v0.1                     0.010000  0.000000   \n",
       "\n",
       "                              correctness/answer_overlap            \\\n",
       "                                                    mean       std   \n",
       "llm                                                                  \n",
       "qwen1_5-32b-chat-q8_0                           0.873725  0.005774   \n",
       "gpt-3.5-turbo-0125                              0.884244  0.012990   \n",
       "gpt-4-turbo                                     0.877302  0.007661   \n",
       "qwen1_5-110b-chat                               0.867315  0.020207   \n",
       "qwen1_5-14b-chat-q8_0                           0.876344  0.006598   \n",
       "Meta-Llama-3-70B-Instruct                       0.865923  0.020651   \n",
       "Meta-Llama-3-8B-Instruct                        0.917846  0.000000   \n",
       "rag-tge_Mistral.Q8                              0.860838  0.012892   \n",
       "rag-tge_Mistral_v2-4480                         0.915308  0.017918   \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.909923  0.001443   \n",
       "rag-tge_Mistral_v2-3360                         0.936128  0.030777   \n",
       "qwen1_5-7b-chat-q8_0                            0.864821  0.024118   \n",
       "rag-tge_Llama-3-8B_v1                           0.944436  0.013723   \n",
       "zephyr-7b-beta                                  0.853718  0.028674   \n",
       "Mistral-7B-Instruct-v0.2                        0.872812  0.014915   \n",
       "gemma-1.1-7b-it                                 0.722513  0.075822   \n",
       "c4ai-command-r-plus                             0.735956  0.023094   \n",
       "rag-tge_TinyLlama.Q32                           0.677537  0.049460   \n",
       "zephyr-orpo-141b-A35b-v0.1                      0.807244  0.060333   \n",
       "Phi-3-mini-4k-instruct                          0.711068  0.012317   \n",
       "gemma-1.1-2b-it                                 0.630654  0.038105   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                   0.566297  0.028318   \n",
       "Mistral-7B-Instruct-v0.1                        0.790410  0.014434   \n",
       "\n",
       "                              correctness/answer_entail            \\\n",
       "                                                   mean       std   \n",
       "llm                                                                 \n",
       "qwen1_5-32b-chat-q8_0                          0.896667  0.005774   \n",
       "gpt-3.5-turbo-0125                             0.910000  0.011547   \n",
       "gpt-4-turbo                                    0.900000  0.011547   \n",
       "qwen1_5-110b-chat                              0.893333  0.017321   \n",
       "qwen1_5-14b-chat-q8_0                          0.863333  0.005774   \n",
       "Meta-Llama-3-70B-Instruct                      0.873333  0.017321   \n",
       "Meta-Llama-3-8B-Instruct                       0.903333  0.005774   \n",
       "rag-tge_Mistral.Q8                             0.866667  0.005774   \n",
       "rag-tge_Mistral_v2-4480                        0.896667  0.023094   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.896667  0.011547   \n",
       "rag-tge_Mistral_v2-3360                        0.910000  0.011547   \n",
       "qwen1_5-7b-chat-q8_0                           0.840000  0.023094   \n",
       "rag-tge_Llama-3-8B_v1                          0.923333  0.023094   \n",
       "zephyr-7b-beta                                 0.866667  0.046188   \n",
       "Mistral-7B-Instruct-v0.2                       0.886667  0.017321   \n",
       "gemma-1.1-7b-it                                0.726667  0.075056   \n",
       "c4ai-command-r-plus                            0.880000  0.000000   \n",
       "rag-tge_TinyLlama.Q32                          0.693333  0.046188   \n",
       "zephyr-orpo-141b-A35b-v0.1                     0.860000  0.040415   \n",
       "Phi-3-mini-4k-instruct                         0.780000  0.023094   \n",
       "gemma-1.1-2b-it                                0.670000  0.040415   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                  0.616667  0.057735   \n",
       "Mistral-7B-Instruct-v0.1                       0.826667  0.017321   \n",
       "\n",
       "                              correctness/citations_recall            \\\n",
       "                                                      mean       std   \n",
       "llm                                                                    \n",
       "qwen1_5-32b-chat-q8_0                             0.655000  0.008660   \n",
       "gpt-3.5-turbo-0125                                0.853333  0.023094   \n",
       "gpt-4-turbo                                       0.795000  0.028868   \n",
       "qwen1_5-110b-chat                                 0.735000  0.051962   \n",
       "qwen1_5-14b-chat-q8_0                             0.660000  0.030981   \n",
       "Meta-Llama-3-70B-Instruct                         0.785000  0.017321   \n",
       "Meta-Llama-3-8B-Instruct                          0.753333  0.023094   \n",
       "rag-tge_Mistral.Q8                                0.915000  0.023094   \n",
       "rag-tge_Mistral_v2-4480                           0.971667  0.025981   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.825000  0.034641   \n",
       "rag-tge_Mistral_v2-3360                           0.968333  0.025981   \n",
       "qwen1_5-7b-chat-q8_0                              0.548333  0.074282   \n",
       "rag-tge_Llama-3-8B_v1                             0.988333  0.008660   \n",
       "zephyr-7b-beta                                    0.626667  0.080056   \n",
       "Mistral-7B-Instruct-v0.2                          0.751667  0.025981   \n",
       "gemma-1.1-7b-it                                   0.471667  0.080829   \n",
       "c4ai-command-r-plus                               0.578333  0.043868   \n",
       "rag-tge_TinyLlama.Q32                             0.525000  0.051962   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.775000  0.092376   \n",
       "Phi-3-mini-4k-instruct                            0.451667  0.051188   \n",
       "gemma-1.1-2b-it                                   0.033333  0.005774   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                     0.051667  0.002887   \n",
       "Mistral-7B-Instruct-v0.1                          0.010000  0.000000   \n",
       "\n",
       "                              correctness/citations_precision            \\\n",
       "                                                         mean       std   \n",
       "llm                                                                       \n",
       "qwen1_5-32b-chat-q8_0                                0.961667  0.000000   \n",
       "gpt-3.5-turbo-0125                                   0.941667  0.023671   \n",
       "gpt-4-turbo                                          0.938778  0.010585   \n",
       "qwen1_5-110b-chat                                    0.929889  0.023286   \n",
       "qwen1_5-14b-chat-q8_0                                0.920000  0.016358   \n",
       "Meta-Llama-3-70B-Instruct                            0.907556  0.009623   \n",
       "Meta-Llama-3-8B-Instruct                             0.907556  0.018283   \n",
       "rag-tge_Mistral.Q8                                   0.907413  0.040843   \n",
       "rag-tge_Mistral_v2-4480                              0.876556  0.070338   \n",
       "Mixtral-8x7B-Instruct-v0.1                           0.875556  0.037528   \n",
       "rag-tge_Mistral_v2-3360                              0.842111  0.084337   \n",
       "qwen1_5-7b-chat-q8_0                                 0.800444  0.078327   \n",
       "rag-tge_Llama-3-8B_v1                                0.775833  0.098810   \n",
       "zephyr-7b-beta                                       0.727884  0.088494   \n",
       "Mistral-7B-Instruct-v0.2                             0.721619  0.050125   \n",
       "gemma-1.1-7b-it                                      0.660222  0.101471   \n",
       "c4ai-command-r-plus                                  0.644302  0.054568   \n",
       "rag-tge_TinyLlama.Q32                                0.608111  0.068060   \n",
       "zephyr-orpo-141b-A35b-v0.1                           0.545670  0.108477   \n",
       "Phi-3-mini-4k-instruct                               0.457889  0.064275   \n",
       "gemma-1.1-2b-it                                      0.042778  0.006736   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                        0.036111  0.006736   \n",
       "Mistral-7B-Instruct-v0.1                             0.006667  0.000000   \n",
       "\n",
       "                              quality/answer_relevance            \n",
       "                                                  mean       std  \n",
       "llm                                                               \n",
       "qwen1_5-32b-chat-q8_0                         0.710307  0.026912  \n",
       "gpt-3.5-turbo-0125                            0.751901  0.041098  \n",
       "gpt-4-turbo                                   0.747313  0.033935  \n",
       "qwen1_5-110b-chat                             0.737396  0.055224  \n",
       "qwen1_5-14b-chat-q8_0                         0.719488  0.038641  \n",
       "Meta-Llama-3-70B-Instruct                     0.752517  0.027829  \n",
       "Meta-Llama-3-8B-Instruct                      0.720451  0.031690  \n",
       "rag-tge_Mistral.Q8                            0.742347  0.040067  \n",
       "rag-tge_Mistral_v2-4480                       0.729280  0.055383  \n",
       "Mixtral-8x7B-Instruct-v0.1                    0.726039  0.030875  \n",
       "rag-tge_Mistral_v2-3360                       0.725706  0.063220  \n",
       "qwen1_5-7b-chat-q8_0                          0.767839  0.034364  \n",
       "rag-tge_Llama-3-8B_v1                         0.735427  0.071202  \n",
       "zephyr-7b-beta                                0.715053  0.041852  \n",
       "Mistral-7B-Instruct-v0.2                      0.720431  0.028340  \n",
       "gemma-1.1-7b-it                               0.738827  0.043209  \n",
       "c4ai-command-r-plus                           0.635162  0.046987  \n",
       "rag-tge_TinyLlama.Q32                         0.614176  0.045262  \n",
       "zephyr-orpo-141b-A35b-v0.1                    0.696486  0.059428  \n",
       "Phi-3-mini-4k-instruct                        0.663574  0.037250  \n",
       "gemma-1.1-2b-it                               0.708830  0.019533  \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                 0.564932  0.044756  \n",
       "Mistral-7B-Instruct-v0.1                      0.737850  0.027130  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: quality/answer_relevance"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>0.233444</td>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.864821</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.800444</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.767839</td>\n",
       "      <td>0.034364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.865923</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.752517</td>\n",
       "      <td>0.027829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>0.737556</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>0.041098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>0.733013</td>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.877302</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.938778</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.747313</td>\n",
       "      <td>0.033935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <td>0.812135</td>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.957667</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>0.860838</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907413</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.742347</td>\n",
       "      <td>0.040067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>0.367889</td>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.722513</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>0.471667</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.660222</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.738827</td>\n",
       "      <td>0.043209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790410</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737850</td>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>0.528167</td>\n",
       "      <td>0.095486</td>\n",
       "      <td>0.976111</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.867315</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.929889</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.737396</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B_v1</th>\n",
       "      <td>0.640377</td>\n",
       "      <td>0.100349</td>\n",
       "      <td>0.953748</td>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.988333</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.735427</td>\n",
       "      <td>0.071202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-4480</th>\n",
       "      <td>0.733170</td>\n",
       "      <td>0.134646</td>\n",
       "      <td>0.954283</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.915308</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.876556</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.729280</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.928603</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.909923</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.726039</td>\n",
       "      <td>0.030875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral_v2-3360</th>\n",
       "      <td>0.682667</td>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.957922</td>\n",
       "      <td>0.032981</td>\n",
       "      <td>0.936128</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.842111</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.725706</td>\n",
       "      <td>0.063220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>0.492702</td>\n",
       "      <td>0.060547</td>\n",
       "      <td>0.951210</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.917846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.907556</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.720451</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>0.871517</td>\n",
       "      <td>0.038350</td>\n",
       "      <td>0.872812</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.721619</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.720431</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.719488</td>\n",
       "      <td>0.038641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.406690</td>\n",
       "      <td>0.090558</td>\n",
       "      <td>0.910524</td>\n",
       "      <td>0.068665</td>\n",
       "      <td>0.853718</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.727884</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.715053</td>\n",
       "      <td>0.041852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.873725</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710307</td>\n",
       "      <td>0.026912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.046111</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.630654</td>\n",
       "      <td>0.038105</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.708830</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>0.417516</td>\n",
       "      <td>0.134222</td>\n",
       "      <td>0.796321</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.807244</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.545670</td>\n",
       "      <td>0.108477</td>\n",
       "      <td>0.696486</td>\n",
       "      <td>0.059428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.252796</td>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>0.711068</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.457889</td>\n",
       "      <td>0.064275</td>\n",
       "      <td>0.663574</td>\n",
       "      <td>0.037250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>0.409167</td>\n",
       "      <td>0.060382</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.735956</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578333</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>0.644302</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.635162</td>\n",
       "      <td>0.046987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_TinyLlama.Q32</th>\n",
       "      <td>0.405833</td>\n",
       "      <td>0.121770</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>0.039015</td>\n",
       "      <td>0.677537</td>\n",
       "      <td>0.049460</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.608111</td>\n",
       "      <td>0.068060</td>\n",
       "      <td>0.614176</td>\n",
       "      <td>0.045262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinyllama-1.1b-chat-v1.0.Q8_0</th>\n",
       "      <td>0.041361</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>0.566297</td>\n",
       "      <td>0.028318</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.564932</td>\n",
       "      <td>0.044756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              citations/ais_recall            \\\n",
       "                                              mean       std   \n",
       "llm                                                            \n",
       "qwen1_5-7b-chat-q8_0                      0.233444  0.063671   \n",
       "Meta-Llama-3-70B-Instruct                 0.691944  0.049556   \n",
       "gpt-3.5-turbo-0125                        0.737556  0.072604   \n",
       "gpt-4-turbo                               0.733013  0.045401   \n",
       "rag-tge_Mistral.Q8                        0.812135  0.060520   \n",
       "gemma-1.1-7b-it                           0.367889  0.122999   \n",
       "Mistral-7B-Instruct-v0.1                  0.005000  0.000000   \n",
       "qwen1_5-110b-chat                         0.528167  0.095486   \n",
       "rag-tge_Llama-3-8B_v1                     0.640377  0.100349   \n",
       "rag-tge_Mistral_v2-4480                   0.733170  0.134646   \n",
       "Mixtral-8x7B-Instruct-v0.1                0.653500  0.061199   \n",
       "rag-tge_Mistral_v2-3360                   0.682667  0.146211   \n",
       "Meta-Llama-3-8B-Instruct                  0.492702  0.060547   \n",
       "Mistral-7B-Instruct-v0.2                  0.575644  0.036560   \n",
       "qwen1_5-14b-chat-q8_0                     0.633333  0.042339   \n",
       "zephyr-7b-beta                            0.406690  0.090558   \n",
       "qwen1_5-32b-chat-q8_0                     0.512222  0.031856   \n",
       "gemma-1.1-2b-it                           0.006667  0.005774   \n",
       "zephyr-orpo-141b-A35b-v0.1                0.417516  0.134222   \n",
       "Phi-3-mini-4k-instruct                    0.252796  0.030503   \n",
       "c4ai-command-r-plus                       0.409167  0.060382   \n",
       "rag-tge_TinyLlama.Q32                     0.405833  0.121770   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0             0.041361  0.010585   \n",
       "\n",
       "                              citations/ais_precision            \\\n",
       "                                                 mean       std   \n",
       "llm                                                               \n",
       "qwen1_5-7b-chat-q8_0                         0.862000  0.057158   \n",
       "Meta-Llama-3-70B-Instruct                    0.955556  0.017802   \n",
       "gpt-3.5-turbo-0125                           0.995833  0.002887   \n",
       "gpt-4-turbo                                  0.985000  0.005774   \n",
       "rag-tge_Mistral.Q8                           0.957667  0.021027   \n",
       "gemma-1.1-7b-it                              0.766667  0.082995   \n",
       "Mistral-7B-Instruct-v0.1                     0.010000  0.000000   \n",
       "qwen1_5-110b-chat                            0.976111  0.026943   \n",
       "rag-tge_Llama-3-8B_v1                        0.953748  0.030020   \n",
       "rag-tge_Mistral_v2-4480                      0.954283  0.031338   \n",
       "Mixtral-8x7B-Instruct-v0.1                   0.928603  0.029692   \n",
       "rag-tge_Mistral_v2-3360                      0.957922  0.032981   \n",
       "Meta-Llama-3-8B-Instruct                     0.951210  0.022033   \n",
       "Mistral-7B-Instruct-v0.2                     0.871517  0.038350   \n",
       "qwen1_5-14b-chat-q8_0                        0.975000  0.008660   \n",
       "zephyr-7b-beta                               0.910524  0.068665   \n",
       "qwen1_5-32b-chat-q8_0                        0.993333  0.002887   \n",
       "gemma-1.1-2b-it                              0.046111  0.009623   \n",
       "zephyr-orpo-141b-A35b-v0.1                   0.796321  0.101052   \n",
       "Phi-3-mini-4k-instruct                       0.578455  0.069580   \n",
       "c4ai-command-r-plus                          0.714694  0.061399   \n",
       "rag-tge_TinyLlama.Q32                        0.749778  0.039015   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                0.125000  0.031754   \n",
       "\n",
       "                              correctness/answer_overlap            \\\n",
       "                                                    mean       std   \n",
       "llm                                                                  \n",
       "qwen1_5-7b-chat-q8_0                            0.864821  0.024118   \n",
       "Meta-Llama-3-70B-Instruct                       0.865923  0.020651   \n",
       "gpt-3.5-turbo-0125                              0.884244  0.012990   \n",
       "gpt-4-turbo                                     0.877302  0.007661   \n",
       "rag-tge_Mistral.Q8                              0.860838  0.012892   \n",
       "gemma-1.1-7b-it                                 0.722513  0.075822   \n",
       "Mistral-7B-Instruct-v0.1                        0.790410  0.014434   \n",
       "qwen1_5-110b-chat                               0.867315  0.020207   \n",
       "rag-tge_Llama-3-8B_v1                           0.944436  0.013723   \n",
       "rag-tge_Mistral_v2-4480                         0.915308  0.017918   \n",
       "Mixtral-8x7B-Instruct-v0.1                      0.909923  0.001443   \n",
       "rag-tge_Mistral_v2-3360                         0.936128  0.030777   \n",
       "Meta-Llama-3-8B-Instruct                        0.917846  0.000000   \n",
       "Mistral-7B-Instruct-v0.2                        0.872812  0.014915   \n",
       "qwen1_5-14b-chat-q8_0                           0.876344  0.006598   \n",
       "zephyr-7b-beta                                  0.853718  0.028674   \n",
       "qwen1_5-32b-chat-q8_0                           0.873725  0.005774   \n",
       "gemma-1.1-2b-it                                 0.630654  0.038105   \n",
       "zephyr-orpo-141b-A35b-v0.1                      0.807244  0.060333   \n",
       "Phi-3-mini-4k-instruct                          0.711068  0.012317   \n",
       "c4ai-command-r-plus                             0.735956  0.023094   \n",
       "rag-tge_TinyLlama.Q32                           0.677537  0.049460   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                   0.566297  0.028318   \n",
       "\n",
       "                              correctness/answer_entail            \\\n",
       "                                                   mean       std   \n",
       "llm                                                                 \n",
       "qwen1_5-7b-chat-q8_0                           0.840000  0.023094   \n",
       "Meta-Llama-3-70B-Instruct                      0.873333  0.017321   \n",
       "gpt-3.5-turbo-0125                             0.910000  0.011547   \n",
       "gpt-4-turbo                                    0.900000  0.011547   \n",
       "rag-tge_Mistral.Q8                             0.866667  0.005774   \n",
       "gemma-1.1-7b-it                                0.726667  0.075056   \n",
       "Mistral-7B-Instruct-v0.1                       0.826667  0.017321   \n",
       "qwen1_5-110b-chat                              0.893333  0.017321   \n",
       "rag-tge_Llama-3-8B_v1                          0.923333  0.023094   \n",
       "rag-tge_Mistral_v2-4480                        0.896667  0.023094   \n",
       "Mixtral-8x7B-Instruct-v0.1                     0.896667  0.011547   \n",
       "rag-tge_Mistral_v2-3360                        0.910000  0.011547   \n",
       "Meta-Llama-3-8B-Instruct                       0.903333  0.005774   \n",
       "Mistral-7B-Instruct-v0.2                       0.886667  0.017321   \n",
       "qwen1_5-14b-chat-q8_0                          0.863333  0.005774   \n",
       "zephyr-7b-beta                                 0.866667  0.046188   \n",
       "qwen1_5-32b-chat-q8_0                          0.896667  0.005774   \n",
       "gemma-1.1-2b-it                                0.670000  0.040415   \n",
       "zephyr-orpo-141b-A35b-v0.1                     0.860000  0.040415   \n",
       "Phi-3-mini-4k-instruct                         0.780000  0.023094   \n",
       "c4ai-command-r-plus                            0.880000  0.000000   \n",
       "rag-tge_TinyLlama.Q32                          0.693333  0.046188   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                  0.616667  0.057735   \n",
       "\n",
       "                              correctness/citations_recall            \\\n",
       "                                                      mean       std   \n",
       "llm                                                                    \n",
       "qwen1_5-7b-chat-q8_0                              0.548333  0.074282   \n",
       "Meta-Llama-3-70B-Instruct                         0.785000  0.017321   \n",
       "gpt-3.5-turbo-0125                                0.853333  0.023094   \n",
       "gpt-4-turbo                                       0.795000  0.028868   \n",
       "rag-tge_Mistral.Q8                                0.915000  0.023094   \n",
       "gemma-1.1-7b-it                                   0.471667  0.080829   \n",
       "Mistral-7B-Instruct-v0.1                          0.010000  0.000000   \n",
       "qwen1_5-110b-chat                                 0.735000  0.051962   \n",
       "rag-tge_Llama-3-8B_v1                             0.988333  0.008660   \n",
       "rag-tge_Mistral_v2-4480                           0.971667  0.025981   \n",
       "Mixtral-8x7B-Instruct-v0.1                        0.825000  0.034641   \n",
       "rag-tge_Mistral_v2-3360                           0.968333  0.025981   \n",
       "Meta-Llama-3-8B-Instruct                          0.753333  0.023094   \n",
       "Mistral-7B-Instruct-v0.2                          0.751667  0.025981   \n",
       "qwen1_5-14b-chat-q8_0                             0.660000  0.030981   \n",
       "zephyr-7b-beta                                    0.626667  0.080056   \n",
       "qwen1_5-32b-chat-q8_0                             0.655000  0.008660   \n",
       "gemma-1.1-2b-it                                   0.033333  0.005774   \n",
       "zephyr-orpo-141b-A35b-v0.1                        0.775000  0.092376   \n",
       "Phi-3-mini-4k-instruct                            0.451667  0.051188   \n",
       "c4ai-command-r-plus                               0.578333  0.043868   \n",
       "rag-tge_TinyLlama.Q32                             0.525000  0.051962   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                     0.051667  0.002887   \n",
       "\n",
       "                              correctness/citations_precision            \\\n",
       "                                                         mean       std   \n",
       "llm                                                                       \n",
       "qwen1_5-7b-chat-q8_0                                 0.800444  0.078327   \n",
       "Meta-Llama-3-70B-Instruct                            0.907556  0.009623   \n",
       "gpt-3.5-turbo-0125                                   0.941667  0.023671   \n",
       "gpt-4-turbo                                          0.938778  0.010585   \n",
       "rag-tge_Mistral.Q8                                   0.907413  0.040843   \n",
       "gemma-1.1-7b-it                                      0.660222  0.101471   \n",
       "Mistral-7B-Instruct-v0.1                             0.006667  0.000000   \n",
       "qwen1_5-110b-chat                                    0.929889  0.023286   \n",
       "rag-tge_Llama-3-8B_v1                                0.775833  0.098810   \n",
       "rag-tge_Mistral_v2-4480                              0.876556  0.070338   \n",
       "Mixtral-8x7B-Instruct-v0.1                           0.875556  0.037528   \n",
       "rag-tge_Mistral_v2-3360                              0.842111  0.084337   \n",
       "Meta-Llama-3-8B-Instruct                             0.907556  0.018283   \n",
       "Mistral-7B-Instruct-v0.2                             0.721619  0.050125   \n",
       "qwen1_5-14b-chat-q8_0                                0.920000  0.016358   \n",
       "zephyr-7b-beta                                       0.727884  0.088494   \n",
       "qwen1_5-32b-chat-q8_0                                0.961667  0.000000   \n",
       "gemma-1.1-2b-it                                      0.042778  0.006736   \n",
       "zephyr-orpo-141b-A35b-v0.1                           0.545670  0.108477   \n",
       "Phi-3-mini-4k-instruct                               0.457889  0.064275   \n",
       "c4ai-command-r-plus                                  0.644302  0.054568   \n",
       "rag-tge_TinyLlama.Q32                                0.608111  0.068060   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                        0.036111  0.006736   \n",
       "\n",
       "                              quality/answer_relevance            \n",
       "                                                  mean       std  \n",
       "llm                                                               \n",
       "qwen1_5-7b-chat-q8_0                          0.767839  0.034364  \n",
       "Meta-Llama-3-70B-Instruct                     0.752517  0.027829  \n",
       "gpt-3.5-turbo-0125                            0.751901  0.041098  \n",
       "gpt-4-turbo                                   0.747313  0.033935  \n",
       "rag-tge_Mistral.Q8                            0.742347  0.040067  \n",
       "gemma-1.1-7b-it                               0.738827  0.043209  \n",
       "Mistral-7B-Instruct-v0.1                      0.737850  0.027130  \n",
       "qwen1_5-110b-chat                             0.737396  0.055224  \n",
       "rag-tge_Llama-3-8B_v1                         0.735427  0.071202  \n",
       "rag-tge_Mistral_v2-4480                       0.729280  0.055383  \n",
       "Mixtral-8x7B-Instruct-v0.1                    0.726039  0.030875  \n",
       "rag-tge_Mistral_v2-3360                       0.725706  0.063220  \n",
       "Meta-Llama-3-8B-Instruct                      0.720451  0.031690  \n",
       "Mistral-7B-Instruct-v0.2                      0.720431  0.028340  \n",
       "qwen1_5-14b-chat-q8_0                         0.719488  0.038641  \n",
       "zephyr-7b-beta                                0.715053  0.041852  \n",
       "qwen1_5-32b-chat-q8_0                         0.710307  0.026912  \n",
       "gemma-1.1-2b-it                               0.708830  0.019533  \n",
       "zephyr-orpo-141b-A35b-v0.1                    0.696486  0.059428  \n",
       "Phi-3-mini-4k-instruct                        0.663574  0.037250  \n",
       "c4ai-command-r-plus                           0.635162  0.046987  \n",
       "rag-tge_TinyLlama.Q32                         0.614176  0.045262  \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0                 0.564932  0.044756  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_results = show_cleaned_results(eval_display)\n",
    "for sort_by in [\n",
    "    (\"citations/ais_recall\", \"mean\"),\n",
    "    (\"citations/ais_precision\", \"mean\"),\n",
    "    (\"correctness/answer_overlap\", \"mean\"),\n",
    "    (\"correctness/answer_entail\", \"mean\"),\n",
    "    (\"correctness/citations_recall\", \"mean\"),\n",
    "    (\"correctness/citations_precision\", \"mean\"),\n",
    "    (\"quality/answer_relevance\", \"mean\"),\n",
    "]:\n",
    "    display(Markdown(f\"### sorted by: {sort_by[0]}\"))\n",
    "    display(clean_results.sort_values(by=sort_by, ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Training results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_sentences</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_total_citations</th>\n",
       "      <th>citations/n_correct_citations</th>\n",
       "      <th>...</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "      <th>n_questions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>ellm</th>\n",
       "      <th>sim</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.742273</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.958344</td>\n",
       "      <td>0.010844</td>\n",
       "      <td>1.454174</td>\n",
       "      <td>0.063348</td>\n",
       "      <td>1.978738</td>\n",
       "      <td>0.085451</td>\n",
       "      <td>1.879570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.891749</td>\n",
       "      <td>0.010757</td>\n",
       "      <td>0.810243</td>\n",
       "      <td>0.015654</td>\n",
       "      <td>0.910769</td>\n",
       "      <td>0.011854</td>\n",
       "      <td>0.742832</td>\n",
       "      <td>0.024321</td>\n",
       "      <td>17872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.670310</td>\n",
       "      <td>0.063516</td>\n",
       "      <td>0.931789</td>\n",
       "      <td>0.027845</td>\n",
       "      <td>2.077639</td>\n",
       "      <td>0.209854</td>\n",
       "      <td>2.475505</td>\n",
       "      <td>0.274398</td>\n",
       "      <td>2.285696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017245</td>\n",
       "      <td>0.879884</td>\n",
       "      <td>0.020221</td>\n",
       "      <td>0.824611</td>\n",
       "      <td>0.037924</td>\n",
       "      <td>0.845152</td>\n",
       "      <td>0.037920</td>\n",
       "      <td>0.729910</td>\n",
       "      <td>0.034703</td>\n",
       "      <td>7659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1.Q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.623737</td>\n",
       "      <td>0.070232</td>\n",
       "      <td>0.901718</td>\n",
       "      <td>0.034851</td>\n",
       "      <td>2.656944</td>\n",
       "      <td>0.273580</td>\n",
       "      <td>3.031389</td>\n",
       "      <td>0.383894</td>\n",
       "      <td>2.768167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018198</td>\n",
       "      <td>0.877611</td>\n",
       "      <td>0.019919</td>\n",
       "      <td>0.847833</td>\n",
       "      <td>0.036453</td>\n",
       "      <td>0.797328</td>\n",
       "      <td>0.046054</td>\n",
       "      <td>0.724574</td>\n",
       "      <td>0.036725</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.564920</td>\n",
       "      <td>0.117130</td>\n",
       "      <td>0.964120</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>1.936333</td>\n",
       "      <td>0.256917</td>\n",
       "      <td>1.789667</td>\n",
       "      <td>0.213576</td>\n",
       "      <td>1.687333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022317</td>\n",
       "      <td>0.874333</td>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.737167</td>\n",
       "      <td>0.053828</td>\n",
       "      <td>0.909575</td>\n",
       "      <td>0.036772</td>\n",
       "      <td>0.725493</td>\n",
       "      <td>0.043379</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.549691</td>\n",
       "      <td>0.031801</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.006415</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.083395</td>\n",
       "      <td>1.362963</td>\n",
       "      <td>0.044905</td>\n",
       "      <td>1.340741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.022453</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.722650</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.443428</td>\n",
       "      <td>0.127016</td>\n",
       "      <td>0.797227</td>\n",
       "      <td>0.101713</td>\n",
       "      <td>1.991263</td>\n",
       "      <td>0.372804</td>\n",
       "      <td>4.609655</td>\n",
       "      <td>1.252030</td>\n",
       "      <td>3.255570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036494</td>\n",
       "      <td>0.845347</td>\n",
       "      <td>0.034536</td>\n",
       "      <td>0.738204</td>\n",
       "      <td>0.097210</td>\n",
       "      <td>0.562458</td>\n",
       "      <td>0.105757</td>\n",
       "      <td>0.682368</td>\n",
       "      <td>0.063733</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              prompt_id  \\\n",
       "                                                                                                                          \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "\n",
       "                                                                                                              citations/ais_recall  \\\n",
       "                                                                                                                              mean   \n",
       "llm                             temperature nli                     ellm                     sim                                     \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.742273   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.670310   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.623737   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.564920   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.549691   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             0.443428   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.031242   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.063516   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.070232   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.117130   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.031801   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.127016   \n",
       "\n",
       "                                                                                                              citations/ais_precision  \\\n",
       "                                                                                                                                 mean   \n",
       "llm                             temperature nli                     ellm                     sim                                        \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.958344   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.931789   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.901718   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.964120   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.988889   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                0.797227   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.010844   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.027845   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034851   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.030177   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.006415   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.101713   \n",
       "\n",
       "                                                                                                              citations/n_sentences  \\\n",
       "                                                                                                                               mean   \n",
       "llm                             temperature nli                     ellm                     sim                                      \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.454174   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.077639   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              2.656944   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.936333   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.600000   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              1.991263   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.063348   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.209854   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.273580   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.256917   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.083395   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.372804   \n",
       "\n",
       "                                                                                                              citations/n_total_citations  \\\n",
       "                                                                                                                                     mean   \n",
       "llm                             temperature nli                     ellm                     sim                                            \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.978738   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    2.475505   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    3.031389   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.789667   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    1.362963   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    4.609655   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.085451   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.274398   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.383894   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.213576   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.044905   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  1.252030   \n",
       "\n",
       "                                                                                                              citations/n_correct_citations  \\\n",
       "                                                                                                                                       mean   \n",
       "llm                             temperature nli                     ellm                     sim                                              \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.879570   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.285696   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      2.768167   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.687333   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      1.340741   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                      3.255570   \n",
       "\n",
       "                                                                                                               ...  \\\n",
       "                                                                                                               ...   \n",
       "llm                             temperature nli                     ellm                     sim               ...   \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  ...   \n",
       "\n",
       "                                                                                                              correctness/answer_overlap  \\\n",
       "                                                                                                                                     std   \n",
       "llm                             temperature nli                     ellm                     sim                                           \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.010100   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.017245   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.018198   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.022317   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.010200   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.036494   \n",
       "\n",
       "                                                                                                              correctness/answer_entail  \\\n",
       "                                                                                                                                   mean   \n",
       "llm                             temperature nli                     ellm                     sim                                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.891749   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.879884   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.877611   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.874333   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.844444   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                  0.845347   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.010757   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.020221   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.019919   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.025403   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.000000   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034536   \n",
       "\n",
       "                                                                                                              correctness/citations_recall  \\\n",
       "                                                                                                                                      mean   \n",
       "llm                             temperature nli                     ellm                     sim                                             \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.810243   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.824611   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.847833   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.737167   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.633333   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.738204   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.015654   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.037924   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.036453   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.053828   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.022453   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.097210   \n",
       "\n",
       "                                                                                                              correctness/citations_precision  \\\n",
       "                                                                                                                                         mean   \n",
       "llm                             temperature nli                     ellm                     sim                                                \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.910769   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.845152   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.797328   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.909575   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.953704   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                        0.562458   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.011854   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.037920   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.046054   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.036772   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.003208   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.105757   \n",
       "\n",
       "                                                                                                              quality/answer_relevance  \\\n",
       "                                                                                                                                  mean   \n",
       "llm                             temperature nli                     ellm                     sim                                         \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.742832   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.729910   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.724574   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.725493   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.722650   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.682368   \n",
       "\n",
       "                                                                                                                         \\\n",
       "                                                                                                                    std   \n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.024321   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.034703   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.036725   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.043379   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.017761   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2  0.063733   \n",
       "\n",
       "                                                                                                              n_questions  \n",
       "                                                                                                                           \n",
       "llm                             temperature nli                     ellm                     sim                           \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2       17872  \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2        7659  \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2        6000  \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2        1000  \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          90  \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         763  \n",
       "\n",
       "[6 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Training results\"))\n",
    "train_display = remove_index(train_results, \"prompt_id\")\n",
    "train_display"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
