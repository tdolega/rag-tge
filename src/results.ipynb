{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "from common.consts import RESULTS_DIR, EVAL_SIZE\n",
    "from common.utils import filename_to_obj, remove_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_idx</th>\n",
       "      <th>question_id</th>\n",
       "      <th>llm</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>nlg</th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>citations/n_sentences</th>\n",
       "      <th>...</th>\n",
       "      <th>citations/n_overcitations</th>\n",
       "      <th>citations/sentences</th>\n",
       "      <th>citations/supported</th>\n",
       "      <th>citations/citations</th>\n",
       "      <th>citations/correct_citations</th>\n",
       "      <th>citations/out_of_range</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>qwen1_5-32b-chat-q8_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>mistral-7b-instruct-v0.2.Q8_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Malcolm Subban is related to P.K., Subban and...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[[], [4]]</td>\n",
       "      <td>[[], [True]]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.523090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>qwen1_5-32b-chat-q8_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>mistral-7b-instruct-v0.2.Q8_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Malcolm Subban is related to P.K., Subban and...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[[], [4]]</td>\n",
       "      <td>[[], [True]]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.523090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>qwen1_5-32b-chat-q8_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>mistral-7b-instruct-v0.2.Q8_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Malcolm Subban is related to P.K., Subban and...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[[], [4]]</td>\n",
       "      <td>[[], [True]]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.523090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5a761900554299109176e648</td>\n",
       "      <td>qwen1_5-32b-chat-q8_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>mistral-7b-instruct-v0.2.Q8_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Flynn Intel Group is a lobbying group establi...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[[1]]</td>\n",
       "      <td>[[True]]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.619434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5a761900554299109176e648</td>\n",
       "      <td>qwen1_5-32b-chat-q8_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>mistral-7b-instruct-v0.2.Q8_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Flynn Intel Group is a lobbying group establi...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[[1]]</td>\n",
       "      <td>[[True]]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.626151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_idx               question_id                    llm prompt_id  \\\n",
       "0             0  5abab42e55429955dce3eed2  qwen1_5-32b-chat-q8_0         1   \n",
       "1             0  5abab42e55429955dce3eed2  qwen1_5-32b-chat-q8_0         1   \n",
       "2             0  5abab42e55429955dce3eed2  qwen1_5-32b-chat-q8_0         1   \n",
       "3             1  5a761900554299109176e648  qwen1_5-32b-chat-q8_0         1   \n",
       "4             1  5a761900554299109176e648  qwen1_5-32b-chat-q8_0         1   \n",
       "\n",
       "  temperature                      nli                            nlg  \\\n",
       "0         0.1  t5_xxl_true_nli_mixture  mistral-7b-instruct-v0.2.Q8_0   \n",
       "1         0.1  t5_xxl_true_nli_mixture  mistral-7b-instruct-v0.2.Q8_0   \n",
       "2         0.1  t5_xxl_true_nli_mixture  mistral-7b-instruct-v0.2.Q8_0   \n",
       "3         0.1  t5_xxl_true_nli_mixture  mistral-7b-instruct-v0.2.Q8_0   \n",
       "4         0.1  t5_xxl_true_nli_mixture  mistral-7b-instruct-v0.2.Q8_0   \n",
       "\n",
       "   citations/ais_recall  citations/ais_precision  citations/n_sentences  ...  \\\n",
       "0                   0.0                      1.0                      2  ...   \n",
       "1                   0.0                      1.0                      2  ...   \n",
       "2                   0.0                      1.0                      2  ...   \n",
       "3                   0.0                      1.0                      1  ...   \n",
       "4                   0.0                      1.0                      1  ...   \n",
       "\n",
       "   citations/n_overcitations  \\\n",
       "0                          0   \n",
       "1                          0   \n",
       "2                          0   \n",
       "3                          0   \n",
       "4                          0   \n",
       "\n",
       "                                 citations/sentences  citations/supported  \\\n",
       "0  [Malcolm Subban is related to P.K., Subban and...               [0, 0]   \n",
       "1  [Malcolm Subban is related to P.K., Subban and...               [0, 0]   \n",
       "2  [Malcolm Subban is related to P.K., Subban and...               [0, 0]   \n",
       "3  [Flynn Intel Group is a lobbying group establi...                  [0]   \n",
       "4  [Flynn Intel Group is a lobbying group establi...                  [0]   \n",
       "\n",
       "   citations/citations citations/correct_citations citations/out_of_range  \\\n",
       "0            [[], [4]]                [[], [True]]                 [0, 0]   \n",
       "1            [[], [4]]                [[], [True]]                 [0, 0]   \n",
       "2            [[], [4]]                [[], [True]]                 [0, 0]   \n",
       "3                [[1]]                    [[True]]                    [0]   \n",
       "4                [[1]]                    [[True]]                    [0]   \n",
       "\n",
       "  correctness/answer_overlap correctness/answer_entail  \\\n",
       "0                        1.0                       1.0   \n",
       "1                        1.0                       1.0   \n",
       "2                        1.0                       1.0   \n",
       "3                        1.0                       1.0   \n",
       "4                        1.0                       1.0   \n",
       "\n",
       "  correctness/citations_recall  quality/answer_relevance  \n",
       "0                          0.5                  0.523090  \n",
       "1                          0.5                  0.523090  \n",
       "2                          0.5                  0.523090  \n",
       "3                          0.5                  0.619434  \n",
       "4                          0.5                  0.626151  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def results_as_pandas(filename):\n",
    "    path = os.path.join(RESULTS_DIR, filename)\n",
    "    with open(path, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "    data = [json.loads(d) for d in data]\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    params = filename_to_obj(filename)\n",
    "    for k, v in params.items():\n",
    "        data[k] = v\n",
    "\n",
    "    data = data.explode(\"evaluations\")\n",
    "    data = data.rename_axis(\"question_idx\").reset_index()\n",
    "\n",
    "    data = pd.concat([data, data[\"evaluations\"].apply(pd.Series)], axis=1)\n",
    "    evaluation_keys = data[\"evaluations\"].apply(pd.Series).columns\n",
    "    for col in evaluation_keys:\n",
    "        data = pd.concat([data, data[col].apply(pd.Series).add_prefix(f\"{col}/\")], axis=1)\n",
    "        data = data.drop(columns=col)\n",
    "    data = data.drop(columns=[\"evaluations\"])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "files = os.listdir(RESULTS_DIR)\n",
    "params_names = list(filename_to_obj(files[0]).keys())\n",
    "all_results = pd.concat([results_as_pandas(f) for f in files])\n",
    "all_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns: ['citations/citations', 'citations/sentences', 'citations/correct_citations', 'citations/supported', 'citations/out_of_range']\n"
     ]
    }
   ],
   "source": [
    "all_obj_cols = all_results.select_dtypes(include=[\"object\"]).columns\n",
    "drop_obj_cols = list(set(all_obj_cols) - set(params_names))\n",
    "drop_obj_cols.remove(\"question_id\")\n",
    "print(f\"Dropping columns: {drop_obj_cols}\")\n",
    "all_num_results = all_results.drop(columns=drop_obj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_split = all_num_results[all_num_results[\"question_idx\"] < EVAL_SIZE]\n",
    "train_split = all_num_results[all_num_results[\"question_idx\"] >= EVAL_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(split):\n",
    "    split = split.drop(columns=[\"question_idx\"])\n",
    "    results_with_std_for_each_question = split.groupby([*params_names, \"question_id\"]).agg([\"mean\", \"std\"])\n",
    "    results_for_each_model = results_with_std_for_each_question.groupby(params_names)\n",
    "    results = results_for_each_model.mean()\n",
    "    results[\"n_questions\"] = results_for_each_model.size()\n",
    "    return results\n",
    "\n",
    "\n",
    "eval_results = aggregate(eval_split)\n",
    "train_results = aggregate(train_split)\n",
    "\n",
    "if eval_results[\"n_questions\"].nunique() != 1:\n",
    "    print(\"Warning: not all rows in evaluation have the same number of examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Prompts comparison"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_sentences</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_total_citations</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_correct_citations</th>\n",
       "      <th>...</th>\n",
       "      <th>citations/n_overcitations</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "      <th>n_questions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>nlg</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <th>1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>0.549818</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.876011</td>\n",
       "      <td>0.038954</td>\n",
       "      <td>2.853333</td>\n",
       "      <td>0.452654</td>\n",
       "      <td>3.203333</td>\n",
       "      <td>0.641732</td>\n",
       "      <td>2.730000</td>\n",
       "      <td>0.566563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.873581</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.768333</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.537185</td>\n",
       "      <td>0.046166</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>0.488163</td>\n",
       "      <td>0.075649</td>\n",
       "      <td>0.843323</td>\n",
       "      <td>0.054662</td>\n",
       "      <td>3.190000</td>\n",
       "      <td>0.484905</td>\n",
       "      <td>4.113333</td>\n",
       "      <td>0.767421</td>\n",
       "      <td>3.496667</td>\n",
       "      <td>0.727615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.856701</td>\n",
       "      <td>0.013472</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.048301</td>\n",
       "      <td>0.514640</td>\n",
       "      <td>0.054069</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>0.512314</td>\n",
       "      <td>0.055778</td>\n",
       "      <td>0.877921</td>\n",
       "      <td>0.038959</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>0.414779</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>2.463333</td>\n",
       "      <td>0.370637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.847581</td>\n",
       "      <td>0.030792</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.526535</td>\n",
       "      <td>0.046135</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                          citations/ais_recall  \\\n",
       "                                                                                                                          mean   \n",
       "llm                           prompt_id temperature nli                     nlg                                                  \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.549818   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.488163   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.512314   \n",
       "\n",
       "                                                                                                                     \\\n",
       "                                                                                                                std   \n",
       "llm                           prompt_id temperature nli                     nlg                                       \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.056448   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.075649   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.055778   \n",
       "\n",
       "                                                                                                          citations/ais_precision  \\\n",
       "                                                                                                                             mean   \n",
       "llm                           prompt_id temperature nli                     nlg                                                     \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.876011   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.843323   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.877921   \n",
       "\n",
       "                                                                                                                     \\\n",
       "                                                                                                                std   \n",
       "llm                           prompt_id temperature nli                     nlg                                       \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.038954   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.054662   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.038959   \n",
       "\n",
       "                                                                                                          citations/n_sentences  \\\n",
       "                                                                                                                           mean   \n",
       "llm                           prompt_id temperature nli                     nlg                                                   \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              2.853333   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              3.190000   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              2.420000   \n",
       "\n",
       "                                                                                                                     \\\n",
       "                                                                                                                std   \n",
       "llm                           prompt_id temperature nli                     nlg                                       \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.452654   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.484905   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.414779   \n",
       "\n",
       "                                                                                                          citations/n_total_citations  \\\n",
       "                                                                                                                                 mean   \n",
       "llm                           prompt_id temperature nli                     nlg                                                         \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    3.203333   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    4.113333   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    3.133333   \n",
       "\n",
       "                                                                                                                     \\\n",
       "                                                                                                                std   \n",
       "llm                           prompt_id temperature nli                     nlg                                       \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.641732   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.767421   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.549383   \n",
       "\n",
       "                                                                                                          citations/n_correct_citations  \\\n",
       "                                                                                                                                   mean   \n",
       "llm                           prompt_id temperature nli                     nlg                                                           \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      2.730000   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      3.496667   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      2.463333   \n",
       "\n",
       "                                                                                                                     \\\n",
       "                                                                                                                std   \n",
       "llm                           prompt_id temperature nli                     nlg                                       \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.566563   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.727615   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.370637   \n",
       "\n",
       "                                                                                                           ...  \\\n",
       "                                                                                                           ...   \n",
       "llm                           prompt_id temperature nli                     nlg                            ...   \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "\n",
       "                                                                                                          citations/n_overcitations  \\\n",
       "                                                                                                                                std   \n",
       "llm                           prompt_id temperature nli                     nlg                                                       \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.000000   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.005774   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.017321   \n",
       "\n",
       "                                                                                                          correctness/answer_overlap  \\\n",
       "                                                                                                                                mean   \n",
       "llm                           prompt_id temperature nli                     nlg                                                        \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.873581   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.856701   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.847581   \n",
       "\n",
       "                                                                                                                     \\\n",
       "                                                                                                                std   \n",
       "llm                           prompt_id temperature nli                     nlg                                       \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.017802   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.013472   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.030792   \n",
       "\n",
       "                                                                                                          correctness/answer_entail  \\\n",
       "                                                                                                                               mean   \n",
       "llm                           prompt_id temperature nli                     nlg                                                       \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.656667   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.680000   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.566667   \n",
       "\n",
       "                                                                                                                     \\\n",
       "                                                                                                                std   \n",
       "llm                           prompt_id temperature nli                     nlg                                       \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.023094   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.023094   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.080829   \n",
       "\n",
       "                                                                                                          correctness/citations_recall  \\\n",
       "                                                                                                                                  mean   \n",
       "llm                           prompt_id temperature nli                     nlg                                                          \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.768333   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.758333   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.735000   \n",
       "\n",
       "                                                                                                                     \\\n",
       "                                                                                                                std   \n",
       "llm                           prompt_id temperature nli                     nlg                                       \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.040415   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.048301   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.037528   \n",
       "\n",
       "                                                                                                          quality/answer_relevance  \\\n",
       "                                                                                                                              mean   \n",
       "llm                           prompt_id temperature nli                     nlg                                                      \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.537185   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.514640   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.526535   \n",
       "\n",
       "                                                                                                                     \\\n",
       "                                                                                                                std   \n",
       "llm                           prompt_id temperature nli                     nlg                                       \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.046166   \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.054069   \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.046135   \n",
       "\n",
       "                                                                                                          n_questions  \n",
       "                                                                                                                       \n",
       "llm                           prompt_id temperature nli                     nlg                                        \n",
       "mistral-7b-instruct-v0.2.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         100  \n",
       "                              2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         100  \n",
       "                              3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         100  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Prompts comparison\"))\n",
    "eval_results[eval_results.index.get_level_values(\"llm\") == \"mistral-7b-instruct-v0.2.Q8_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Evaluation results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_sentences</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_total_citations</th>\n",
       "      <th>citations/n_correct_citations</th>\n",
       "      <th>...</th>\n",
       "      <th>citations/n_overcitations</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "      <th>n_questions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>nlg</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.729222</td>\n",
       "      <td>0.075490</td>\n",
       "      <td>0.991389</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>0.214022</td>\n",
       "      <td>2.143333</td>\n",
       "      <td>0.207846</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.560276</td>\n",
       "      <td>0.049467</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-13b-chat.Q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.062823</td>\n",
       "      <td>0.027852</td>\n",
       "      <td>0.365528</td>\n",
       "      <td>0.112087</td>\n",
       "      <td>7.236667</td>\n",
       "      <td>1.402854</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.631751</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576931</td>\n",
       "      <td>0.140262</td>\n",
       "      <td>0.303333</td>\n",
       "      <td>0.121244</td>\n",
       "      <td>0.223333</td>\n",
       "      <td>0.082169</td>\n",
       "      <td>0.510357</td>\n",
       "      <td>0.067551</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-7b-chat.Q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.166704</td>\n",
       "      <td>0.068833</td>\n",
       "      <td>0.707119</td>\n",
       "      <td>0.076430</td>\n",
       "      <td>7.646667</td>\n",
       "      <td>1.930327</td>\n",
       "      <td>4.143333</td>\n",
       "      <td>1.329357</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.828647</td>\n",
       "      <td>0.051196</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.538333</td>\n",
       "      <td>0.072169</td>\n",
       "      <td>0.545313</td>\n",
       "      <td>0.062214</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.549818</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.876011</td>\n",
       "      <td>0.038954</td>\n",
       "      <td>2.853333</td>\n",
       "      <td>0.452654</td>\n",
       "      <td>3.203333</td>\n",
       "      <td>0.641732</td>\n",
       "      <td>2.730000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.873581</td>\n",
       "      <td>0.017802</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.768333</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.537185</td>\n",
       "      <td>0.046166</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixtral-8x7b-instruct-v0.1.Q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.603619</td>\n",
       "      <td>0.082348</td>\n",
       "      <td>0.922921</td>\n",
       "      <td>0.050573</td>\n",
       "      <td>2.746667</td>\n",
       "      <td>0.294585</td>\n",
       "      <td>2.896667</td>\n",
       "      <td>0.442236</td>\n",
       "      <td>2.703333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882598</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.046188</td>\n",
       "      <td>0.529603</td>\n",
       "      <td>0.052443</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.628333</td>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.978333</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>1.393333</td>\n",
       "      <td>0.075056</td>\n",
       "      <td>1.593333</td>\n",
       "      <td>0.096603</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.540885</td>\n",
       "      <td>0.039755</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.033299</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.069282</td>\n",
       "      <td>1.406667</td>\n",
       "      <td>0.027321</td>\n",
       "      <td>1.396667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.873725</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.549227</td>\n",
       "      <td>0.028203</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.231778</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.863667</td>\n",
       "      <td>0.060044</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>0.227846</td>\n",
       "      <td>1.303333</td>\n",
       "      <td>0.217846</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.864821</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.545086</td>\n",
       "      <td>0.046009</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral.Q8</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.827056</td>\n",
       "      <td>0.051516</td>\n",
       "      <td>0.964500</td>\n",
       "      <td>0.019295</td>\n",
       "      <td>2.246667</td>\n",
       "      <td>0.261624</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.311359</td>\n",
       "      <td>2.873333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.860838</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.545968</td>\n",
       "      <td>0.039325</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_TinyLlama.Q32</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.402143</td>\n",
       "      <td>0.122389</td>\n",
       "      <td>0.742889</td>\n",
       "      <td>0.045462</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>0.326630</td>\n",
       "      <td>1.856667</td>\n",
       "      <td>0.273440</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.677537</td>\n",
       "      <td>0.049460</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>0.086603</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.051962</td>\n",
       "      <td>0.511939</td>\n",
       "      <td>0.058308</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinyllama-1.1b-chat-v1.0.Q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.038767</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>0.127286</td>\n",
       "      <td>0.032991</td>\n",
       "      <td>2.896667</td>\n",
       "      <td>0.435674</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.127017</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.567131</td>\n",
       "      <td>0.026874</td>\n",
       "      <td>0.276667</td>\n",
       "      <td>0.063509</td>\n",
       "      <td>0.063333</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.522607</td>\n",
       "      <td>0.042034</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  prompt_id  \\\n",
       "                                                                                                              \n",
       "llm                             temperature nli                     nlg                                       \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         1   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         1   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         1   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         1   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         1   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         1   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         1   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         1   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         1   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         1   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         1   \n",
       "\n",
       "                                                                                                  citations/ais_recall  \\\n",
       "                                                                                                                  mean   \n",
       "llm                             temperature nli                     nlg                                                  \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.729222   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.062823   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.166704   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.549818   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.603619   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.628333   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.513889   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.231778   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.827056   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.402143   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.038767   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.075490   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.027852   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.068833   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.056448   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.082348   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.042339   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.033299   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.069444   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.051516   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.122389   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.011996   \n",
       "\n",
       "                                                                                                  citations/ais_precision  \\\n",
       "                                                                                                                     mean   \n",
       "llm                             temperature nli                     nlg                                                     \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.991389   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.365528   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.707119   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.876011   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.922921   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.978333   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.996667   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.863667   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.964500   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.742889   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.127286   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.003849   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.112087   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.076430   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.038954   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.050573   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.011547   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.000000   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.060044   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.019295   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.045462   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.032991   \n",
       "\n",
       "                                                                                                  citations/n_sentences  \\\n",
       "                                                                                                                   mean   \n",
       "llm                             temperature nli                     nlg                                                   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              2.020000   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              7.236667   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              7.646667   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              2.853333   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              2.746667   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              1.393333   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              1.600000   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              2.420000   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              2.246667   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              2.030000   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              2.896667   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.214022   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  1.402854   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  1.930327   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.452654   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.294585   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.075056   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.069282   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.227846   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.261624   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.326630   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.435674   \n",
       "\n",
       "                                                                                                  citations/n_total_citations  \\\n",
       "                                                                                                                         mean   \n",
       "llm                             temperature nli                     nlg                                                         \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    2.143333   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    1.666667   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    4.143333   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    3.203333   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    2.896667   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    1.593333   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    1.406667   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    1.303333   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    3.000000   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    1.856667   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    0.533333   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.207846   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.631751   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  1.329357   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.641732   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.442236   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.096603   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.027321   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.217846   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.311359   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.273440   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.127017   \n",
       "\n",
       "                                                                                                  citations/n_correct_citations  \\\n",
       "                                                                                                                           mean   \n",
       "llm                             temperature nli                     nlg                                                           \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      2.120000   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      1.466667   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      3.616667   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      2.730000   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      2.703333   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      1.533333   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      1.396667   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      1.266667   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      2.873333   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      1.660000   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      0.560000   \n",
       "\n",
       "                                                                                                   ...  \\\n",
       "                                                                                                   ...   \n",
       "llm                             temperature nli                     nlg                            ...   \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "\n",
       "                                                                                                  citations/n_overcitations  \\\n",
       "                                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                                       \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.000000   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.000000   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.000000   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.000000   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.000000   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.000000   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.000000   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.000000   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.005774   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.000000   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.000000   \n",
       "\n",
       "                                                                                                  correctness/answer_overlap  \\\n",
       "                                                                                                                        mean   \n",
       "llm                             temperature nli                     nlg                                                        \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.884244   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.576931   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.828647   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.873581   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.882598   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.876344   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.873725   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.864821   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.860838   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.677537   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.567131   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.012990   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.140262   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.051196   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.017802   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.007698   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.006598   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.005774   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.024118   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.012892   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.049460   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.026874   \n",
       "\n",
       "                                                                                                  correctness/answer_entail  \\\n",
       "                                                                                                                       mean   \n",
       "llm                             temperature nli                     nlg                                                       \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.750000   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.303333   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.650000   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.656667   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.693333   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.583333   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.650000   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.686667   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.720000   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.436667   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.276667   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.040415   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.121244   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.057735   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.023094   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.057735   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.040415   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.000000   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.057735   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.023094   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.086603   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.063509   \n",
       "\n",
       "                                                                                                  correctness/citations_recall  \\\n",
       "                                                                                                                          mean   \n",
       "llm                             temperature nli                     nlg                                                          \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.853333   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.223333   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.538333   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.768333   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.871667   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.660000   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.655000   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.548333   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.915000   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.525000   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.063333   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.023094   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.082169   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.072169   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.040415   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.046188   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.030981   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.008660   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.074282   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.023094   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.051962   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.005774   \n",
       "\n",
       "                                                                                                  quality/answer_relevance  \\\n",
       "                                                                                                                      mean   \n",
       "llm                             temperature nli                     nlg                                                      \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.560276   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.510357   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.545313   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.537185   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.529603   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.540885   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.549227   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.545086   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.545968   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.511939   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.522607   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.049467   \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.067551   \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.062214   \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.046166   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.052443   \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.039755   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.028203   \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.046009   \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.039325   \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.058308   \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.042034   \n",
       "\n",
       "                                                                                                  n_questions  \n",
       "                                                                                                               \n",
       "llm                             temperature nli                     nlg                                        \n",
       "gpt-3.5-turbo-0125              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         100  \n",
       "llama-2-13b-chat.Q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         100  \n",
       "llama-2-7b-chat.Q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         100  \n",
       "mistral-7b-instruct-v0.2.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         100  \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         100  \n",
       "qwen1_5-14b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         100  \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         100  \n",
       "qwen1_5-7b-chat-q8_0            0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         100  \n",
       "rag-tge_Mistral.Q8              0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         100  \n",
       "rag-tge_TinyLlama.Q32           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         100  \n",
       "tinyllama-1.1b-chat-v1.0.Q8_0   0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         100  \n",
       "\n",
       "[11 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Evaluation results\"))\n",
    "eval_display = eval_results[eval_results.index.get_level_values(\"prompt_id\") == \"1\"]\n",
    "eval_display = remove_index(eval_display, \"prompt_id\")\n",
    "eval_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Training results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/ais_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_sentences</th>\n",
       "      <th colspan=\"2\" halign=\"left\">citations/n_total_citations</th>\n",
       "      <th>citations/n_correct_citations</th>\n",
       "      <th>...</th>\n",
       "      <th>citations/n_overcitations</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_overlap</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/answer_entail</th>\n",
       "      <th colspan=\"2\" halign=\"left\">correctness/citations_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality/answer_relevance</th>\n",
       "      <th>n_questions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>nlg</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mixtral-8x7b-instruct-v0.1.Q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.624604</td>\n",
       "      <td>0.084236</td>\n",
       "      <td>0.900825</td>\n",
       "      <td>0.042749</td>\n",
       "      <td>2.652852</td>\n",
       "      <td>0.330967</td>\n",
       "      <td>3.067836</td>\n",
       "      <td>0.476308</td>\n",
       "      <td>2.800035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.876157</td>\n",
       "      <td>0.022135</td>\n",
       "      <td>0.736096</td>\n",
       "      <td>0.055219</td>\n",
       "      <td>0.843650</td>\n",
       "      <td>0.044804</td>\n",
       "      <td>0.565015</td>\n",
       "      <td>0.044626</td>\n",
       "      <td>3764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.549691</td>\n",
       "      <td>0.031801</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.006415</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.083395</td>\n",
       "      <td>1.362963</td>\n",
       "      <td>0.044905</td>\n",
       "      <td>1.340741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.869838</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.692593</td>\n",
       "      <td>0.025660</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.022453</td>\n",
       "      <td>0.602882</td>\n",
       "      <td>0.027104</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  prompt_id  \\\n",
       "                                                                                                              \n",
       "llm                             temperature nli                     nlg                                       \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         1   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         1   \n",
       "\n",
       "                                                                                                  citations/ais_recall  \\\n",
       "                                                                                                                  mean   \n",
       "llm                             temperature nli                     nlg                                                  \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.624604   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0             0.549691   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.084236   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.031801   \n",
       "\n",
       "                                                                                                  citations/ais_precision  \\\n",
       "                                                                                                                     mean   \n",
       "llm                             temperature nli                     nlg                                                     \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.900825   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                0.988889   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.042749   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.006415   \n",
       "\n",
       "                                                                                                  citations/n_sentences  \\\n",
       "                                                                                                                   mean   \n",
       "llm                             temperature nli                     nlg                                                   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              2.652852   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              1.600000   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.330967   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.083395   \n",
       "\n",
       "                                                                                                  citations/n_total_citations  \\\n",
       "                                                                                                                         mean   \n",
       "llm                             temperature nli                     nlg                                                         \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    3.067836   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    1.362963   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.476308   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.044905   \n",
       "\n",
       "                                                                                                  citations/n_correct_citations  \\\n",
       "                                                                                                                           mean   \n",
       "llm                             temperature nli                     nlg                                                           \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      2.800035   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      1.340741   \n",
       "\n",
       "                                                                                                   ...  \\\n",
       "                                                                                                   ...   \n",
       "llm                             temperature nli                     nlg                            ...   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  ...   \n",
       "\n",
       "                                                                                                  citations/n_overcitations  \\\n",
       "                                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                                       \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.000153   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.000000   \n",
       "\n",
       "                                                                                                  correctness/answer_overlap  \\\n",
       "                                                                                                                        mean   \n",
       "llm                             temperature nli                     nlg                                                        \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.876157   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.869838   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.022135   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.010200   \n",
       "\n",
       "                                                                                                  correctness/answer_entail  \\\n",
       "                                                                                                                       mean   \n",
       "llm                             temperature nli                     nlg                                                       \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.736096   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.692593   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.055219   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.025660   \n",
       "\n",
       "                                                                                                  correctness/citations_recall  \\\n",
       "                                                                                                                          mean   \n",
       "llm                             temperature nli                     nlg                                                          \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.843650   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     0.633333   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.044804   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.022453   \n",
       "\n",
       "                                                                                                  quality/answer_relevance  \\\n",
       "                                                                                                                      mean   \n",
       "llm                             temperature nli                     nlg                                                      \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.565015   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.602882   \n",
       "\n",
       "                                                                                                             \\\n",
       "                                                                                                        std   \n",
       "llm                             temperature nli                     nlg                                       \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.044626   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0  0.027104   \n",
       "\n",
       "                                                                                                  n_questions  \n",
       "                                                                                                               \n",
       "llm                             temperature nli                     nlg                                        \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0        3764  \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0          90  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Training results\"))\n",
    "train_display = remove_index(train_results, \"prompt_id\")\n",
    "train_display"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
