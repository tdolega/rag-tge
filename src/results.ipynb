{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from common.utils import RESULTS_DIR, filename_to_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'llm': 'mixtral-8x7b-instruct-v0.1.Q8_0', 'prompt_id': '1', 'temperature': '0.1', 'nli': 't5_xxl_true_nli_mixture', 'nlg': 'mistral-7b-instruct-v0.2.Q8_0'}\n",
      "{'llm': 'mistral-7b-instruct-v0.2.Q8_0', 'prompt_id': '2', 'temperature': '0.1', 'nli': 't5_xxl_true_nli_mixture', 'nlg': 'mistral-7b-instruct-v0.2.Q8_0'}\n",
      "{'llm': 'mistral-7b-instruct-v0.2.Q8_0', 'prompt_id': '1', 'temperature': '0.1', 'nli': 't5_xxl_true_nli_mixture', 'nlg': 'mistral-7b-instruct-v0.2.Q8_0'}\n",
      "{'llm': 'mistral-7b-instruct-v0.2.Q8_0', 'prompt_id': '3', 'temperature': '0.1', 'nli': 't5_xxl_true_nli_mixture', 'nlg': 'mistral-7b-instruct-v0.2.Q8_0'}\n",
      "{'llm': 'gpt-3.5-turbo-0125', 'prompt_id': '1', 'temperature': '0.1', 'nli': 't5_xxl_true_nli_mixture', 'nlg': 'mistral-7b-instruct-v0.2.Q8_0'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_idx</th>\n",
       "      <th>question_id</th>\n",
       "      <th>llm</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>nlg</th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>citations/n_sentences</th>\n",
       "      <th>...</th>\n",
       "      <th>citations/sentences</th>\n",
       "      <th>citations/supported</th>\n",
       "      <th>citations/citations</th>\n",
       "      <th>citations/correct_citations</th>\n",
       "      <th>citations/out_of_range</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1.Q8_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>mistral-7b-instruct-v0.2.Q8_0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>[Malcolm Subban, a Canadian ice hockey goalten...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[[], [], [4], [], [2], [], []]</td>\n",
       "      <td>[[], [], [True], [], [True], [], []]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.403033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1.Q8_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>mistral-7b-instruct-v0.2.Q8_0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>[Malcolm Subban, a Canadian ice hockey goalten...</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[[], [4], [3], [], []]</td>\n",
       "      <td>[[], [True], [True], [], []]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.549066</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1.Q8_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>mistral-7b-instruct-v0.2.Q8_0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[The professional hockey player related to P.K...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[[], [4], [4], [3]]</td>\n",
       "      <td>[[], [True], [True], [True]]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707082</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5a761900554299109176e648</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1.Q8_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>mistral-7b-instruct-v0.2.Q8_0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[The 25th National Security Advisor, Michael F...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[[0, 1]]</td>\n",
       "      <td>[[True, True]]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692493</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5a761900554299109176e648</td>\n",
       "      <td>mixtral-8x7b-instruct-v0.1.Q8_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>mistral-7b-instruct-v0.2.Q8_0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[The 25th National Security Advisor, Michael F...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[[0, 1]]</td>\n",
       "      <td>[[True, True]]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.689531</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_idx               question_id                              llm  \\\n",
       "0             0  5abab42e55429955dce3eed2  mixtral-8x7b-instruct-v0.1.Q8_0   \n",
       "1             0  5abab42e55429955dce3eed2  mixtral-8x7b-instruct-v0.1.Q8_0   \n",
       "2             0  5abab42e55429955dce3eed2  mixtral-8x7b-instruct-v0.1.Q8_0   \n",
       "3             1  5a761900554299109176e648  mixtral-8x7b-instruct-v0.1.Q8_0   \n",
       "4             1  5a761900554299109176e648  mixtral-8x7b-instruct-v0.1.Q8_0   \n",
       "\n",
       "  prompt_id temperature                      nli  \\\n",
       "0         1         0.1  t5_xxl_true_nli_mixture   \n",
       "1         1         0.1  t5_xxl_true_nli_mixture   \n",
       "2         1         0.1  t5_xxl_true_nli_mixture   \n",
       "3         1         0.1  t5_xxl_true_nli_mixture   \n",
       "4         1         0.1  t5_xxl_true_nli_mixture   \n",
       "\n",
       "                             nlg  citations/ais_recall  \\\n",
       "0  mistral-7b-instruct-v0.2.Q8_0              0.142857   \n",
       "1  mistral-7b-instruct-v0.2.Q8_0              0.200000   \n",
       "2  mistral-7b-instruct-v0.2.Q8_0              0.000000   \n",
       "3  mistral-7b-instruct-v0.2.Q8_0              1.000000   \n",
       "4  mistral-7b-instruct-v0.2.Q8_0              1.000000   \n",
       "\n",
       "   citations/ais_precision  citations/n_sentences  ...  \\\n",
       "0                      1.0                      7  ...   \n",
       "1                      1.0                      5  ...   \n",
       "2                      1.0                      4  ...   \n",
       "3                      1.0                      1  ...   \n",
       "4                      1.0                      1  ...   \n",
       "\n",
       "                                 citations/sentences    citations/supported  \\\n",
       "0  [Malcolm Subban, a Canadian ice hockey goalten...  [0, 0, 1, 0, 0, 0, 0]   \n",
       "1  [Malcolm Subban, a Canadian ice hockey goalten...        [0, 1, 0, 0, 0]   \n",
       "2  [The professional hockey player related to P.K...           [0, 0, 0, 0]   \n",
       "3  [The 25th National Security Advisor, Michael F...                    [1]   \n",
       "4  [The 25th National Security Advisor, Michael F...                    [1]   \n",
       "\n",
       "              citations/citations           citations/correct_citations  \\\n",
       "0  [[], [], [4], [], [2], [], []]  [[], [], [True], [], [True], [], []]   \n",
       "1          [[], [4], [3], [], []]          [[], [True], [True], [], []]   \n",
       "2             [[], [4], [4], [3]]          [[], [True], [True], [True]]   \n",
       "3                        [[0, 1]]                        [[True, True]]   \n",
       "4                        [[0, 1]]                        [[True, True]]   \n",
       "\n",
       "  citations/out_of_range correctness/answer_overlap correctness/answer_entail  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0]                        1.0                       0.0   \n",
       "1        [0, 0, 0, 0, 0]                        1.0                       0.0   \n",
       "2           [0, 0, 0, 0]                        1.0                       1.0   \n",
       "3                    [0]                        1.0                       1.0   \n",
       "4                    [0]                        1.0                       1.0   \n",
       "\n",
       "  correctness/citations_recall quality/answer_relevance   id  \n",
       "0                          0.5                 0.403033  NaN  \n",
       "1                          1.0                 0.549066  NaN  \n",
       "2                          1.0                 0.707082  NaN  \n",
       "3                          1.0                 0.692493  NaN  \n",
       "4                          1.0                 0.689531  NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def results_as_pandas(filename):\n",
    "    path = os.path.join(RESULTS_DIR, filename)\n",
    "    with open(path, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "    data = [json.loads(d) for d in data]\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    params = filename_to_obj(filename)\n",
    "    print(params)\n",
    "    for k, v in params.items():\n",
    "        data[k] = v\n",
    "\n",
    "    data = data.explode(\"evaluations\")\n",
    "    data = data.rename_axis(\"question_idx\").reset_index()\n",
    "\n",
    "    data = pd.concat([data, data[\"evaluations\"].apply(pd.Series)], axis=1)\n",
    "    evaluation_keys = data[\"evaluations\"].apply(pd.Series).columns\n",
    "    for col in evaluation_keys:\n",
    "        data = pd.concat([data, data[col].apply(pd.Series).add_prefix(f\"{col}/\")], axis=1)\n",
    "        data = data.drop(columns=col)\n",
    "    data = data.drop(columns=[\"evaluations\"])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "results = os.listdir(RESULTS_DIR)\n",
    "params_names = list(filename_to_obj(results[0]).keys())\n",
    "results = pd.concat([results_as_pandas(r) for r in results])\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.drop(columns=[\"id\"])\n",
    "all_obj_cols = results.select_dtypes(include=[\"object\"]).columns\n",
    "drop_obj_cols = list(set(all_obj_cols) - set(params_names))\n",
    "results = results.drop(columns=drop_obj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: not all rows have the same number of examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>citations/n_sentences</th>\n",
       "      <th>citations/n_total_citations</th>\n",
       "      <th>citations/n_correct_citations</th>\n",
       "      <th>citations/n_correctly_multicited_sentences</th>\n",
       "      <th>citations/n_overcitations</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "      <th>n_examples</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>nlg</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <th>1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>0.729222</td>\n",
       "      <td>0.991389</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>2.143333</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.560276</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <th>1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>0.549818</td>\n",
       "      <td>0.876011</td>\n",
       "      <td>2.853333</td>\n",
       "      <td>3.203333</td>\n",
       "      <td>2.730000</td>\n",
       "      <td>1.146667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.873581</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.768333</td>\n",
       "      <td>0.537185</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>0.488163</td>\n",
       "      <td>0.843323</td>\n",
       "      <td>3.190000</td>\n",
       "      <td>4.113333</td>\n",
       "      <td>3.496667</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.856701</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.514640</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>0.512314</td>\n",
       "      <td>0.877921</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>2.463333</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.847581</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.526535</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixtral-8x7b-instruct-v0.1.Q8_0</th>\n",
       "      <th>1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>mistral-7b-instruct-v0.2.Q8_0</th>\n",
       "      <td>0.637489</td>\n",
       "      <td>0.918824</td>\n",
       "      <td>2.647651</td>\n",
       "      <td>2.991051</td>\n",
       "      <td>2.721477</td>\n",
       "      <td>0.649888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882620</td>\n",
       "      <td>0.748322</td>\n",
       "      <td>0.872483</td>\n",
       "      <td>0.558097</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                             citations/ais_recall  \\\n",
       "llm                             prompt_id temperature nli                     nlg                                                   \n",
       "gpt-3.5-turbo-0125              1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              0.729222   \n",
       "mistral-7b-instruct-v0.2.Q8_0   1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              0.549818   \n",
       "                                2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              0.488163   \n",
       "                                3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              0.512314   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0              0.637489   \n",
       "\n",
       "                                                                                                             citations/ais_precision  \\\n",
       "llm                             prompt_id temperature nli                     nlg                                                      \n",
       "gpt-3.5-turbo-0125              1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.991389   \n",
       "mistral-7b-instruct-v0.2.Q8_0   1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.876011   \n",
       "                                2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.843323   \n",
       "                                3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.877921   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                 0.918824   \n",
       "\n",
       "                                                                                                             citations/n_sentences  \\\n",
       "llm                             prompt_id temperature nli                     nlg                                                    \n",
       "gpt-3.5-turbo-0125              1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0               2.020000   \n",
       "mistral-7b-instruct-v0.2.Q8_0   1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0               2.853333   \n",
       "                                2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0               3.190000   \n",
       "                                3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0               2.420000   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0               2.647651   \n",
       "\n",
       "                                                                                                             citations/n_total_citations  \\\n",
       "llm                             prompt_id temperature nli                     nlg                                                          \n",
       "gpt-3.5-turbo-0125              1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     2.143333   \n",
       "mistral-7b-instruct-v0.2.Q8_0   1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     3.203333   \n",
       "                                2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     4.113333   \n",
       "                                3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     3.133333   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                     2.991051   \n",
       "\n",
       "                                                                                                             citations/n_correct_citations  \\\n",
       "llm                             prompt_id temperature nli                     nlg                                                            \n",
       "gpt-3.5-turbo-0125              1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                       2.120000   \n",
       "mistral-7b-instruct-v0.2.Q8_0   1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                       2.730000   \n",
       "                                2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                       3.496667   \n",
       "                                3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                       2.463333   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                       2.721477   \n",
       "\n",
       "                                                                                                             citations/n_correctly_multicited_sentences  \\\n",
       "llm                             prompt_id temperature nli                     nlg                                                                         \n",
       "gpt-3.5-turbo-0125              1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                                    0.500000   \n",
       "mistral-7b-instruct-v0.2.Q8_0   1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                                    1.146667   \n",
       "                                2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                                    1.080000   \n",
       "                                3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                                    0.753333   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                                    0.649888   \n",
       "\n",
       "                                                                                                             citations/n_overcitations  \\\n",
       "llm                             prompt_id temperature nli                     nlg                                                        \n",
       "gpt-3.5-turbo-0125              1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.000000   \n",
       "mistral-7b-instruct-v0.2.Q8_0   1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.000000   \n",
       "                                2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.006667   \n",
       "                                3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.036667   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.000000   \n",
       "\n",
       "                                                                                                             correctness/answer_overlap  \\\n",
       "llm                             prompt_id temperature nli                     nlg                                                         \n",
       "gpt-3.5-turbo-0125              1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    0.884244   \n",
       "mistral-7b-instruct-v0.2.Q8_0   1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    0.873581   \n",
       "                                2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    0.856701   \n",
       "                                3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    0.847581   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                    0.882620   \n",
       "\n",
       "                                                                                                             correctness/answer_entail  \\\n",
       "llm                             prompt_id temperature nli                     nlg                                                        \n",
       "gpt-3.5-turbo-0125              1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.750000   \n",
       "mistral-7b-instruct-v0.2.Q8_0   1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.656667   \n",
       "                                2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.680000   \n",
       "                                3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.566667   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                   0.748322   \n",
       "\n",
       "                                                                                                             correctness/citations_recall  \\\n",
       "llm                             prompt_id temperature nli                     nlg                                                           \n",
       "gpt-3.5-turbo-0125              1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      0.853333   \n",
       "mistral-7b-instruct-v0.2.Q8_0   1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      0.768333   \n",
       "                                2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      0.758333   \n",
       "                                3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      0.735000   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                      0.872483   \n",
       "\n",
       "                                                                                                             quality/answer_relevance  \\\n",
       "llm                             prompt_id temperature nli                     nlg                                                       \n",
       "gpt-3.5-turbo-0125              1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.560276   \n",
       "mistral-7b-instruct-v0.2.Q8_0   1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.537185   \n",
       "                                2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.514640   \n",
       "                                3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.526535   \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0                  0.558097   \n",
       "\n",
       "                                                                                                             n_examples  \n",
       "llm                             prompt_id temperature nli                     nlg                                        \n",
       "gpt-3.5-turbo-0125              1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         300  \n",
       "mistral-7b-instruct-v0.2.Q8_0   1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         300  \n",
       "                                2         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         300  \n",
       "                                3         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         300  \n",
       "mixtral-8x7b-instruct-v0.1.Q8_0 1         0.1         t5_xxl_true_nli_mixture mistral-7b-instruct-v0.2.Q8_0         894  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = results.groupby(params_names)\n",
    "mean = gb.mean()\n",
    "mean = mean.drop(columns=[\"question_idx\"])\n",
    "mean[\"n_examples\"] = gb.size()\n",
    "if mean[\"n_examples\"].nunique() != 1:\n",
    "    print(\"Warning: not all rows have the same number of examples\")\n",
    "mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
