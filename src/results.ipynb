{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tdolega/miniconda/envs/p311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from common.consts import RESULTS_DIR, EVAL_SIZE\n",
    "from common.utils import filename_to_obj, remove_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:29<00:00,  2.49s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_idx</th>\n",
       "      <th>question_id</th>\n",
       "      <th>llm</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>ellm</th>\n",
       "      <th>sim</th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>citations/supported</th>\n",
       "      <th>citations/citations</th>\n",
       "      <th>citations/correct_citations</th>\n",
       "      <th>citations/out_of_range</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "      <th>quality/new_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[[], [], [5], [], [], [], [4, 7]]</td>\n",
       "      <td>[[], [], [1], [], [], [], [0]]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.542151</td>\n",
       "      <td>In what professional sports leagues do Moala T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "      <td>[[], [], [4], [6]]</td>\n",
       "      <td>[[], [], [0], [1]]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>Who are Jordan Subban and Auston Matthews, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5abab42e55429955dce3eed2</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[[], [], [4], [], [3]]</td>\n",
       "      <td>[[], [], [0], [], [1]]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640139</td>\n",
       "      <td>Who are the hockey-playing brothers, one of wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5a761900554299109176e648</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[[0, 1]]</td>\n",
       "      <td>[[True, True]]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401913</td>\n",
       "      <td>What company is associated with the Flynn inve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5a761900554299109176e648</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>t5_xxl_true_nli_mixture</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[[1]]</td>\n",
       "      <td>[[1]]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420150</td>\n",
       "      <td>What company is associated with the Flynn Inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_idx               question_id                       llm prompt_id  \\\n",
       "0             0  5abab42e55429955dce3eed2  Mistral-7B-Instruct-v0.2         1   \n",
       "1             0  5abab42e55429955dce3eed2  Mistral-7B-Instruct-v0.2         1   \n",
       "2             0  5abab42e55429955dce3eed2  Mistral-7B-Instruct-v0.2         1   \n",
       "3             1  5a761900554299109176e648  Mistral-7B-Instruct-v0.2         1   \n",
       "4             1  5a761900554299109176e648  Mistral-7B-Instruct-v0.2         1   \n",
       "\n",
       "  temperature                      nli                      ellm  \\\n",
       "0         1.0  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "1         1.0  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "2         1.0  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "3         1.0  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "4         1.0  t5_xxl_true_nli_mixture  Mistral-7B-Instruct-v0.2   \n",
       "\n",
       "                sim  citations/ais_recall  citations/ais_precision  ...  \\\n",
       "0  all-MiniLM-L6-v2              0.142857                 0.333333  ...   \n",
       "1  all-MiniLM-L6-v2              0.250000                 0.500000  ...   \n",
       "2  all-MiniLM-L6-v2              0.200000                 0.500000  ...   \n",
       "3  all-MiniLM-L6-v2              1.000000                 1.000000  ...   \n",
       "4  all-MiniLM-L6-v2              1.000000                 1.000000  ...   \n",
       "\n",
       "     citations/supported                citations/citations  \\\n",
       "0  [0, 0, 1, 0, 0, 0, 0]  [[], [], [5], [], [], [], [4, 7]]   \n",
       "1           [0, 0, 0, 1]                 [[], [], [4], [6]]   \n",
       "2        [0, 0, 0, 0, 1]             [[], [], [4], [], [3]]   \n",
       "3                    [1]                           [[0, 1]]   \n",
       "4                    [1]                              [[1]]   \n",
       "\n",
       "      citations/correct_citations  citations/out_of_range  \\\n",
       "0  [[], [], [1], [], [], [], [0]]   [0, 0, 0, 0, 0, 0, 0]   \n",
       "1              [[], [], [0], [1]]            [0, 0, 0, 0]   \n",
       "2          [[], [], [0], [], [1]]         [0, 0, 0, 0, 0]   \n",
       "3                  [[True, True]]                     [0]   \n",
       "4                           [[1]]                     [0]   \n",
       "\n",
       "   correctness/answer_overlap correctness/answer_entail  \\\n",
       "0                         1.0                       0.0   \n",
       "1                         0.5                       0.0   \n",
       "2                         0.5                       0.0   \n",
       "3                         1.0                       1.0   \n",
       "4                         1.0                       1.0   \n",
       "\n",
       "  correctness/citations_recall correctness/citations_precision  \\\n",
       "0                          0.5                        0.333333   \n",
       "1                          0.5                        0.500000   \n",
       "2                          1.0                        1.000000   \n",
       "3                          1.0                        1.000000   \n",
       "4                          0.5                        1.000000   \n",
       "\n",
       "  quality/answer_relevance                               quality/new_question  \n",
       "0                 0.542151  In what professional sports leagues do Moala T...  \n",
       "1                 0.561224  Who are Jordan Subban and Auston Matthews, and...  \n",
       "2                 0.640139  Who are the hockey-playing brothers, one of wh...  \n",
       "3                 0.401913  What company is associated with the Flynn inve...  \n",
       "4                 0.420150  What company is associated with the Flynn Inte...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def results_as_pandas(filename):\n",
    "    path = os.path.join(RESULTS_DIR, filename)\n",
    "    data = pd.read_json(path, lines=True)\n",
    "\n",
    "    if len(data) == 0:\n",
    "        print(f\"empty file: {filename}\")\n",
    "        return data\n",
    "\n",
    "    params = filename_to_obj(filename)\n",
    "    for k, v in params.items():\n",
    "        data[k] = v\n",
    "\n",
    "    data = data.explode(\"evaluations\")\n",
    "    data = data.rename_axis(\"question_idx\").reset_index()\n",
    "\n",
    "    data = pd.concat([data, data[\"evaluations\"].apply(pd.Series)], axis=1)\n",
    "    evaluation_keys = data[\"evaluations\"].apply(pd.Series).columns\n",
    "    for col in evaluation_keys:\n",
    "        data = pd.concat([data, data[col].apply(pd.Series).add_prefix(f\"{col}/\")], axis=1)\n",
    "        data = data.drop(columns=col)\n",
    "    data = data.drop(columns=[\"evaluations\"])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "files = os.listdir(RESULTS_DIR)\n",
    "params_names = list(filename_to_obj(files[0]).keys())\n",
    "all_results = pd.concat([results_as_pandas(f) for f in tqdm(files)])\n",
    "all_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns: ['citations/correct_citations', 'citations/out_of_range', 'citations/sentences', 'citations/citations', 'quality/new_question', 'citations/supported']\n"
     ]
    }
   ],
   "source": [
    "all_obj_cols = all_results.select_dtypes(include=[\"object\"]).columns\n",
    "drop_obj_cols = list(set(all_obj_cols) - set(params_names))\n",
    "drop_obj_cols.remove(\"question_id\")\n",
    "print(f\"Dropping columns: {drop_obj_cols}\")\n",
    "all_num_results = all_results.drop(columns=drop_obj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_split = all_num_results[all_num_results[\"question_idx\"] < EVAL_SIZE]\n",
    "train_split = all_num_results[all_num_results[\"question_idx\"] >= EVAL_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_AGG_FUNC = \"mean\"  # or \"max\"\n",
    "\n",
    "\n",
    "def merge_mean_std(df):\n",
    "    ndf = pd.DataFrame()\n",
    "    for main_column, sub_column in df.columns[::2]:\n",
    "        if sub_column == \"\":\n",
    "            ndf[main_column] = df[main_column]\n",
    "        else:\n",
    "            main = df[main_column][SAMPLES_AGG_FUNC]\n",
    "            std = df[main_column][\"std\"]\n",
    "            if main_column in [\"citations/ais_recall\", \"citations/ais_precision\", \"correctness/answer_overlap\", \"correctness/answer_entail\", \"correctness/citations_recall\", \"correctness/citations_precision\", \"quality/answer_relevance\"]:\n",
    "                main = (main * 100).round(1).astype(str) + \"%\"\n",
    "                std = (std * 100).round(1).astype(str) + \"%\"\n",
    "            else:\n",
    "                main = main.round(1).astype(str)\n",
    "                std = std.round(1).astype(str)\n",
    "            # std = std.str.rjust(5, \" \") # doesn't work for some reason\n",
    "            ndf[main_column] = main + \" ± \" + std\n",
    "    return ndf\n",
    "\n",
    "\n",
    "def aggregate(split):\n",
    "    split = split.drop(columns=[\"question_idx\"])\n",
    "    results_with_std_for_each_question = split.groupby([*params_names, \"question_id\"]).agg([SAMPLES_AGG_FUNC, \"std\"])\n",
    "    results_for_each_model = results_with_std_for_each_question.groupby(params_names)\n",
    "    results = results_for_each_model.mean()\n",
    "    results[\"n_questions\"] = results_for_each_model.size()\n",
    "    results = merge_mean_std(results)\n",
    "    return results\n",
    "\n",
    "\n",
    "eval_results = aggregate(eval_split)\n",
    "train_results = aggregate(train_split)\n",
    "\n",
    "if eval_results[\"n_questions\"].nunique() != 1:\n",
    "    print(\"Warning: not all rows in evaluation have the same number of examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Prompts comparison"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.1% ± 4.1%</td>\n",
       "      <td>69.1% ± 6.2%</td>\n",
       "      <td>87.3% ± 1.5%</td>\n",
       "      <td>88.7% ± 1.7%</td>\n",
       "      <td>75.2% ± 2.6%</td>\n",
       "      <td>72.2% ± 5.0%</td>\n",
       "      <td>71.0% ± 3.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.3% ± 6.7%</td>\n",
       "      <td>64.2% ± 6.4%</td>\n",
       "      <td>85.5% ± 2.8%</td>\n",
       "      <td>86.0% ± 2.3%</td>\n",
       "      <td>77.0% ± 4.3%</td>\n",
       "      <td>67.1% ± 4.7%</td>\n",
       "      <td>69.1% ± 3.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.0% ± 4.5%</td>\n",
       "      <td>72.1% ± 5.7%</td>\n",
       "      <td>85.6% ± 1.7%</td>\n",
       "      <td>86.3% ± 1.2%</td>\n",
       "      <td>66.5% ± 3.5%</td>\n",
       "      <td>65.8% ± 4.2%</td>\n",
       "      <td>65.6% ± 2.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.7% ± 5.1%</td>\n",
       "      <td>65.7% ± 6.9%</td>\n",
       "      <td>84.3% ± 2.4%</td>\n",
       "      <td>83.7% ± 1.2%</td>\n",
       "      <td>60.2% ± 3.2%</td>\n",
       "      <td>69.0% ± 3.6%</td>\n",
       "      <td>67.1% ± 3.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          citations/ais_recall citations/ais_precision  \\\n",
       "prompt_id                                                \n",
       "1                 57.1% ± 4.1%            69.1% ± 6.2%   \n",
       "2                 50.3% ± 6.7%            64.2% ± 6.4%   \n",
       "3                 58.0% ± 4.5%            72.1% ± 5.7%   \n",
       "4                 50.7% ± 5.1%            65.7% ± 6.9%   \n",
       "\n",
       "          correctness/answer_overlap correctness/answer_entail  \\\n",
       "prompt_id                                                        \n",
       "1                       87.3% ± 1.5%              88.7% ± 1.7%   \n",
       "2                       85.5% ± 2.8%              86.0% ± 2.3%   \n",
       "3                       85.6% ± 1.7%              86.3% ± 1.2%   \n",
       "4                       84.3% ± 2.4%              83.7% ± 1.2%   \n",
       "\n",
       "          correctness/citations_recall correctness/citations_precision  \\\n",
       "prompt_id                                                                \n",
       "1                         75.2% ± 2.6%                    72.2% ± 5.0%   \n",
       "2                         77.0% ± 4.3%                    67.1% ± 4.7%   \n",
       "3                         66.5% ± 3.5%                    65.8% ± 4.2%   \n",
       "4                         60.2% ± 3.2%                    69.0% ± 3.6%   \n",
       "\n",
       "          quality/answer_relevance  \n",
       "prompt_id                           \n",
       "1                     71.0% ± 3.9%  \n",
       "2                     69.1% ± 3.7%  \n",
       "3                     65.6% ± 2.7%  \n",
       "4                     67.1% ± 3.0%  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Prompts comparison\"))\n",
    "parameter_results = eval_results[eval_results.index.get_level_values(\"llm\") == \"Mistral-7B-Instruct-v0.2\"]\n",
    "\n",
    "RESULTS_COLUMNS = [\"citations/ais_recall\", \"citations/ais_precision\", \"correctness/answer_overlap\", \"correctness/answer_entail\", \"correctness/citations_recall\", \"correctness/citations_precision\", \"quality/answer_relevance\"]\n",
    "\n",
    "\n",
    "def show_cleaned_results(short_eval_display, keep_index_name=None, keep_columns=RESULTS_COLUMNS):\n",
    "    short_eval_display = short_eval_display.copy()\n",
    "    for index_name in [\"llm\", \"temperature\", \"nli\", \"ellm\", \"sim\", \"prompt_id\"]:\n",
    "        if keep_index_name == True or index_name == keep_index_name or index_name not in short_eval_display.index.names:\n",
    "            continue\n",
    "        short_eval_display = remove_index(short_eval_display, index_name)\n",
    "    short_eval_display = short_eval_display[keep_columns]\n",
    "    return short_eval_display\n",
    "\n",
    "\n",
    "prompts_comparison = show_cleaned_results(parameter_results[parameter_results.index.get_level_values(\"temperature\") == \"0.1\"], keep_index_name=\"prompt_id\")\n",
    "prompts_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Temperature comparison"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>57.6% ± 2.7%</td>\n",
       "      <td>70.1% ± 3.6%</td>\n",
       "      <td>85.9% ± 1.3%</td>\n",
       "      <td>88.3% ± 1.7%</td>\n",
       "      <td>75.8% ± 1.4%</td>\n",
       "      <td>74.4% ± 2.3%</td>\n",
       "      <td>72.6% ± 2.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>57.1% ± 4.1%</td>\n",
       "      <td>69.1% ± 6.2%</td>\n",
       "      <td>87.3% ± 1.5%</td>\n",
       "      <td>88.7% ± 1.7%</td>\n",
       "      <td>75.2% ± 2.6%</td>\n",
       "      <td>72.2% ± 5.0%</td>\n",
       "      <td>71.0% ± 3.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>55.3% ± 8.3%</td>\n",
       "      <td>69.2% ± 10.4%</td>\n",
       "      <td>86.5% ± 3.0%</td>\n",
       "      <td>88.7% ± 0.6%</td>\n",
       "      <td>77.0% ± 5.2%</td>\n",
       "      <td>74.2% ± 5.1%</td>\n",
       "      <td>71.6% ± 4.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>57.1% ± 8.3%</td>\n",
       "      <td>69.6% ± 11.3%</td>\n",
       "      <td>87.3% ± 4.6%</td>\n",
       "      <td>88.3% ± 2.3%</td>\n",
       "      <td>77.7% ± 6.0%</td>\n",
       "      <td>75.0% ± 6.7%</td>\n",
       "      <td>71.4% ± 5.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>58.1% ± 15.1%</td>\n",
       "      <td>70.7% ± 19.4%</td>\n",
       "      <td>87.2% ± 4.5%</td>\n",
       "      <td>88.7% ± 2.9%</td>\n",
       "      <td>77.5% ± 9.7%</td>\n",
       "      <td>73.8% ± 10.0%</td>\n",
       "      <td>71.6% ± 6.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>57.4% ± 14.5%</td>\n",
       "      <td>71.1% ± 16.9%</td>\n",
       "      <td>85.3% ± 7.4%</td>\n",
       "      <td>88.0% ± 3.5%</td>\n",
       "      <td>76.2% ± 8.2%</td>\n",
       "      <td>73.7% ± 11.4%</td>\n",
       "      <td>71.3% ± 6.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>52.2% ± 16.7%</td>\n",
       "      <td>65.5% ± 21.6%</td>\n",
       "      <td>84.5% ± 4.9%</td>\n",
       "      <td>87.0% ± 4.0%</td>\n",
       "      <td>75.8% ± 12.2%</td>\n",
       "      <td>73.9% ± 12.6%</td>\n",
       "      <td>71.7% ± 7.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>54.8% ± 19.1%</td>\n",
       "      <td>66.5% ± 24.1%</td>\n",
       "      <td>87.1% ± 4.7%</td>\n",
       "      <td>87.3% ± 2.9%</td>\n",
       "      <td>77.0% ± 11.9%</td>\n",
       "      <td>73.6% ± 13.2%</td>\n",
       "      <td>72.3% ± 6.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>50.7% ± 19.6%</td>\n",
       "      <td>62.8% ± 23.6%</td>\n",
       "      <td>86.7% ± 6.3%</td>\n",
       "      <td>86.0% ± 8.7%</td>\n",
       "      <td>75.2% ± 12.0%</td>\n",
       "      <td>72.0% ± 12.4%</td>\n",
       "      <td>71.1% ± 7.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>57.3% ± 20.5%</td>\n",
       "      <td>71.3% ± 22.7%</td>\n",
       "      <td>82.9% ± 7.4%</td>\n",
       "      <td>85.7% ± 5.8%</td>\n",
       "      <td>75.2% ± 14.9%</td>\n",
       "      <td>73.2% ± 15.2%</td>\n",
       "      <td>68.7% ± 8.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>55.5% ± 20.7%</td>\n",
       "      <td>68.9% ± 24.0%</td>\n",
       "      <td>82.5% ± 6.7%</td>\n",
       "      <td>83.7% ± 6.4%</td>\n",
       "      <td>70.7% ± 14.4%</td>\n",
       "      <td>70.7% ± 16.4%</td>\n",
       "      <td>68.5% ± 8.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>52.6% ± 22.1%</td>\n",
       "      <td>65.1% ± 26.3%</td>\n",
       "      <td>83.8% ± 7.5%</td>\n",
       "      <td>85.3% ± 6.9%</td>\n",
       "      <td>75.3% ± 17.8%</td>\n",
       "      <td>71.1% ± 16.1%</td>\n",
       "      <td>68.2% ± 9.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>46.5% ± 26.4%</td>\n",
       "      <td>57.1% ± 30.5%</td>\n",
       "      <td>80.9% ± 9.0%</td>\n",
       "      <td>83.0% ± 7.5%</td>\n",
       "      <td>77.0% ± 22.3%</td>\n",
       "      <td>65.9% ± 22.6%</td>\n",
       "      <td>68.1% ± 10.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5</th>\n",
       "      <td>26.7% ± 26.3%</td>\n",
       "      <td>35.9% ± 34.4%</td>\n",
       "      <td>72.5% ± 18.6%</td>\n",
       "      <td>75.0% ± 16.2%</td>\n",
       "      <td>66.8% ± 28.4%</td>\n",
       "      <td>55.0% ± 25.9%</td>\n",
       "      <td>68.6% ± 11.5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            citations/ais_recall citations/ais_precision  \\\n",
       "temperature                                                \n",
       "0.01                57.6% ± 2.7%            70.1% ± 3.6%   \n",
       "0.1                 57.1% ± 4.1%            69.1% ± 6.2%   \n",
       "0.2                 55.3% ± 8.3%           69.2% ± 10.4%   \n",
       "0.3                 57.1% ± 8.3%           69.6% ± 11.3%   \n",
       "0.4                58.1% ± 15.1%           70.7% ± 19.4%   \n",
       "0.5                57.4% ± 14.5%           71.1% ± 16.9%   \n",
       "0.6                52.2% ± 16.7%           65.5% ± 21.6%   \n",
       "0.7                54.8% ± 19.1%           66.5% ± 24.1%   \n",
       "0.8                50.7% ± 19.6%           62.8% ± 23.6%   \n",
       "0.9                57.3% ± 20.5%           71.3% ± 22.7%   \n",
       "1.0                55.5% ± 20.7%           68.9% ± 24.0%   \n",
       "1.5                52.6% ± 22.1%           65.1% ± 26.3%   \n",
       "2.0                46.5% ± 26.4%           57.1% ± 30.5%   \n",
       "2.5                26.7% ± 26.3%           35.9% ± 34.4%   \n",
       "\n",
       "            correctness/answer_overlap correctness/answer_entail  \\\n",
       "temperature                                                        \n",
       "0.01                      85.9% ± 1.3%              88.3% ± 1.7%   \n",
       "0.1                       87.3% ± 1.5%              88.7% ± 1.7%   \n",
       "0.2                       86.5% ± 3.0%              88.7% ± 0.6%   \n",
       "0.3                       87.3% ± 4.6%              88.3% ± 2.3%   \n",
       "0.4                       87.2% ± 4.5%              88.7% ± 2.9%   \n",
       "0.5                       85.3% ± 7.4%              88.0% ± 3.5%   \n",
       "0.6                       84.5% ± 4.9%              87.0% ± 4.0%   \n",
       "0.7                       87.1% ± 4.7%              87.3% ± 2.9%   \n",
       "0.8                       86.7% ± 6.3%              86.0% ± 8.7%   \n",
       "0.9                       82.9% ± 7.4%              85.7% ± 5.8%   \n",
       "1.0                       82.5% ± 6.7%              83.7% ± 6.4%   \n",
       "1.5                       83.8% ± 7.5%              85.3% ± 6.9%   \n",
       "2.0                       80.9% ± 9.0%              83.0% ± 7.5%   \n",
       "2.5                      72.5% ± 18.6%             75.0% ± 16.2%   \n",
       "\n",
       "            correctness/citations_recall correctness/citations_precision  \\\n",
       "temperature                                                                \n",
       "0.01                        75.8% ± 1.4%                    74.4% ± 2.3%   \n",
       "0.1                         75.2% ± 2.6%                    72.2% ± 5.0%   \n",
       "0.2                         77.0% ± 5.2%                    74.2% ± 5.1%   \n",
       "0.3                         77.7% ± 6.0%                    75.0% ± 6.7%   \n",
       "0.4                         77.5% ± 9.7%                   73.8% ± 10.0%   \n",
       "0.5                         76.2% ± 8.2%                   73.7% ± 11.4%   \n",
       "0.6                        75.8% ± 12.2%                   73.9% ± 12.6%   \n",
       "0.7                        77.0% ± 11.9%                   73.6% ± 13.2%   \n",
       "0.8                        75.2% ± 12.0%                   72.0% ± 12.4%   \n",
       "0.9                        75.2% ± 14.9%                   73.2% ± 15.2%   \n",
       "1.0                        70.7% ± 14.4%                   70.7% ± 16.4%   \n",
       "1.5                        75.3% ± 17.8%                   71.1% ± 16.1%   \n",
       "2.0                        77.0% ± 22.3%                   65.9% ± 22.6%   \n",
       "2.5                        66.8% ± 28.4%                   55.0% ± 25.9%   \n",
       "\n",
       "            quality/answer_relevance  \n",
       "temperature                           \n",
       "0.01                    72.6% ± 2.3%  \n",
       "0.1                     71.0% ± 3.9%  \n",
       "0.2                     71.6% ± 4.8%  \n",
       "0.3                     71.4% ± 5.2%  \n",
       "0.4                     71.6% ± 6.7%  \n",
       "0.5                     71.3% ± 6.2%  \n",
       "0.6                     71.7% ± 7.2%  \n",
       "0.7                     72.3% ± 6.9%  \n",
       "0.8                     71.1% ± 7.4%  \n",
       "0.9                     68.7% ± 8.8%  \n",
       "1.0                     68.5% ± 8.2%  \n",
       "1.5                     68.2% ± 9.4%  \n",
       "2.0                    68.1% ± 10.7%  \n",
       "2.5                    68.6% ± 11.5%  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Temperature comparison\"))\n",
    "temperature_comparison = show_cleaned_results(parameter_results[parameter_results.index.get_level_values(\"prompt_id\") == \"1\"], keep_index_name=\"temperature\")\n",
    "temperature_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def separate_avg_std(x, as_num=False):\n",
    "    parts = x.split(\" ± \")\n",
    "    if as_num:\n",
    "        return float(parts[0][:-1]), float(parts[1][:-1])\n",
    "    else:\n",
    "        return parts\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "for i, (column, column_nice) in enumerate([(\"citations/ais_recall\", \"Średnia czułość\"), (\"citations/ais_precision\", \"Średnia precyzja\")]):\n",
    "    val = temperature_comparison[column]\n",
    "    avg, std = zip(*[separate_avg_std(x, as_num=True) for x in val])\n",
    "    axs[i].bar(temperature_comparison.index.get_level_values(\"temperature\"), avg, yerr=std, capsize=5)\n",
    "    axs[i].set_ylim(0, 100)\n",
    "    axs[i].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:.0f}%\"))\n",
    "    axs[i].set_ylabel(column_nice)\n",
    "    axs[i].set_xlabel(\"Temperatura\")\n",
    "    axs[i].set_title(column)\n",
    "axs[0].set_title(\"Czułość wstawionych cytowań\")\n",
    "axs[1].set_title(\"Precyzja wstawionych cytowań\")\n",
    "fig.suptitle(\"Porównanie wyników ewaluacji dla różnych temperatur generacji\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Evaluation results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"### Evaluation results\"))\n",
    "eval_not_mistral = eval_results[eval_results.index.get_level_values(\"llm\") != \"Mistral-7B-Instruct-v0.2\"]\n",
    "eval_mistral = eval_results[(eval_results.index.get_level_values(\"llm\") == \"Mistral-7B-Instruct-v0.2\") & (eval_results.index.get_level_values(\"prompt_id\") == \"1\") & (eval_results.index.get_level_values(\"temperature\") == \"0.1\")]\n",
    "eval_display = pd.concat([eval_not_mistral, eval_mistral])\n",
    "eval_display = eval_display[eval_display.index.get_level_values(\"llm\") != \"Mixtral-8x7B-Instruct-v0.1.Q8_0\"]  # use this model only for training data, because we already have same model without quantization\n",
    "eval_display = remove_index(eval_display, \"prompt_id\")\n",
    "eval_display = eval_display.sort_values(by=(\"correctness/citations_recall\"), ascending=False)\n",
    "# eval_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>citations/n_sentences</th>\n",
       "      <th>citations/n_total_citations</th>\n",
       "      <th>citations/n_correct_citations</th>\n",
       "      <th>citations/n_correctly_multicited_sentences</th>\n",
       "      <th>citations/n_overcitations</th>\n",
       "      <th>n_questions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>ellm</th>\n",
       "      <th>sim</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.5 ± 0.1</td>\n",
       "      <td>2.4 ± 0.2</td>\n",
       "      <td>2.0 ± 0.2</td>\n",
       "      <td>0.8 ± 0.1</td>\n",
       "      <td>0.2 ± 0.1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.4 ± 0.1</td>\n",
       "      <td>2.1 ± 0.1</td>\n",
       "      <td>1.8 ± 0.1</td>\n",
       "      <td>0.7 ± 0.1</td>\n",
       "      <td>0.2 ± 0.1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0 ± 0.2</td>\n",
       "      <td>2.1 ± 0.2</td>\n",
       "      <td>2.0 ± 0.3</td>\n",
       "      <td>0.5 ± 0.1</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.1 ± 0.1</td>\n",
       "      <td>2.3 ± 0.2</td>\n",
       "      <td>1.7 ± 0.2</td>\n",
       "      <td>0.4 ± 0.1</td>\n",
       "      <td>0.3 ± 0.1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.6 ± 0.2</td>\n",
       "      <td>1.8 ± 0.1</td>\n",
       "      <td>1.6 ± 0.1</td>\n",
       "      <td>0.5 ± 0.1</td>\n",
       "      <td>0.1 ± 0.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.5 ± 0.1</td>\n",
       "      <td>1.9 ± 0.1</td>\n",
       "      <td>1.5 ± 0.1</td>\n",
       "      <td>0.5 ± 0.1</td>\n",
       "      <td>0.2 ± 0.1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0 ± 0.4</td>\n",
       "      <td>4.9 ± 1.3</td>\n",
       "      <td>3.2 ± 1.1</td>\n",
       "      <td>0.4 ± 0.1</td>\n",
       "      <td>1.6 ± 0.9</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.2 ± 0.2</td>\n",
       "      <td>2.0 ± 0.2</td>\n",
       "      <td>1.2 ± 0.2</td>\n",
       "      <td>0.3 ± 0.1</td>\n",
       "      <td>0.2 ± 0.1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.6 ± 0.2</td>\n",
       "      <td>2.9 ± 0.3</td>\n",
       "      <td>2.1 ± 0.3</td>\n",
       "      <td>0.6 ± 0.1</td>\n",
       "      <td>0.6 ± 0.2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0 ± 0.2</td>\n",
       "      <td>1.7 ± 0.1</td>\n",
       "      <td>1.4 ± 0.2</td>\n",
       "      <td>0.4 ± 0.1</td>\n",
       "      <td>0.1 ± 0.1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.4 ± 0.1</td>\n",
       "      <td>1.6 ± 0.1</td>\n",
       "      <td>1.2 ± 0.1</td>\n",
       "      <td>0.3 ± 0.1</td>\n",
       "      <td>0.1 ± 0.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.6 ± 0.1</td>\n",
       "      <td>1.4 ± 0.0</td>\n",
       "      <td>1.0 ± 0.1</td>\n",
       "      <td>0.3 ± 0.0</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>3.3 ± 0.4</td>\n",
       "      <td>2.6 ± 0.7</td>\n",
       "      <td>1.8 ± 0.6</td>\n",
       "      <td>0.4 ± 0.2</td>\n",
       "      <td>0.3 ± 0.3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.1 ± 0.1</td>\n",
       "      <td>1.8 ± 0.3</td>\n",
       "      <td>1.4 ± 0.3</td>\n",
       "      <td>0.3 ± 0.1</td>\n",
       "      <td>0.2 ± 0.1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.4 ± 0.2</td>\n",
       "      <td>1.3 ± 0.2</td>\n",
       "      <td>0.7 ± 0.2</td>\n",
       "      <td>0.1 ± 0.1</td>\n",
       "      <td>0.1 ± 0.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.3 ± 0.2</td>\n",
       "      <td>1.4 ± 0.2</td>\n",
       "      <td>0.8 ± 0.3</td>\n",
       "      <td>0.2 ± 0.1</td>\n",
       "      <td>0.4 ± 0.2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>8.4 ± 2.7</td>\n",
       "      <td>1.6 ± 0.3</td>\n",
       "      <td>1.1 ± 0.3</td>\n",
       "      <td>0.4 ± 0.1</td>\n",
       "      <td>0.3 ± 0.2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.4 ± 0.0</td>\n",
       "      <td>0.1 ± 0.0</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>0.1 ± 0.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.4 ± 0.1</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                         prompt_id  \\\n",
       "llm                        temperature nli                     ellm                     sim                          \n",
       "rag-tge_Llama-3-8B         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         4   \n",
       "rag-tge_Mistral            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         4   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "\n",
       "                                                                                                         citations/n_sentences  \\\n",
       "llm                        temperature nli                     ellm                     sim                                      \n",
       "rag-tge_Llama-3-8B         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             1.5 ± 0.1   \n",
       "rag-tge_Mistral            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             1.4 ± 0.1   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             2.0 ± 0.2   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             2.1 ± 0.1   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             1.6 ± 0.2   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             1.5 ± 0.1   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             2.0 ± 0.4   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             2.2 ± 0.2   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             2.6 ± 0.2   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             2.0 ± 0.2   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             1.4 ± 0.1   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             1.6 ± 0.1   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             3.3 ± 0.4   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             2.1 ± 0.1   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             2.4 ± 0.2   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             1.3 ± 0.2   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             8.4 ± 2.7   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             1.4 ± 0.0   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             1.4 ± 0.1   \n",
       "\n",
       "                                                                                                         citations/n_total_citations  \\\n",
       "llm                        temperature nli                     ellm                     sim                                            \n",
       "rag-tge_Llama-3-8B         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   2.4 ± 0.2   \n",
       "rag-tge_Mistral            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   2.1 ± 0.1   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   2.1 ± 0.2   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   2.3 ± 0.2   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   1.8 ± 0.1   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   1.9 ± 0.1   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   4.9 ± 1.3   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   2.0 ± 0.2   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   2.9 ± 0.3   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   1.7 ± 0.1   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   1.6 ± 0.1   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   1.4 ± 0.0   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   2.6 ± 0.7   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   1.8 ± 0.3   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   1.3 ± 0.2   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   1.4 ± 0.2   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   1.6 ± 0.3   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.1 ± 0.0   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   0.0 ± 0.0   \n",
       "\n",
       "                                                                                                         citations/n_correct_citations  \\\n",
       "llm                        temperature nli                     ellm                     sim                                              \n",
       "rag-tge_Llama-3-8B         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     2.0 ± 0.2   \n",
       "rag-tge_Mistral            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     1.8 ± 0.1   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     2.0 ± 0.3   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     1.7 ± 0.2   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     1.6 ± 0.1   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     1.5 ± 0.1   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     3.2 ± 1.1   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     1.2 ± 0.2   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     2.1 ± 0.3   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     1.4 ± 0.2   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     1.2 ± 0.1   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     1.0 ± 0.1   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     1.8 ± 0.6   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     1.4 ± 0.3   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.7 ± 0.2   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.8 ± 0.3   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     1.1 ± 0.3   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.0 ± 0.0   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     0.0 ± 0.0   \n",
       "\n",
       "                                                                                                         citations/n_correctly_multicited_sentences  \\\n",
       "llm                        temperature nli                     ellm                     sim                                                           \n",
       "rag-tge_Llama-3-8B         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.8 ± 0.1   \n",
       "rag-tge_Mistral            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.7 ± 0.1   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.5 ± 0.1   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.4 ± 0.1   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.5 ± 0.1   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.5 ± 0.1   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.4 ± 0.1   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.3 ± 0.1   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.6 ± 0.1   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.4 ± 0.1   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.3 ± 0.1   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.3 ± 0.0   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.4 ± 0.2   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.3 ± 0.1   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.1 ± 0.1   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.2 ± 0.1   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.4 ± 0.1   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.0 ± 0.0   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.0 ± 0.0   \n",
       "\n",
       "                                                                                                         citations/n_overcitations  \\\n",
       "llm                        temperature nli                     ellm                     sim                                          \n",
       "rag-tge_Llama-3-8B         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.2 ± 0.1   \n",
       "rag-tge_Mistral            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.2 ± 0.1   \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.0 ± 0.0   \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.3 ± 0.1   \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.1 ± 0.0   \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.2 ± 0.1   \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 1.6 ± 0.9   \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.2 ± 0.1   \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.6 ± 0.2   \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.1 ± 0.1   \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.1 ± 0.0   \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.0 ± 0.0   \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.3 ± 0.3   \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.2 ± 0.1   \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.1 ± 0.0   \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.4 ± 0.2   \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.3 ± 0.2   \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.1 ± 0.0   \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.0 ± 0.0   \n",
       "\n",
       "                                                                                                          n_questions  \n",
       "llm                        temperature nli                     ellm                     sim                            \n",
       "rag-tge_Llama-3-8B         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "rag-tge_Mistral            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "gpt-3.5-turbo-0125         0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "Mixtral-8x7B-Instruct-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "gpt-4-turbo                0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "Meta-Llama-3-70B-Instruct  0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "zephyr-orpo-141b-A35b-v0.1 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "Meta-Llama-3-8B-Instruct   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "Mistral-7B-Instruct-v0.2   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "qwen1_5-110b-chat          0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "qwen1_5-14b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "qwen1_5-32b-chat-q8_0      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "zephyr-7b-beta             0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "c4ai-command-r-plus        0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "qwen1_5-7b-chat-q8_0       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "gemma-1.1-7b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "Phi-3-mini-4k-instruct     0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "gemma-1.1-2b-it            0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  \n",
       "Mistral-7B-Instruct-v0.1   0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          100  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = eval_display.columns\n",
    "metadata_cols = cols[~cols.isin(RESULTS_COLUMNS)]\n",
    "clean_metadata = show_cleaned_results(eval_display, keep_index_name=True, keep_columns=metadata_cols)\n",
    "clean_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B</th>\n",
       "      <td>83.6% ± 4.8%</td>\n",
       "      <td>85.7% ± 5.2%</td>\n",
       "      <td>89.4% ± 2.4%</td>\n",
       "      <td>92.0% ± 2.9%</td>\n",
       "      <td>96.7% ± 2.0%</td>\n",
       "      <td>97.9% ± 1.0%</td>\n",
       "      <td>74.1% ± 3.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral</th>\n",
       "      <td>84.3% ± 5.8%</td>\n",
       "      <td>85.2% ± 5.6%</td>\n",
       "      <td>86.7% ± 1.7%</td>\n",
       "      <td>90.0% ± 1.2%</td>\n",
       "      <td>95.5% ± 1.4%</td>\n",
       "      <td>95.9% ± 1.5%</td>\n",
       "      <td>73.6% ± 4.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   citations/ais_recall citations/ais_precision  \\\n",
       "llm                                                               \n",
       "rag-tge_Llama-3-8B         83.6% ± 4.8%            85.7% ± 5.2%   \n",
       "rag-tge_Mistral            84.3% ± 5.8%            85.2% ± 5.6%   \n",
       "\n",
       "                   correctness/answer_overlap correctness/answer_entail  \\\n",
       "llm                                                                       \n",
       "rag-tge_Llama-3-8B               89.4% ± 2.4%              92.0% ± 2.9%   \n",
       "rag-tge_Mistral                  86.7% ± 1.7%              90.0% ± 1.2%   \n",
       "\n",
       "                   correctness/citations_recall  \\\n",
       "llm                                               \n",
       "rag-tge_Llama-3-8B                 96.7% ± 2.0%   \n",
       "rag-tge_Mistral                    95.5% ± 1.4%   \n",
       "\n",
       "                   correctness/citations_precision quality/answer_relevance  \n",
       "llm                                                                          \n",
       "rag-tge_Llama-3-8B                    97.9% ± 1.0%             74.1% ± 3.4%  \n",
       "rag-tge_Mistral                       95.9% ± 1.5%             73.6% ± 4.0%  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_results = show_cleaned_results(eval_display, keep_index_name=\"llm\")\n",
    "my_results = clean_results[clean_results.index.get_level_values(\"llm\").str.contains(\"rag-tge\")]\n",
    "my_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### sorted by: citations/ais_recall"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral</th>\n",
       "      <td>84.3% ± 5.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B</th>\n",
       "      <td>83.6% ± 4.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>73.8% ± 7.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>73.0% ± 4.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>69.5% ± 5.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>65.4% ± 6.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>63.2% ± 4.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>57.1% ± 4.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>52.9% ± 9.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>51.2% ± 3.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>49.3% ± 6.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>41.8% ± 13.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>40.6% ± 9.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>40.2% ± 6.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>36.9% ± 12.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>24.9% ± 2.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>23.3% ± 6.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.7% ± 0.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.5% ± 0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_recall\n",
       "llm                                            \n",
       "rag-tge_Mistral                    84.3% ± 5.8%\n",
       "rag-tge_Llama-3-8B                 83.6% ± 4.8%\n",
       "gpt-3.5-turbo-0125                 73.8% ± 7.3%\n",
       "gpt-4-turbo                        73.0% ± 4.8%\n",
       "Meta-Llama-3-70B-Instruct          69.5% ± 5.0%\n",
       "Mixtral-8x7B-Instruct-v0.1         65.4% ± 6.1%\n",
       "qwen1_5-14b-chat-q8_0              63.2% ± 4.5%\n",
       "Mistral-7B-Instruct-v0.2           57.1% ± 4.1%\n",
       "qwen1_5-110b-chat                  52.9% ± 9.7%\n",
       "qwen1_5-32b-chat-q8_0              51.2% ± 3.2%\n",
       "Meta-Llama-3-8B-Instruct           49.3% ± 6.1%\n",
       "zephyr-orpo-141b-A35b-v0.1        41.8% ± 13.4%\n",
       "zephyr-7b-beta                     40.6% ± 9.4%\n",
       "c4ai-command-r-plus                40.2% ± 6.3%\n",
       "gemma-1.1-7b-it                   36.9% ± 12.7%\n",
       "Phi-3-mini-4k-instruct             24.9% ± 2.9%\n",
       "qwen1_5-7b-chat-q8_0               23.3% ± 6.4%\n",
       "gemma-1.1-2b-it                     0.7% ± 0.6%\n",
       "Mistral-7B-Instruct-v0.1            0.5% ± 0.0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: citations/ais_precision"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citations/ais_precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>88.9% ± 3.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>88.8% ± 4.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B</th>\n",
       "      <td>85.7% ± 5.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral</th>\n",
       "      <td>85.2% ± 5.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>80.9% ± 10.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>76.9% ± 5.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>74.6% ± 7.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>69.5% ± 5.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>69.1% ± 6.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>67.4% ± 14.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>66.2% ± 2.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>60.6% ± 7.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>59.9% ± 13.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>57.5% ± 5.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>46.5% ± 12.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>45.6% ± 7.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>45.6% ± 14.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>1.0% ± 0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>0.7% ± 0.6%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           citations/ais_precision\n",
       "llm                                               \n",
       "gpt-4-turbo                           88.9% ± 3.6%\n",
       "gpt-3.5-turbo-0125                    88.8% ± 4.5%\n",
       "rag-tge_Llama-3-8B                    85.7% ± 5.2%\n",
       "rag-tge_Mistral                       85.2% ± 5.6%\n",
       "qwen1_5-110b-chat                    80.9% ± 10.9%\n",
       "Meta-Llama-3-70B-Instruct             76.9% ± 5.1%\n",
       "Mixtral-8x7B-Instruct-v0.1            74.6% ± 7.3%\n",
       "qwen1_5-14b-chat-q8_0                 69.5% ± 5.8%\n",
       "Mistral-7B-Instruct-v0.2              69.1% ± 6.2%\n",
       "zephyr-7b-beta                       67.4% ± 14.1%\n",
       "qwen1_5-32b-chat-q8_0                 66.2% ± 2.8%\n",
       "c4ai-command-r-plus                   60.6% ± 7.4%\n",
       "zephyr-orpo-141b-A35b-v0.1           59.9% ± 13.0%\n",
       "Meta-Llama-3-8B-Instruct              57.5% ± 5.9%\n",
       "qwen1_5-7b-chat-q8_0                 46.5% ± 12.8%\n",
       "Phi-3-mini-4k-instruct                45.6% ± 7.2%\n",
       "gemma-1.1-7b-it                      45.6% ± 14.1%\n",
       "Mistral-7B-Instruct-v0.1               1.0% ± 0.0%\n",
       "gemma-1.1-2b-it                        0.7% ± 0.6%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/answer_overlap"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>91.8% ± 0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>91.0% ± 0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B</th>\n",
       "      <td>89.4% ± 2.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>88.4% ± 1.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>87.7% ± 0.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>87.6% ± 0.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>87.4% ± 0.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>87.3% ± 1.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>86.7% ± 2.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral</th>\n",
       "      <td>86.7% ± 1.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>86.6% ± 2.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>86.5% ± 2.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>85.4% ± 2.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>80.7% ± 6.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>79.0% ± 1.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>73.6% ± 2.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>72.3% ± 7.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>71.1% ± 1.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>63.1% ± 3.8%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           correctness/answer_overlap\n",
       "llm                                                  \n",
       "Meta-Llama-3-8B-Instruct                 91.8% ± 0.0%\n",
       "Mixtral-8x7B-Instruct-v0.1               91.0% ± 0.1%\n",
       "rag-tge_Llama-3-8B                       89.4% ± 2.4%\n",
       "gpt-3.5-turbo-0125                       88.4% ± 1.3%\n",
       "gpt-4-turbo                              87.7% ± 0.8%\n",
       "qwen1_5-14b-chat-q8_0                    87.6% ± 0.7%\n",
       "qwen1_5-32b-chat-q8_0                    87.4% ± 0.6%\n",
       "Mistral-7B-Instruct-v0.2                 87.3% ± 1.5%\n",
       "qwen1_5-110b-chat                        86.7% ± 2.0%\n",
       "rag-tge_Mistral                          86.7% ± 1.7%\n",
       "Meta-Llama-3-70B-Instruct                86.6% ± 2.1%\n",
       "qwen1_5-7b-chat-q8_0                     86.5% ± 2.4%\n",
       "zephyr-7b-beta                           85.4% ± 2.9%\n",
       "zephyr-orpo-141b-A35b-v0.1               80.7% ± 6.0%\n",
       "Mistral-7B-Instruct-v0.1                 79.0% ± 1.4%\n",
       "c4ai-command-r-plus                      73.6% ± 2.3%\n",
       "gemma-1.1-7b-it                          72.3% ± 7.6%\n",
       "Phi-3-mini-4k-instruct                   71.1% ± 1.2%\n",
       "gemma-1.1-2b-it                          63.1% ± 3.8%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/answer_entail"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B</th>\n",
       "      <td>92.0% ± 2.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>91.0% ± 1.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>90.3% ± 0.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>90.0% ± 1.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral</th>\n",
       "      <td>90.0% ± 1.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>89.7% ± 1.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>89.7% ± 0.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>89.3% ± 1.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>88.7% ± 1.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>88.0% ± 0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>87.3% ± 1.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>86.7% ± 4.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>86.3% ± 0.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>86.0% ± 4.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>84.0% ± 2.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>82.7% ± 1.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>78.0% ± 2.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>72.7% ± 7.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>67.0% ± 4.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           correctness/answer_entail\n",
       "llm                                                 \n",
       "rag-tge_Llama-3-8B                      92.0% ± 2.9%\n",
       "gpt-3.5-turbo-0125                      91.0% ± 1.2%\n",
       "Meta-Llama-3-8B-Instruct                90.3% ± 0.6%\n",
       "gpt-4-turbo                             90.0% ± 1.2%\n",
       "rag-tge_Mistral                         90.0% ± 1.2%\n",
       "Mixtral-8x7B-Instruct-v0.1              89.7% ± 1.2%\n",
       "qwen1_5-32b-chat-q8_0                   89.7% ± 0.6%\n",
       "qwen1_5-110b-chat                       89.3% ± 1.7%\n",
       "Mistral-7B-Instruct-v0.2                88.7% ± 1.7%\n",
       "c4ai-command-r-plus                     88.0% ± 0.0%\n",
       "Meta-Llama-3-70B-Instruct               87.3% ± 1.7%\n",
       "zephyr-7b-beta                          86.7% ± 4.6%\n",
       "qwen1_5-14b-chat-q8_0                   86.3% ± 0.6%\n",
       "zephyr-orpo-141b-A35b-v0.1              86.0% ± 4.0%\n",
       "qwen1_5-7b-chat-q8_0                    84.0% ± 2.3%\n",
       "Mistral-7B-Instruct-v0.1                82.7% ± 1.7%\n",
       "Phi-3-mini-4k-instruct                  78.0% ± 2.3%\n",
       "gemma-1.1-7b-it                         72.7% ± 7.5%\n",
       "gemma-1.1-2b-it                         67.0% ± 4.0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/citations_recall"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B</th>\n",
       "      <td>96.7% ± 2.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral</th>\n",
       "      <td>95.5% ± 1.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>85.3% ± 2.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>82.5% ± 3.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>79.5% ± 2.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>78.5% ± 1.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>77.5% ± 9.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>75.3% ± 2.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>75.2% ± 2.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>73.5% ± 5.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>66.0% ± 3.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>65.5% ± 0.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>62.7% ± 8.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>57.8% ± 4.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>54.8% ± 7.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>47.2% ± 8.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>45.2% ± 5.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>3.3% ± 0.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>1.0% ± 0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           correctness/citations_recall\n",
       "llm                                                    \n",
       "rag-tge_Llama-3-8B                         96.7% ± 2.0%\n",
       "rag-tge_Mistral                            95.5% ± 1.4%\n",
       "gpt-3.5-turbo-0125                         85.3% ± 2.3%\n",
       "Mixtral-8x7B-Instruct-v0.1                 82.5% ± 3.5%\n",
       "gpt-4-turbo                                79.5% ± 2.9%\n",
       "Meta-Llama-3-70B-Instruct                  78.5% ± 1.7%\n",
       "zephyr-orpo-141b-A35b-v0.1                 77.5% ± 9.2%\n",
       "Meta-Llama-3-8B-Instruct                   75.3% ± 2.3%\n",
       "Mistral-7B-Instruct-v0.2                   75.2% ± 2.6%\n",
       "qwen1_5-110b-chat                          73.5% ± 5.2%\n",
       "qwen1_5-14b-chat-q8_0                      66.0% ± 3.1%\n",
       "qwen1_5-32b-chat-q8_0                      65.5% ± 0.9%\n",
       "zephyr-7b-beta                             62.7% ± 8.0%\n",
       "c4ai-command-r-plus                        57.8% ± 4.4%\n",
       "qwen1_5-7b-chat-q8_0                       54.8% ± 7.4%\n",
       "gemma-1.1-7b-it                            47.2% ± 8.1%\n",
       "Phi-3-mini-4k-instruct                     45.2% ± 5.1%\n",
       "gemma-1.1-2b-it                             3.3% ± 0.6%\n",
       "Mistral-7B-Instruct-v0.1                    1.0% ± 0.0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: correctness/citations_precision"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B</th>\n",
       "      <td>97.9% ± 1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>96.2% ± 0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral</th>\n",
       "      <td>95.9% ± 1.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>94.2% ± 2.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>93.9% ± 1.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>93.0% ± 2.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>92.0% ± 1.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>90.8% ± 1.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>90.8% ± 1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>87.6% ± 3.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>80.0% ± 7.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>72.8% ± 8.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>72.2% ± 5.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>66.0% ± 10.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>64.4% ± 5.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>54.6% ± 10.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>45.8% ± 6.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>4.3% ± 0.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>0.7% ± 0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           correctness/citations_precision\n",
       "llm                                                       \n",
       "rag-tge_Llama-3-8B                            97.9% ± 1.0%\n",
       "qwen1_5-32b-chat-q8_0                         96.2% ± 0.0%\n",
       "rag-tge_Mistral                               95.9% ± 1.5%\n",
       "gpt-3.5-turbo-0125                            94.2% ± 2.4%\n",
       "gpt-4-turbo                                   93.9% ± 1.1%\n",
       "qwen1_5-110b-chat                             93.0% ± 2.3%\n",
       "qwen1_5-14b-chat-q8_0                         92.0% ± 1.6%\n",
       "Meta-Llama-3-8B-Instruct                      90.8% ± 1.8%\n",
       "Meta-Llama-3-70B-Instruct                     90.8% ± 1.0%\n",
       "Mixtral-8x7B-Instruct-v0.1                    87.6% ± 3.8%\n",
       "qwen1_5-7b-chat-q8_0                          80.0% ± 7.8%\n",
       "zephyr-7b-beta                                72.8% ± 8.8%\n",
       "Mistral-7B-Instruct-v0.2                      72.2% ± 5.0%\n",
       "gemma-1.1-7b-it                              66.0% ± 10.1%\n",
       "c4ai-command-r-plus                           64.4% ± 5.5%\n",
       "zephyr-orpo-141b-A35b-v0.1                   54.6% ± 10.8%\n",
       "Phi-3-mini-4k-instruct                        45.8% ± 6.4%\n",
       "gemma-1.1-2b-it                                4.3% ± 0.7%\n",
       "Mistral-7B-Instruct-v0.1                       0.7% ± 0.0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sorted by: quality/answer_relevance"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qwen1_5-7b-chat-q8_0</th>\n",
       "      <td>75.1% ± 5.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <td>74.4% ± 2.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Llama-3-8B</th>\n",
       "      <td>74.1% ± 3.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <td>73.9% ± 5.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag-tge_Mistral</th>\n",
       "      <td>73.6% ± 4.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <td>73.5% ± 4.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-7b-it</th>\n",
       "      <td>73.4% ± 5.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>72.8% ± 3.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <td>72.2% ± 1.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-14b-chat-q8_0</th>\n",
       "      <td>71.8% ± 2.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.1</th>\n",
       "      <td>71.8% ± 2.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-1.1-2b-it</th>\n",
       "      <td>71.4% ± 2.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>71.0% ± 4.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <td>71.0% ± 3.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <td>70.3% ± 4.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>70.3% ± 3.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <td>68.7% ± 6.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct</th>\n",
       "      <td>65.6% ± 4.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4ai-command-r-plus</th>\n",
       "      <td>62.9% ± 5.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           quality/answer_relevance\n",
       "llm                                                \n",
       "qwen1_5-7b-chat-q8_0                   75.1% ± 5.1%\n",
       "Meta-Llama-3-70B-Instruct              74.4% ± 2.4%\n",
       "rag-tge_Llama-3-8B                     74.1% ± 3.4%\n",
       "gpt-3.5-turbo-0125                     73.9% ± 5.4%\n",
       "rag-tge_Mistral                        73.6% ± 4.0%\n",
       "qwen1_5-110b-chat                      73.5% ± 4.8%\n",
       "gemma-1.1-7b-it                        73.4% ± 5.5%\n",
       "gpt-4-turbo                            72.8% ± 3.3%\n",
       "qwen1_5-32b-chat-q8_0                  72.2% ± 1.7%\n",
       "qwen1_5-14b-chat-q8_0                  71.8% ± 2.9%\n",
       "Mistral-7B-Instruct-v0.1               71.8% ± 2.7%\n",
       "gemma-1.1-2b-it                        71.4% ± 2.3%\n",
       "zephyr-7b-beta                         71.0% ± 4.6%\n",
       "Mistral-7B-Instruct-v0.2               71.0% ± 3.9%\n",
       "Meta-Llama-3-8B-Instruct               70.3% ± 4.0%\n",
       "Mixtral-8x7B-Instruct-v0.1             70.3% ± 3.0%\n",
       "zephyr-orpo-141b-A35b-v0.1             68.7% ± 6.1%\n",
       "Phi-3-mini-4k-instruct                 65.6% ± 4.6%\n",
       "c4ai-command-r-plus                    62.9% ± 5.0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_results.style.apply(lambda x: [\"font-weight: 1000\" if \"rag-tge\" in x.name else \"\" for _ in x], axis=1)\n",
    "\n",
    "for sort_by in [\n",
    "    \"citations/ais_recall\",\n",
    "    \"citations/ais_precision\",\n",
    "    \"correctness/answer_overlap\",\n",
    "    \"correctness/answer_entail\",\n",
    "    \"correctness/citations_recall\",\n",
    "    \"correctness/citations_precision\",\n",
    "    \"quality/answer_relevance\",\n",
    "]:\n",
    "    display(Markdown(f\"### sorted by: {sort_by}\"))\n",
    "    results = clean_results.sort_values(by=sort_by, ascending=False)\n",
    "    results = results[[sort_by]]\n",
    "    display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Training results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>citations/n_sentences</th>\n",
       "      <th>citations/n_total_citations</th>\n",
       "      <th>citations/n_correct_citations</th>\n",
       "      <th>citations/n_correctly_multicited_sentences</th>\n",
       "      <th>citations/n_overcitations</th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <th>quality/answer_relevance</th>\n",
       "      <th>n_questions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th>temperature</th>\n",
       "      <th>nli</th>\n",
       "      <th>ellm</th>\n",
       "      <th>sim</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>74.2% ± 3.1%</td>\n",
       "      <td>95.8% ± 1.1%</td>\n",
       "      <td>1.5 ± 0.1</td>\n",
       "      <td>2.0 ± 0.1</td>\n",
       "      <td>1.9 ± 0.1</td>\n",
       "      <td>0.6 ± 0.0</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>88.7% ± 1.0%</td>\n",
       "      <td>89.2% ± 1.1%</td>\n",
       "      <td>81.0% ± 1.6%</td>\n",
       "      <td>91.1% ± 1.2%</td>\n",
       "      <td>74.3% ± 2.4%</td>\n",
       "      <td>17872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0% ± 6.4%</td>\n",
       "      <td>93.2% ± 2.8%</td>\n",
       "      <td>2.1 ± 0.2</td>\n",
       "      <td>2.5 ± 0.3</td>\n",
       "      <td>2.3 ± 0.3</td>\n",
       "      <td>0.6 ± 0.1</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>88.0% ± 1.7%</td>\n",
       "      <td>88.0% ± 2.0%</td>\n",
       "      <td>82.5% ± 3.8%</td>\n",
       "      <td>84.5% ± 3.8%</td>\n",
       "      <td>73.0% ± 3.5%</td>\n",
       "      <td>7659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1.Q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>62.4% ± 7.0%</td>\n",
       "      <td>90.2% ± 3.5%</td>\n",
       "      <td>2.7 ± 0.3</td>\n",
       "      <td>3.0 ± 0.4</td>\n",
       "      <td>2.8 ± 0.3</td>\n",
       "      <td>0.7 ± 0.1</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>87.5% ± 1.8%</td>\n",
       "      <td>87.8% ± 2.0%</td>\n",
       "      <td>84.8% ± 3.6%</td>\n",
       "      <td>79.7% ± 4.6%</td>\n",
       "      <td>72.5% ± 3.7%</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-110b-chat</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>56.5% ± 11.7%</td>\n",
       "      <td>94.6% ± 3.8%</td>\n",
       "      <td>1.9 ± 0.3</td>\n",
       "      <td>1.8 ± 0.2</td>\n",
       "      <td>1.7 ± 0.2</td>\n",
       "      <td>0.5 ± 0.1</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>88.5% ± 2.2%</td>\n",
       "      <td>87.4% ± 2.5%</td>\n",
       "      <td>73.7% ± 5.4%</td>\n",
       "      <td>91.0% ± 3.7%</td>\n",
       "      <td>72.5% ± 4.4%</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen1_5-32b-chat-q8_0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>55.0% ± 3.2%</td>\n",
       "      <td>96.7% ± 0.6%</td>\n",
       "      <td>1.6 ± 0.1</td>\n",
       "      <td>1.4 ± 0.0</td>\n",
       "      <td>1.3 ± 0.1</td>\n",
       "      <td>0.2 ± 0.0</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>87.0% ± 1.0%</td>\n",
       "      <td>84.4% ± 0.0%</td>\n",
       "      <td>63.3% ± 2.2%</td>\n",
       "      <td>95.4% ± 0.3%</td>\n",
       "      <td>72.5% ± 1.9%</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-orpo-141b-A35b-v0.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>t5_xxl_true_nli_mixture</th>\n",
       "      <th>Mistral-7B-Instruct-v0.2</th>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>1</td>\n",
       "      <td>44.3% ± 12.7%</td>\n",
       "      <td>79.0% ± 10.6%</td>\n",
       "      <td>2.0 ± 0.4</td>\n",
       "      <td>4.6 ± 1.3</td>\n",
       "      <td>3.2 ± 1.0</td>\n",
       "      <td>0.6 ± 0.2</td>\n",
       "      <td>0.1 ± 0.1</td>\n",
       "      <td>83.5% ± 3.6%</td>\n",
       "      <td>84.5% ± 3.5%</td>\n",
       "      <td>73.8% ± 9.7%</td>\n",
       "      <td>56.2% ± 10.6%</td>\n",
       "      <td>68.2% ± 6.4%</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              prompt_id  \\\n",
       "llm                             temperature nli                     ellm                     sim                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1   \n",
       "\n",
       "                                                                                                              citations/ais_recall  \\\n",
       "llm                             temperature nli                     ellm                     sim                                     \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         74.2% ± 3.1%   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         67.0% ± 6.4%   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         62.4% ± 7.0%   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2        56.5% ± 11.7%   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         55.0% ± 3.2%   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2        44.3% ± 12.7%   \n",
       "\n",
       "                                                                                                              citations/ais_precision  \\\n",
       "llm                             temperature nli                     ellm                     sim                                        \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2            95.8% ± 1.1%   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2            93.2% ± 2.8%   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2            90.2% ± 3.5%   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2            94.6% ± 3.8%   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2            96.7% ± 0.6%   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2           79.0% ± 10.6%   \n",
       "\n",
       "                                                                                                              citations/n_sentences  \\\n",
       "llm                             temperature nli                     ellm                     sim                                      \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             1.5 ± 0.1   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             2.1 ± 0.2   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             2.7 ± 0.3   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             1.9 ± 0.3   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             1.6 ± 0.1   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             2.0 ± 0.4   \n",
       "\n",
       "                                                                                                              citations/n_total_citations  \\\n",
       "llm                             temperature nli                     ellm                     sim                                            \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   2.0 ± 0.1   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   2.5 ± 0.3   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   3.0 ± 0.4   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   1.8 ± 0.2   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   1.4 ± 0.0   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   4.6 ± 1.3   \n",
       "\n",
       "                                                                                                              citations/n_correct_citations  \\\n",
       "llm                             temperature nli                     ellm                     sim                                              \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     1.9 ± 0.1   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     2.3 ± 0.3   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     2.8 ± 0.3   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     1.7 ± 0.2   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     1.3 ± 0.1   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                     3.2 ± 1.0   \n",
       "\n",
       "                                                                                                              citations/n_correctly_multicited_sentences  \\\n",
       "llm                             temperature nli                     ellm                     sim                                                           \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.6 ± 0.0   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.6 ± 0.1   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.7 ± 0.1   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.5 ± 0.1   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.2 ± 0.0   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                                  0.6 ± 0.2   \n",
       "\n",
       "                                                                                                              citations/n_overcitations  \\\n",
       "llm                             temperature nli                     ellm                     sim                                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.0 ± 0.0   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.0 ± 0.0   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.0 ± 0.0   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.0 ± 0.0   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.0 ± 0.0   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 0.1 ± 0.1   \n",
       "\n",
       "                                                                                                              correctness/answer_overlap  \\\n",
       "llm                             temperature nli                     ellm                     sim                                           \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2               88.7% ± 1.0%   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2               88.0% ± 1.7%   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2               87.5% ± 1.8%   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2               88.5% ± 2.2%   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2               87.0% ± 1.0%   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2               83.5% ± 3.6%   \n",
       "\n",
       "                                                                                                              correctness/answer_entail  \\\n",
       "llm                             temperature nli                     ellm                     sim                                          \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              89.2% ± 1.1%   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              88.0% ± 2.0%   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              87.8% ± 2.0%   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              87.4% ± 2.5%   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              84.4% ± 0.0%   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2              84.5% ± 3.5%   \n",
       "\n",
       "                                                                                                              correctness/citations_recall  \\\n",
       "llm                             temperature nli                     ellm                     sim                                             \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 81.0% ± 1.6%   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 82.5% ± 3.8%   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 84.8% ± 3.6%   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 73.7% ± 5.4%   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 63.3% ± 2.2%   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                 73.8% ± 9.7%   \n",
       "\n",
       "                                                                                                              correctness/citations_precision  \\\n",
       "llm                             temperature nli                     ellm                     sim                                                \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    91.1% ± 1.2%   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    84.5% ± 3.8%   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    79.7% ± 4.6%   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    91.0% ± 3.7%   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                    95.4% ± 0.3%   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2                   56.2% ± 10.6%   \n",
       "\n",
       "                                                                                                              quality/answer_relevance  \\\n",
       "llm                             temperature nli                     ellm                     sim                                         \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             74.3% ± 2.4%   \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             73.0% ± 3.5%   \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             72.5% ± 3.7%   \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             72.5% ± 4.4%   \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             72.5% ± 1.9%   \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2             68.2% ± 6.4%   \n",
       "\n",
       "                                                                                                               n_questions  \n",
       "llm                             temperature nli                     ellm                     sim                            \n",
       "Meta-Llama-3-70B-Instruct       0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2        17872  \n",
       "Mixtral-8x7B-Instruct-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         7659  \n",
       "Mixtral-8x7B-Instruct-v0.1.Q8_0 0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         6000  \n",
       "qwen1_5-110b-chat               0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2         1000  \n",
       "qwen1_5-32b-chat-q8_0           0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2           90  \n",
       "zephyr-orpo-141b-A35b-v0.1      0.1         t5_xxl_true_nli_mixture Mistral-7B-Instruct-v0.2 all-MiniLM-L6-v2          763  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"### Training results\"))\n",
    "train_display = remove_index(train_results, \"prompt_id\")\n",
    "train_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "citations recall correlation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.45609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <td>0.45609</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              citations/ais_recall  \\\n",
       "citations/ais_recall                       1.00000   \n",
       "correctness/citations_recall               0.45609   \n",
       "\n",
       "                              correctness/citations_recall  \n",
       "citations/ais_recall                               0.45609  \n",
       "correctness/citations_recall                       1.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "citations precision correlation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.475579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <td>0.475579</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 citations/ais_precision  \\\n",
       "citations/ais_precision                         1.000000   \n",
       "correctness/citations_precision                 0.475579   \n",
       "\n",
       "                                 correctness/citations_precision  \n",
       "citations/ais_precision                                 0.475579  \n",
       "correctness/citations_precision                         1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer correlation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.661116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <td>0.661116</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            correctness/answer_overlap  \\\n",
       "correctness/answer_overlap                    1.000000   \n",
       "correctness/answer_entail                     0.661116   \n",
       "\n",
       "                            correctness/answer_entail  \n",
       "correctness/answer_overlap                   0.661116  \n",
       "correctness/answer_entail                    1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> binary columns created\n",
      "\n",
      "citations recall correlation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <th>correctness/citations_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>citations/ais_recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctness/citations_recall</th>\n",
       "      <td>0.161288</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              citations/ais_recall  \\\n",
       "citations/ais_recall                      1.000000   \n",
       "correctness/citations_recall              0.161288   \n",
       "\n",
       "                              correctness/citations_recall  \n",
       "citations/ais_recall                              0.161288  \n",
       "correctness/citations_recall                      1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "citations precision correlation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <th>correctness/citations_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>citations/ais_precision</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctness/citations_precision</th>\n",
       "      <td>0.3567</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 citations/ais_precision  \\\n",
       "citations/ais_precision                           1.0000   \n",
       "correctness/citations_precision                   0.3567   \n",
       "\n",
       "                                 correctness/citations_precision  \n",
       "citations/ais_precision                                   0.3567  \n",
       "correctness/citations_precision                           1.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer correlation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <th>correctness/answer_entail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>correctness/answer_overlap</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.653553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctness/answer_entail</th>\n",
       "      <td>0.653553</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            correctness/answer_overlap  \\\n",
       "correctness/answer_overlap                    1.000000   \n",
       "correctness/answer_entail                     0.653553   \n",
       "\n",
       "                            correctness/answer_entail  \n",
       "correctness/answer_overlap                   0.653553  \n",
       "correctness/answer_entail                    1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_method = \"pearson\"  # \"spearman\", \"kendall\" or \"pearson\"\n",
    "eval_split_copy = eval_split.copy()\n",
    "\n",
    "citations_recall_corr = eval_split_copy[[\"citations/ais_recall\", \"correctness/citations_recall\"]].corr(method=corr_method)\n",
    "print(\"citations recall correlation:\")\n",
    "display(citations_recall_corr)\n",
    "\n",
    "citations_precision_corr = eval_split_copy[[\"citations/ais_precision\", \"correctness/citations_precision\"]].corr(method=corr_method)\n",
    "print(\"citations precision correlation:\")\n",
    "display(citations_precision_corr)\n",
    "\n",
    "answer_corr = eval_split_copy[[\"correctness/answer_overlap\", \"correctness/answer_entail\"]].corr(method=corr_method)\n",
    "print(\"answer correlation:\")\n",
    "display(answer_corr)\n",
    "\n",
    "\n",
    "for col in [\"citations/ais_recall\", \"citations/ais_precision\", \"correctness/answer_overlap\", \"correctness/answer_entail\", \"correctness/citations_recall\", \"correctness/citations_precision\"]:\n",
    "    eval_split_copy[col] = eval_split_copy[col] == eval_split_copy[col].max()\n",
    "print(\"\\n> binary columns created\\n\")\n",
    "\n",
    "\n",
    "citations_recall_corr = eval_split_copy[[\"citations/ais_recall\", \"correctness/citations_recall\"]].corr(method=corr_method)\n",
    "print(\"citations recall correlation:\")\n",
    "display(citations_recall_corr)\n",
    "\n",
    "citations_precision_corr = eval_split_copy[[\"citations/ais_precision\", \"correctness/citations_precision\"]].corr(method=corr_method)\n",
    "print(\"citations precision correlation:\")\n",
    "display(citations_precision_corr)\n",
    "\n",
    "answer_corr = eval_split_copy[[\"correctness/answer_overlap\", \"correctness/answer_entail\"]].corr(method=corr_method)\n",
    "print(\"answer correlation:\")\n",
    "display(answer_corr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
